<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8"/>
	<link type="text/css" rel="stylesheet" href="https://hendri54.github.io/css/avenir-white.css"/>
	<meta name="author" content="Lutz Hendricks"/>
	<meta name="affiliation" content="https://www.unc.edu"/>
<a style="color: rgb(102, 102, 102);" href="https://www.lhendricks.org"><span
style="font-weight: bold;">Lutz Hendricks - UNC - Department of
Economics</span></a><link rel="stylesheet" href="https://yandex.st/highlightjs/7.3/styles/default.min.css">
<script src="https://yandex.st/highlightjs/7.3/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript"  
src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>

<h1 id="thequestionofsimplemodelsandlittledata">The Question of Simple Models and Little Data</h1>

<p>For some time, I have been wondering why many highly competent authors in quantitative economics work with very stylized models and with very limited data.</p>

<h3 id="examples:">Examples:</h3>

<ul>
<li>Hsieh/Hurst/Jones/Klenow (Econometrica, forthcoming) could use panel data to get a better idea of individuals&#8217; comparative advantage for particular occupations.</li>
<li>Lagakos/Waugh (AER) could use panel data to see whether urban/rural migrants experience large wage gains (similar to Glazer/Mare using US data).</li>
<li>An extreme example: Manuelli/Seshadri (AER) use essentially no data at all.</li>
</ul>

<p>Could one not pin down key model parameters, such as &#8220;the elasticity&#8221; in Manuelly/Seshadri, more precisely with more/better data?</p>

<p>One possible resolution of the puzzle: these papers really point out the <em>possibility</em> that a particular cause-effect mechanism <strong>could be</strong> empirically important.</p>

<p>To do so, they write down a simple model and calibrate it in a simple way. The point being made would then be rather limited: one can write down a non-nonsensical model and stick in non-nonsensical parameter values and find that the mechanism under study is &#8220;big.&#8221;</p>

<p>Of course, this is not the way the papers are written. They typically contain quantitative statements, such as &#8220;the entire rise in the US college wage premium can be accounted for by the changing relative abilities of college graduates&#8221; (Hendricks/Schoellman, JME 2014; to point a finger at myself).</p>

<p>An innocent reader (like myself, until recently) might take the quantitative results at face value.</p>

<p>But then it is puzzling that the models so stylized and that not more data are used to discipline them.</p>

<p>But then: if the papers merely point out a possibility, this puzzle is resolved. </p>

<p>Perhaps, the authors understand that possibilities are all we can get from quantitative models. So we might as well proceed with simple examples instead of complicated models and detailed data.</p>

<p>But then we have a major problem: quantitative economics is then limited to accumulating <em>potentially</em> important explanations for what we observe.</p>

<p>In many cases, the number of explanations is quite large.
Take the case of cross-country income gaps. If we add up the fractions explained by physical capital, human capital, misallocation, capital import frictions, etc., we end up explaining the observed income gaps many times over. </p>

<p>Something seems fundamentally wrong here.</p>

<hr />

</body>
</html>
