{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Lutz Hendricks Associate Professor of Economics UNC Chapel Hill 06C Gardner Hall Chapel Hill, NC 27599 hendricksl at protonmail.com Teaching Fall 2021 \u00b6 Econ720 : Advanced Macro Theory I (PhD) Econ520 Advanced Macroeconomic Theory Econ920 Macro student workshop Office hours: MW 1-2pm or by appointment. Online by default (during covid). Please contact me (ahead of time) so I start the zoom meeting. Zoom info is on the couse sakai sites. Teaching Spring 2021 \u00b6 Econ520 Advanced Macroeconomic Theory Econ890 Graduate field course on income and wealth inequality. Office hours: MW 3:45-4:45pm Due to Covid, office hours will be held online only. I encourage students to make appointments. Zoom information is shown in the sakai course site. Notes \u00b6 I do not have openings for research positions at any level. This is my professional web site. Personal content is posted elsewhere. I do not have social media accounts (especially not Fakebook, SnapCheat, InstaScam, or Twister).","title":"Home"},{"location":"index.html#teaching-fall-2021","text":"Econ720 : Advanced Macro Theory I (PhD) Econ520 Advanced Macroeconomic Theory Econ920 Macro student workshop Office hours: MW 1-2pm or by appointment. Online by default (during covid). Please contact me (ahead of time) so I start the zoom meeting. Zoom info is on the couse sakai sites.","title":"Teaching Fall 2021"},{"location":"index.html#teaching-spring-2021","text":"Econ520 Advanced Macroeconomic Theory Econ890 Graduate field course on income and wealth inequality. Office hours: MW 3:45-4:45pm Due to Covid, office hours will be held online only. I encourage students to make appointments. Zoom information is shown in the sakai course site.","title":"Teaching Spring 2021"},{"location":"index.html#notes","text":"I do not have openings for research positions at any level. This is my professional web site. Personal content is posted elsewhere. I do not have social media accounts (especially not Fakebook, SnapCheat, InstaScam, or Twister).","title":"Notes"},{"location":"inactive_link.html","text":"{{markdown_header.txt}} This link is not yet active. If you think the link is broken, please report to Lutz Hendricks.","title":"Inactive link"},{"location":"test.html","text":"First Header Second Header Third Header Content Cell Content Cell Content Cell Content Cell Content Cell Content Cell","title":"Test"},{"location":"Research/computer_code.html","text":"Computer Code \u00b6 Notes on the Julia language . The purpose is to document solutions that I could not find in the Julia documentation. Updated periodically. My github repo contains code for recent projects. Newer code is written in Julia. Pre-2019 code is written in Matlab. The shared repo contains general purpose Matlab code. This is no longer updated. Making this code available is a small attempt at reducing duplication, given that economics lacks a code archive . Feel free to use my code in your research (with attribution, where appropriate). Related material: General notes on programming and Matlab Spring 2016 Econ821 course Replication code for Manuelli and Seshadri, \"Human Capital and the Wealth of Nations\", AER 2014 (Their original code as published on the AER web site contains a substantial error. The authors have confirmed this to me.) External Links \u00b6 Chris Carroll's notes on dynamic programming","title":"Computer code"},{"location":"Research/computer_code.html#computer-code","text":"Notes on the Julia language . The purpose is to document solutions that I could not find in the Julia documentation. Updated periodically. My github repo contains code for recent projects. Newer code is written in Julia. Pre-2019 code is written in Matlab. The shared repo contains general purpose Matlab code. This is no longer updated. Making this code available is a small attempt at reducing duplication, given that economics lacks a code archive . Feel free to use my code in your research (with attribution, where appropriate). Related material: General notes on programming and Matlab Spring 2016 Econ821 course Replication code for Manuelli and Seshadri, \"Human Capital and the Wealth of Nations\", AER 2014 (Their original code as published on the AER web site contains a substantial error. The authors have confirmed this to me.)","title":"Computer Code"},{"location":"Research/computer_code.html#external-links","text":"Chris Carroll's notes on dynamic programming","title":"External Links"},{"location":"Research/project_ideas.html","text":"{{../markdown_header.txt}} Some Ideas for Dissertation Projects \u00b6 This page contains a collection of ideas that may be useful for getting started on dissertation research. Talk to me if any of these sound interesting. Disclaimer : I haven't thought about these ideas carefully, so they may not be good ideas. Or they may have been done (note the date next to each idea). Or they may not be doable. Or boring, or fundamentally mistaken, or any of the other things that tend to derail research projects. Don't take the ideas as given. Use them to get started thinking about a set of questions. Some general tips for getting started with a dissertation are here . Human Capital \u00b6 Why did schooling stop rising in 1950? (10/08) \u00b6 U.S. educational attainment rose smoothly from at least 1900 to 1950. Then it stopped rising. Why? And why did schooling rise in the first place (some recent papers offer answers, but do I believe them?)? The Ag/Non-Ag or Urban-Rural Wage Gap ## (2015-05) \u00b6 Wages in non-ag are double those in ag. Wages in cities are higher than in villages (by how much?). Some papers suggest reasons. For example, Lagakos and Waugh (2013 AER) argue that selection is important. But nobody seems to use much data to study these questions. To me, this calls for panel data. One could observe the wage changes as a given person migrates from ag to non-ag. Taxation with risky human capital (6/01) \u00b6 A large literature studies how human capital responds to taxation. Almost all of this literature abstracts from most uncertainty (about earnings etc.). It seems obvious that this abstraction should lead to overstated tax effects (use the intuition from portfolio choice). It would be useful to quantify how large that bias is. This would require embedding realistic earnings uncertainty into a standard life-cycle model with schooling and job-training. It would also be nice to have some analytical results about the effect of uncertainty on tax elasticities in simpler models. A word of caution: There are a couple of papers looking at human capital under uncertainty, though it seems nobody has looked at this particular question. This needs to be checked, though. Why is schooling lumpy? (12/07) \u00b6 In virtually all theories of human capital, years of schooling are a continuous choice. In the data, the choice is lumpy (high school graduate or dropout). Why is schooling lumpy? Why is there a big (presumably permanent) earnings penalty for dropping out of college after 3 years with a good GPA? What can be learned about how human capital is produced and valued in the market? Does this have to do with the fact that grades are a noisy signal of ability? Why is grade completion a better signal?","title":"Project ideas"},{"location":"Research/project_ideas.html#some-ideas-for-dissertation-projects","text":"This page contains a collection of ideas that may be useful for getting started on dissertation research. Talk to me if any of these sound interesting. Disclaimer : I haven't thought about these ideas carefully, so they may not be good ideas. Or they may have been done (note the date next to each idea). Or they may not be doable. Or boring, or fundamentally mistaken, or any of the other things that tend to derail research projects. Don't take the ideas as given. Use them to get started thinking about a set of questions. Some general tips for getting started with a dissertation are here .","title":"Some Ideas for Dissertation Projects"},{"location":"Research/project_ideas.html#human-capital","text":"","title":"Human Capital"},{"location":"Research/project_ideas.html#why-did-schooling-stop-rising-in-1950-1008","text":"U.S. educational attainment rose smoothly from at least 1900 to 1950. Then it stopped rising. Why? And why did schooling rise in the first place (some recent papers offer answers, but do I believe them?)?","title":"Why did schooling stop rising in 1950? (10/08)"},{"location":"Research/project_ideas.html#the-agnon-ag-or-urban-rural-wage-gap-2015-05","text":"Wages in non-ag are double those in ag. Wages in cities are higher than in villages (by how much?). Some papers suggest reasons. For example, Lagakos and Waugh (2013 AER) argue that selection is important. But nobody seems to use much data to study these questions. To me, this calls for panel data. One could observe the wage changes as a given person migrates from ag to non-ag.","title":"The Ag/Non-Ag or Urban-Rural Wage Gap ## (2015-05)"},{"location":"Research/project_ideas.html#taxation-with-risky-human-capital-601","text":"A large literature studies how human capital responds to taxation. Almost all of this literature abstracts from most uncertainty (about earnings etc.). It seems obvious that this abstraction should lead to overstated tax effects (use the intuition from portfolio choice). It would be useful to quantify how large that bias is. This would require embedding realistic earnings uncertainty into a standard life-cycle model with schooling and job-training. It would also be nice to have some analytical results about the effect of uncertainty on tax elasticities in simpler models. A word of caution: There are a couple of papers looking at human capital under uncertainty, though it seems nobody has looked at this particular question. This needs to be checked, though.","title":"Taxation with risky human capital (6/01)"},{"location":"Research/project_ideas.html#why-is-schooling-lumpy-1207","text":"In virtually all theories of human capital, years of schooling are a continuous choice. In the data, the choice is lumpy (high school graduate or dropout). Why is schooling lumpy? Why is there a big (presumably permanent) earnings penalty for dropping out of college after 3 years with a good GPA? What can be learned about how human capital is produced and valued in the market? Does this have to do with the fact that grades are a noisy signal of ability? Why is grade completion a better signal?","title":"Why is schooling lumpy? (12/07)"},{"location":"Research/research.html","text":"Research: Human Capital \u00b6 Current working papers \u00b6 Selective College Admissions: Implications for Equity and Efficiency \u00b6 With Oksana Leukhina and Tatyana Koreshkova . Paper coming soon. Skilled Labor Productivity and Cross-country Income Differences \u00b6 With Todd Schoellman . Slides (R&R AEJ-Macro) Accounting for the Evolution of U.S. Wage Inequality [soin] \u00b6 2013-May-10. Bibtex citation Publications \u00b6 College Quality and Attendance Patterns: A Long-run View \u00b6 With Chris Herrington and Todd Schoellman | American Economic Journal - Macroeconomics, 2021 . Bibtex entry Summary in \"The Region\" Human Capital and Development Accounting: New Evidence From Immigrant Earnings \u00b6 With Todd Schoellman , QJE , 2018 | Bibtex entry The Return to College: Selection and Dropout Risk \u00b6 With Oksana Leukhina | 2018, International Economic Review | Online Appendix | Bibtex citation How Risky Is College Investment? \u00b6 With Oksana Leukhina | 2017, Review of Economic Dynamics | Bibtex citation Student Abilities During the Expansion of U.S. Education [ability] \u00b6 With Todd Schoellman . Journal of Monetary Economics , 36: 19-36, 2014. Appendix . Bibtex citation Cross-country Variation in Educational Attainment: Structural Change or Within Industry Skill Upgrading? [hdind] \u00b6 Journal of Economic Growth 15(3), 2010. Bibtex citation . IPUMS Validation paper . Mapping from country specific to detailed industries . The Skill Composition of U.S. Cities [hc_cities] \u00b6 International Economic Review 52(1): 1-32, 2011. Bibtex citation Previous title: Educational attainment in U.S. cities. Taxation and Human Capital Accumulation \u00b6 Macroeconomic Dynamics 2004, 8(3) Paper . Bibtex citation Taxation and the Intergenerational Transmission of Human Capital \u00b6 Journal of Economics Dynamics and Control 2003, 27(9): 1639-1662. Paper . Bibtex citation How Important is Human Capital for Development? Evidence from Immigrant Earnings \u00b6 American Economic Review 2002, 92(1): 198-219. Bibtex citation . Technical Appendix . Data table with Mincer regressions and other source country data (MS Excel format). How Do Taxes Affect Human Capital? The Role of Intergenerational Mobility [hctax] \u00b6 Review of Economic Dynamics 2001, 4(3): 695-735. Technical Appendix | Bibtex citation Growth, Death, and Taxes [gdtax] \u00b6 Review of Economic Dynamics 2001, 4(1): 26-57. Bibtex citation Taxation and Long-Run Growth \u00b6 Journal of Monetary Economics , 1999, (43)2: 411-434. Bibtex citation The Technical Appendix contains details on computation and analytics. Program files are available in the following zip files: Main program files Shared program files Older working papers \u00b6 The Ben-Porath Model and Age-wage Profiles [ojttech] \u00b6 2012-Nov-27. Bibtex citation The Evolution of U.S. Wages: Skill Prices versus Human Capital \u00b6 2012-Feb-23. Bibtex citation Why Does Education Differ Across Countries? [scd_paper] \u00b6 Paper (First draft: March 2005). Bibtex citation Discussions \u00b6 MisMatch in Human Capital Accumulation","title":"Human capital"},{"location":"Research/research.html#research-human-capital","text":"","title":"Research: Human Capital"},{"location":"Research/research.html#current-working-papers","text":"","title":"Current working papers"},{"location":"Research/research.html#selective-college-admissions-implications-for-equity-and-efficiency","text":"With Oksana Leukhina and Tatyana Koreshkova . Paper coming soon.","title":"Selective College Admissions: Implications for Equity and Efficiency"},{"location":"Research/research.html#skilled-labor-productivity-and-cross-country-income-differences","text":"With Todd Schoellman . Slides (R&R AEJ-Macro)","title":"Skilled Labor Productivity and Cross-country Income Differences"},{"location":"Research/research.html#accounting-for-the-evolution-of-us-wage-inequality-soin","text":"2013-May-10. Bibtex citation","title":"Accounting for the Evolution of U.S. Wage Inequality [soin]"},{"location":"Research/research.html#publications","text":"","title":"Publications"},{"location":"Research/research.html#college-quality-and-attendance-patterns-a-long-run-view","text":"With Chris Herrington and Todd Schoellman | American Economic Journal - Macroeconomics, 2021 . Bibtex entry Summary in \"The Region\"","title":"College Quality and Attendance Patterns: A Long-run View"},{"location":"Research/research.html#human-capital-and-development-accounting-new-evidence-from-immigrant-earnings","text":"With Todd Schoellman , QJE , 2018 | Bibtex entry","title":"Human Capital and Development Accounting: New Evidence From Immigrant Earnings"},{"location":"Research/research.html#the-return-to-college-selection-and-dropout-risk","text":"With Oksana Leukhina | 2018, International Economic Review | Online Appendix | Bibtex citation","title":"The Return to College: Selection and Dropout Risk"},{"location":"Research/research.html#how-risky-is-college-investment","text":"With Oksana Leukhina | 2017, Review of Economic Dynamics | Bibtex citation","title":"How Risky Is College Investment?"},{"location":"Research/research.html#student-abilities-during-the-expansion-of-us-education-ability","text":"With Todd Schoellman . Journal of Monetary Economics , 36: 19-36, 2014. Appendix . Bibtex citation","title":"Student Abilities During the Expansion of U.S. Education [ability]"},{"location":"Research/research.html#cross-country-variation-in-educational-attainment-structural-change-or-within-industry-skill-upgrading-hdind","text":"Journal of Economic Growth 15(3), 2010. Bibtex citation . IPUMS Validation paper . Mapping from country specific to detailed industries .","title":"Cross-country Variation in Educational Attainment: Structural Change or Within Industry Skill Upgrading? [hdind]"},{"location":"Research/research.html#the-skill-composition-of-us-cities-hc_cities","text":"International Economic Review 52(1): 1-32, 2011. Bibtex citation Previous title: Educational attainment in U.S. cities.","title":"The Skill Composition of U.S. Cities [hc_cities]"},{"location":"Research/research.html#taxation-and-human-capital-accumulation","text":"Macroeconomic Dynamics 2004, 8(3) Paper . Bibtex citation","title":"Taxation and Human Capital Accumulation"},{"location":"Research/research.html#taxation-and-the-intergenerational-transmission-of-human-capital","text":"Journal of Economics Dynamics and Control 2003, 27(9): 1639-1662. Paper . Bibtex citation","title":"Taxation and the Intergenerational Transmission of Human Capital"},{"location":"Research/research.html#how-important-is-human-capital-for-development-evidence-from-immigrant-earnings","text":"American Economic Review 2002, 92(1): 198-219. Bibtex citation . Technical Appendix . Data table with Mincer regressions and other source country data (MS Excel format).","title":"How Important is Human Capital for Development? Evidence from Immigrant Earnings"},{"location":"Research/research.html#how-do-taxes-affect-human-capital-the-role-of-intergenerational-mobility-hctax","text":"Review of Economic Dynamics 2001, 4(3): 695-735. Technical Appendix | Bibtex citation","title":"How Do Taxes Affect Human Capital? The Role of Intergenerational Mobility [hctax]"},{"location":"Research/research.html#growth-death-and-taxes-gdtax","text":"Review of Economic Dynamics 2001, 4(1): 26-57. Bibtex citation","title":"Growth, Death, and Taxes [gdtax]"},{"location":"Research/research.html#taxation-and-long-run-growth","text":"Journal of Monetary Economics , 1999, (43)2: 411-434. Bibtex citation The Technical Appendix contains details on computation and analytics. Program files are available in the following zip files: Main program files Shared program files","title":"Taxation and Long-Run Growth"},{"location":"Research/research.html#older-working-papers","text":"","title":"Older working papers"},{"location":"Research/research.html#the-ben-porath-model-and-age-wage-profiles-ojttech","text":"2012-Nov-27. Bibtex citation","title":"The Ben-Porath Model and Age-wage Profiles [ojttech]"},{"location":"Research/research.html#the-evolution-of-us-wages-skill-prices-versus-human-capital","text":"2012-Feb-23. Bibtex citation","title":"The Evolution of U.S. Wages: Skill Prices versus Human Capital"},{"location":"Research/research.html#why-does-education-differ-across-countries-scd_paper","text":"Paper (First draft: March 2005). Bibtex citation","title":"Why Does Education Differ Across Countries? [scd_paper]"},{"location":"Research/research.html#discussions","text":"MisMatch in Human Capital Accumulation","title":"Discussions"},{"location":"Research/research_other.html","text":"Wealth Distribution \u00b6 Retirement wealth and lifetime earnings \u00b6 International Economic Review , 2007, 48(2): 421-56. Bibtex citation How Important Is Discount Rate Heterogeneity for Wealth Inequality? \u00b6 Journal of Economic Dynamics & Control , 2007, 31(9): 3042-68. Bibtex citation Intended and Accidental Bequests in a Life-cycle Economy \u00b6 This paper studies quantitative importance of accidental versus intended bequests. The main finding is that accidental bequests account for at least half, and perhaps for all of observed bequests. Paper [First draft: August 2001] Bequests and Retirement Wealth in U.S. Data \u00b6 This is a background paper for \u201cIntended and Accidental Bequests in a Life-cycle Economy.\u201d It documents bequests and retirement wealth in the SCF and the PSID. Paper | Tables Other Topics \u00b6 Accounting for Changing Returns to Experience \u00b6 BEJM 2018 . Proposes a simple model with time-invariant age-efficiency profiles to account for changing returns to experience in CPS data. Paper | Bibtex citation | Code and additional results Constructing Age-Earnings Profiles From CPS Data \u00b6 Describes procedures for constructing age-wage profiles from March CPS data. Intended as documentation for the data used in several of my projects. The code is available on github . Paper | Bibtex entry Validation of IPUMS International Industry and Education Data \u00b6 This document collects validation information for selected samples of the IPUMS International dataset. The focus is on industry and education data. Paper (2010-Feb) The Intergenerational Persistence of Lifetime Earnings \u00b6 European Economic Review , 2007, 51: 125-44.","title":"Other topics"},{"location":"Research/research_other.html#wealth-distribution","text":"","title":"Wealth Distribution"},{"location":"Research/research_other.html#retirement-wealth-and-lifetime-earnings","text":"International Economic Review , 2007, 48(2): 421-56. Bibtex citation","title":"Retirement wealth and lifetime earnings"},{"location":"Research/research_other.html#how-important-is-discount-rate-heterogeneity-for-wealth-inequality","text":"Journal of Economic Dynamics & Control , 2007, 31(9): 3042-68. Bibtex citation","title":"How Important Is Discount Rate Heterogeneity for Wealth Inequality?"},{"location":"Research/research_other.html#intended-and-accidental-bequests-in-a-life-cycle-economy","text":"This paper studies quantitative importance of accidental versus intended bequests. The main finding is that accidental bequests account for at least half, and perhaps for all of observed bequests. Paper [First draft: August 2001]","title":"Intended and Accidental Bequests in a Life-cycle Economy"},{"location":"Research/research_other.html#bequests-and-retirement-wealth-in-us-data","text":"This is a background paper for \u201cIntended and Accidental Bequests in a Life-cycle Economy.\u201d It documents bequests and retirement wealth in the SCF and the PSID. Paper | Tables","title":"Bequests and Retirement Wealth in U.S. Data"},{"location":"Research/research_other.html#other-topics","text":"","title":"Other Topics"},{"location":"Research/research_other.html#accounting-for-changing-returns-to-experience","text":"BEJM 2018 . Proposes a simple model with time-invariant age-efficiency profiles to account for changing returns to experience in CPS data. Paper | Bibtex citation | Code and additional results","title":"Accounting for Changing Returns to Experience"},{"location":"Research/research_other.html#constructing-age-earnings-profiles-from-cps-data","text":"Describes procedures for constructing age-wage profiles from March CPS data. Intended as documentation for the data used in several of my projects. The code is available on github . Paper | Bibtex entry","title":"Constructing Age-Earnings Profiles From CPS Data"},{"location":"Research/research_other.html#validation-of-ipums-international-industry-and-education-data","text":"This document collects validation information for selected samples of the IPUMS International dataset. The focus is on industry and education data. Paper (2010-Feb)","title":"Validation of IPUMS International Industry and Education Data"},{"location":"Research/research_other.html#the-intergenerational-persistence-of-lifetime-earnings","text":"European Economic Review , 2007, 51: 125-44.","title":"The Intergenerational Persistence of Lifetime Earnings"},{"location":"econ520/econ520.html","text":"Econ520 - Advanced Macroeconomic Theory \u00b6 Spring 2021 - Prof. Lutz Hendricks \u00b6 Announcements \u00b6 Syllabus Midterm exam: Oct-5 (in class). Material covered up to (including) trade deficits (but not the open economy models). Sep-17: Everyone should have contacted me about the term paper by now. If you have not, please do so soon! By week 6 (Sep-23) , each student should send me a list of 5 references with a brief summary of the main arguments, pro and con, on their chosen topic. There is now a sakai site ; to be used in the future for posting grades. It also contains a discussion forum where you can post questions and answers. Important: you must have passed Intermediate Macroeconomics to register for this course. Important: students who do not attend the first week of classes will be dropped from the course. This is department policy. Please contact me if you need an accomodation. Slides will be updated as the course progresses. Final exam: Dec-7, noon Tips for taking exams Of potential interest: Business Today's 47th International Conference . Internships with NCPIRG Schedule of Classes \u00b6 No class on Oct-12 (University Day), Oct-21 (fall break), Nov-25 (Thanksgiving). Short Run \u00b6 Aug-19 (Thu): Introduction , IS-LM model (each of these links leads to the slides that were used in class) Aug-24 (Tue): IS/LM Equilibrium , PP ( PP means \"practice problems\"; for your enjoyment; not to be handed in) Aug-26 (Thu): IS/LM Equilibrium (cont.) Aug-31 (Tue): The term paper , Monetary Policy Sep-2 (Thu): Fiscal Deficits , PP Medium Run \u00b6 Sep-7 (Tue): Labor market , PP Sep-9 (Thu): Labor market (continued) Sep-14 (Tue): AS-AD model , PP (covers Phillips Curve) Sep-16 (Thu): AS-AD model (continued) Sep-21 (Tue): AS-AD model (continued) Sep-23 (Thu): Inflation and unemployment Sep-28 (Tue): Inflation expectations and monetary policy , PP Open Economy \u00b6 Sep-30 (Thu): Trade deficits , PP Oct-7 (Thu): Trade deficits (continued) Oct-14 (Thu): IS-LM model , PP Oct-19 (Tue): IS-LM floating exchange rate Oct-26 (Tue): IS-LM fixed exchange rate Oct-28 (Thu): AS-AD model , Policy analysis , PP Nov-2 (Tue): Costs and benefits of international trade , Model summary Inequality \u00b6 Nov-4 (Thu): Inequality facts , Earnings inequality Nov-9 (Tue): The top 1 percent , Intergenerational mobility Long-run Growth \u00b6 Nov-11 (Thu): Growth facts , Institutions , PP Nov-16 (Tue): Growth and ideas Nov-18 (Thu): Romer model , PP Nov-23 (Tue): Policy implications Nov-30 (Tue): Last class. All questions answered! (or almost all...).","title":"Econ520"},{"location":"econ520/econ520.html#econ520-advanced-macroeconomic-theory","text":"","title":"Econ520 - Advanced Macroeconomic Theory"},{"location":"econ520/econ520.html#spring-2021-prof-lutz-hendricks","text":"","title":"Spring 2021 - Prof. Lutz Hendricks"},{"location":"econ520/econ520.html#announcements","text":"Syllabus Midterm exam: Oct-5 (in class). Material covered up to (including) trade deficits (but not the open economy models). Sep-17: Everyone should have contacted me about the term paper by now. If you have not, please do so soon! By week 6 (Sep-23) , each student should send me a list of 5 references with a brief summary of the main arguments, pro and con, on their chosen topic. There is now a sakai site ; to be used in the future for posting grades. It also contains a discussion forum where you can post questions and answers. Important: you must have passed Intermediate Macroeconomics to register for this course. Important: students who do not attend the first week of classes will be dropped from the course. This is department policy. Please contact me if you need an accomodation. Slides will be updated as the course progresses. Final exam: Dec-7, noon Tips for taking exams Of potential interest: Business Today's 47th International Conference . Internships with NCPIRG","title":"Announcements"},{"location":"econ520/econ520.html#schedule-of-classes","text":"No class on Oct-12 (University Day), Oct-21 (fall break), Nov-25 (Thanksgiving).","title":"Schedule of Classes"},{"location":"econ520/econ520.html#short-run","text":"Aug-19 (Thu): Introduction , IS-LM model (each of these links leads to the slides that were used in class) Aug-24 (Tue): IS/LM Equilibrium , PP ( PP means \"practice problems\"; for your enjoyment; not to be handed in) Aug-26 (Thu): IS/LM Equilibrium (cont.) Aug-31 (Tue): The term paper , Monetary Policy Sep-2 (Thu): Fiscal Deficits , PP","title":"Short Run"},{"location":"econ520/econ520.html#medium-run","text":"Sep-7 (Tue): Labor market , PP Sep-9 (Thu): Labor market (continued) Sep-14 (Tue): AS-AD model , PP (covers Phillips Curve) Sep-16 (Thu): AS-AD model (continued) Sep-21 (Tue): AS-AD model (continued) Sep-23 (Thu): Inflation and unemployment Sep-28 (Tue): Inflation expectations and monetary policy , PP","title":"Medium Run"},{"location":"econ520/econ520.html#open-economy","text":"Sep-30 (Thu): Trade deficits , PP Oct-7 (Thu): Trade deficits (continued) Oct-14 (Thu): IS-LM model , PP Oct-19 (Tue): IS-LM floating exchange rate Oct-26 (Tue): IS-LM fixed exchange rate Oct-28 (Thu): AS-AD model , Policy analysis , PP Nov-2 (Tue): Costs and benefits of international trade , Model summary","title":"Open Economy"},{"location":"econ520/econ520.html#inequality","text":"Nov-4 (Thu): Inequality facts , Earnings inequality Nov-9 (Tue): The top 1 percent , Intergenerational mobility","title":"Inequality"},{"location":"econ520/econ520.html#long-run-growth","text":"Nov-11 (Thu): Growth facts , Institutions , PP Nov-16 (Tue): Growth and ideas Nov-18 (Thu): Romer model , PP Nov-23 (Tue): Policy implications Nov-30 (Tue): Last class. All questions answered! (or almost all...).","title":"Long-run Growth"},{"location":"econ520/schedule.html","text":"Short Run \u00b6 Aug-19 (Thu): IS-LM model Aug-24 (Tue): Equilibrium , PP Medium Run \u00b6 Aug-26 (Thu): Labor market , PP Aug-31 (Tue): Labor market (continued) Sep-2 (Thu): AS-AD model , PP (covers Phillips Curve) Sep-7 (Tue): AS-AD model (continued) Sep-9 (Thu): AS-AD model (continued) Sep-14 (Tue): Inflation and unemployment Sep-16 (Thu): Inflation expectations and monetary policy , PP Open Economy \u00b6 Sep-21 (Tue): Trade deficits , PP Sep-23 (Thu): Trade deficits (continued) Sep-28 (Tue): IS-LM model , PP Sep-30 (Thu): IS-LM floating exchange rate Oct-5 (Tue): IS-LM fixed exchange rate Oct-7 (Thu): AS-AD model , Policy analysis , PP Oct-12 (Tue): Costs and benefits of international trade Expectations \u00b6 Oct-14 (Thu): Last class. Model summary . All questions answered! (or almost all...).","title":"Schedule"},{"location":"econ520/schedule.html#short-run","text":"Aug-19 (Thu): IS-LM model Aug-24 (Tue): Equilibrium , PP","title":"Short Run"},{"location":"econ520/schedule.html#medium-run","text":"Aug-26 (Thu): Labor market , PP Aug-31 (Tue): Labor market (continued) Sep-2 (Thu): AS-AD model , PP (covers Phillips Curve) Sep-7 (Tue): AS-AD model (continued) Sep-9 (Thu): AS-AD model (continued) Sep-14 (Tue): Inflation and unemployment Sep-16 (Thu): Inflation expectations and monetary policy , PP","title":"Medium Run"},{"location":"econ520/schedule.html#open-economy","text":"Sep-21 (Tue): Trade deficits , PP Sep-23 (Thu): Trade deficits (continued) Sep-28 (Tue): IS-LM model , PP Sep-30 (Thu): IS-LM floating exchange rate Oct-5 (Tue): IS-LM fixed exchange rate Oct-7 (Thu): AS-AD model , Policy analysis , PP Oct-12 (Tue): Costs and benefits of international trade","title":"Open Economy"},{"location":"econ520/schedule.html#expectations","text":"Oct-14 (Thu): Last class. Model summary . All questions answered! (or almost all...).","title":"Expectations"},{"location":"econ520/schedule520.html","text":"Short Run \u00b6 Aug-19 (Thu): Introduction , IS-LM model (each of these links leads to the slides that were used in class) Aug-24 (Tue): IS/LM Equilibrium , PP ( PP means \"practice problems\"; for your enjoyment; not to be handed in) Aug-26 (Thu): IS/LM Equilibrium (cont.) Aug-31 (Tue): The term paper , Monetary Policy Sep-2 (Thu): Fiscal Deficits , PP Medium Run \u00b6 Sep-7 (Tue): Labor market , PP Sep-9 (Thu): Labor market (continued) Sep-14 (Tue): AS-AD model , PP (covers Phillips Curve) Sep-16 (Thu): AS-AD model (continued) Sep-21 (Tue): AS-AD model (continued) Sep-23 (Thu): Inflation and unemployment Sep-28 (Tue): Inflation expectations and monetary policy , PP Open Economy \u00b6 Sep-30 (Thu): Trade deficits , PP Oct-7 (Thu): Trade deficits (continued) Oct-14 (Thu): IS-LM model , PP Oct-19 (Tue): IS-LM floating exchange rate Oct-26 (Tue): IS-LM fixed exchange rate Oct-28 (Thu): AS-AD model , Policy analysis , PP Nov-2 (Tue): Costs and benefits of international trade , Model summary Inequality \u00b6 Nov-4 (Thu): Inequality facts , Earnings inequality Nov-9 (Tue): The top 1 percent , Intergenerational mobility Long-run Growth \u00b6 Nov-11 (Thu): Growth facts , Institutions , PP Nov-16 (Tue): Growth and ideas Nov-18 (Thu): Romer model , PP Nov-23 (Tue): Policy implications Nov-30 (Tue): Last class. All questions answered! (or almost all...).","title":"Schedule520"},{"location":"econ520/schedule520.html#short-run","text":"Aug-19 (Thu): Introduction , IS-LM model (each of these links leads to the slides that were used in class) Aug-24 (Tue): IS/LM Equilibrium , PP ( PP means \"practice problems\"; for your enjoyment; not to be handed in) Aug-26 (Thu): IS/LM Equilibrium (cont.) Aug-31 (Tue): The term paper , Monetary Policy Sep-2 (Thu): Fiscal Deficits , PP","title":"Short Run"},{"location":"econ520/schedule520.html#medium-run","text":"Sep-7 (Tue): Labor market , PP Sep-9 (Thu): Labor market (continued) Sep-14 (Tue): AS-AD model , PP (covers Phillips Curve) Sep-16 (Thu): AS-AD model (continued) Sep-21 (Tue): AS-AD model (continued) Sep-23 (Thu): Inflation and unemployment Sep-28 (Tue): Inflation expectations and monetary policy , PP","title":"Medium Run"},{"location":"econ520/schedule520.html#open-economy","text":"Sep-30 (Thu): Trade deficits , PP Oct-7 (Thu): Trade deficits (continued) Oct-14 (Thu): IS-LM model , PP Oct-19 (Tue): IS-LM floating exchange rate Oct-26 (Tue): IS-LM fixed exchange rate Oct-28 (Thu): AS-AD model , Policy analysis , PP Nov-2 (Tue): Costs and benefits of international trade , Model summary","title":"Open Economy"},{"location":"econ520/schedule520.html#inequality","text":"Nov-4 (Thu): Inequality facts , Earnings inequality Nov-9 (Tue): The top 1 percent , Intergenerational mobility","title":"Inequality"},{"location":"econ520/schedule520.html#long-run-growth","text":"Nov-11 (Thu): Growth facts , Institutions , PP Nov-16 (Tue): Growth and ideas Nov-18 (Thu): Romer model , PP Nov-23 (Tue): Policy implications Nov-30 (Tue): Last class. All questions answered! (or almost all...).","title":"Long-run Growth"},{"location":"econ520/schedule520_2020.html","text":"Special dates \u00b6 Feb-15 (Mon): Wellness day Mar-10 (Wed): Midterm: Material covered: TBA Apr-05 (Mon): Wellness day Economic Growth \u00b6 Jan-20 (Wed): Growth facts , In case you need a refresher: Growth rates and logarithms , PP (practice problems; previous exams are at the bottom of the page) Jan-25 (Mon): Methods for identifying causes and effects Jan-27 (Wed): The Role of Capital , PP Feb-01 (Mon): The Role of Capital, part 2 Feb-03 (Wed): Solow model Feb-08 (Mon): Solow diagram , PP Feb-10 (Wed): Solow Applications , Applications, part 2 Feb-17 (Wed): Discussion: How to prevent the end of economic growth Feb-22 (Mon): Institutions , PP Feb-24 (Wed): Growth and ideas Mar-01 (Mon): Romer model , PP Policy implications Inequality \u00b6 Mar-03 (Wed): Inequality facts Earnings inequality Mar-08 (Mon): The top 1 percent Intergenerational mobility Short Run \u00b6 Mar-15 (Mon): IS-LM model Mar-17 (Wed): Equilibrium , PP Medium Run \u00b6 Mar-22 (Mon): Labor market , PP Mar-24 (Wed): Labor market (continued) Mar-29 (Mon): AS-AD model , PP (covers Phillips Curve) Mar-31 (Wed): AS-AD model (continued) Apr-07 (Wed): AS-AD model (continued) Apr-12 (Mon): Inflation and unemployment Apr-14 (Wed): Inflation expectations and monetary policy , PP Open Economy \u00b6 Apr-19 (Mon): Trade deficits , PP Apr-21 (Wed): Trade deficits (continued) Apr-26 (Mon): IS-LM model , PP Apr-28 (Wed): IS-LM floating exchange rate IS-LM fixed exchange rate Apr-30 (Fri): AS-AD model , Policy analysis , PP May-03 (Mon): Costs and benefits of international trade Expectations \u00b6 May-05 (Wed): Last class Review: Model summary All questions answered! (or almost all...) \u00b6","title":"Schedule520 2020"},{"location":"econ520/schedule520_2020.html#special-dates","text":"Feb-15 (Mon): Wellness day Mar-10 (Wed): Midterm: Material covered: TBA Apr-05 (Mon): Wellness day","title":"Special dates"},{"location":"econ520/schedule520_2020.html#economic-growth","text":"Jan-20 (Wed): Growth facts , In case you need a refresher: Growth rates and logarithms , PP (practice problems; previous exams are at the bottom of the page) Jan-25 (Mon): Methods for identifying causes and effects Jan-27 (Wed): The Role of Capital , PP Feb-01 (Mon): The Role of Capital, part 2 Feb-03 (Wed): Solow model Feb-08 (Mon): Solow diagram , PP Feb-10 (Wed): Solow Applications , Applications, part 2 Feb-17 (Wed): Discussion: How to prevent the end of economic growth Feb-22 (Mon): Institutions , PP Feb-24 (Wed): Growth and ideas Mar-01 (Mon): Romer model , PP Policy implications","title":"Economic Growth"},{"location":"econ520/schedule520_2020.html#inequality","text":"Mar-03 (Wed): Inequality facts Earnings inequality Mar-08 (Mon): The top 1 percent Intergenerational mobility","title":"Inequality"},{"location":"econ520/schedule520_2020.html#short-run","text":"Mar-15 (Mon): IS-LM model Mar-17 (Wed): Equilibrium , PP","title":"Short Run"},{"location":"econ520/schedule520_2020.html#medium-run","text":"Mar-22 (Mon): Labor market , PP Mar-24 (Wed): Labor market (continued) Mar-29 (Mon): AS-AD model , PP (covers Phillips Curve) Mar-31 (Wed): AS-AD model (continued) Apr-07 (Wed): AS-AD model (continued) Apr-12 (Mon): Inflation and unemployment Apr-14 (Wed): Inflation expectations and monetary policy , PP","title":"Medium Run"},{"location":"econ520/schedule520_2020.html#open-economy","text":"Apr-19 (Mon): Trade deficits , PP Apr-21 (Wed): Trade deficits (continued) Apr-26 (Mon): IS-LM model , PP Apr-28 (Wed): IS-LM floating exchange rate IS-LM fixed exchange rate Apr-30 (Fri): AS-AD model , Policy analysis , PP May-03 (Mon): Costs and benefits of international trade","title":"Open Economy"},{"location":"econ520/schedule520_2020.html#expectations","text":"May-05 (Wed): Last class Review: Model summary","title":"Expectations"},{"location":"econ520/schedule520_2020.html#all-questions-answered-or-almost-all","text":"","title":"All questions answered! (or almost all...)"},{"location":"econ520/syllabus520.html","text":"Econ520 - Syllabus \u00b6 Fall 2021 - Prof. Lutz Hendricks \u00b6 For those planning / buying ahead: the texts will be Charles Jones. Introduction to Economic Growth, 3rd edition, 2013, ISBN-13: 978-0393919172. * The 2nd edition is very similar to the 3rd edition. Optional. Olivier Blanchard. Macroeconomics, 8th ed., Pearson (ISBN-13: 9780136713883) Older editions of both books are ok and could be a lot less expensive. Ebooks are an affordable alternative. You will not need the MyLab access. Class meets: Tue, Thr 2-3:15 Caldwell 103 Check the course web site regularly for updates. It contains contact info, office hours, class times, exam dates, course outline, slides, etc. Course objective: \u00b6 Econ520 develops macroeconomic models and applies them to real world issues. Topics include: Fiscal policy. Monetary policy. Open economy (exchange rates, transmission of shocks across countries). Economic inequality. Long-run growth. Economies are complex systems. To understand them, it is necessary to write down models . Models need not be mathematical; they could be computational. But in this course, since we want to develop an understanding how macro variables interact, the models will be mathematical. An integral part of the course is the term paper . Grading \u00b6 Grades will be based on midterm (40%) final exam (45%) term paper (15%) If a student misses an exam for a good reason, the remaining exam accounts for 85% of the course grade. If a student misses an exam without a good reason, they will receive a score of 0 on that exam. Each exam focuses on the material covered since the last exam. However, as new material builds on previously covered material, anything covered in the course up to the date of the exam is fair game. Cutoffs for letter grades are: A: 85, B: 70, C: 55, D: 45. There will be fractional grades (e.g. A-). How to Study for This Class \u00b6 Much of our time will be spent on analyzing models. There is only one way to learn how to do this: solve lots of practice problems . You will find such problems for each topic we cover posted on the course web page. The exam questions will similar in nature but tend to be shorter than the practice problems. If you feel that you are falling behind or if you have trouble with the practice problems, come to my office hours (listed on my web page). You should also read the textbook sections corresponding to the material we study in class. Additional reading material is listed at the end of the slides. A note on studying and classroom participation: \u00b6 The picture below shows Jean-Marc Cote's vision of the classroom in the year 2000. Unfortunately, this is not how it works... It is extremely important that you work through the practice problems for each section of the course. Also look at previous exams. If you find that you have trouble with these questions, come to my office hours. Source: Social Learning Feedback \u00b6 You can help improve this course by letting me know what you like and what you don't like. Drop me an e-mail or come to my office. Feel free to suggest topics you would like to discuss in class. Policies \u00b6 Please be on time when coming to class. Turn off your cell phones. The professor reserves the right to make changes to the syllabus, including project due dates and test dates. These changes will be announced as early as possible. Prerequisites \u00b6 Students must have passed Econ420 (Intermediate Macroeconomics). Basic calculus (derivatives) will be needed. If you are not comfortable with math or models, this is not the right course for you. Students should work through the math review problems posted on the course web site as soon as possible. Covid-19 \u00b6 This semester, while we are in the midst of a global pandemic, all enrolled students are required to wear a mask covering your mouth and nose at all times in our classroom. This requirement is to protect our educational community \u2014 your classmates and me \u2013 as we learn together. If you choose not to wear a mask, or wear it improperly, I will ask you to leave immediately, and I will submit a report to the Office of Student Conduct . At that point you will be disenrolled from this course for the protection of our educational community. Students who have an authorized accommodation from Accessibility Resources and Service have an exception. For additional information, see* Carolina Together . Attendance Policy \u00b6 No right or privilege exists that permits a student to be absent from any class meetings, except for these University Approved Absences: Authorized University activities Disability/religious observance/pregnancy, as required by law and approved by Accessibility Resources and Service and/or the Equal Opportunity and Compliance Office (EOC) Significant health condition and/or personal/family emergency as approved by the Office of the Dean of Students , Gender Violence Service Coordinators, and/or the Equal Opportunity and Compliance Office (EOC). Honor Code \u00b6 All students are expected to follow the guidelines of the UNC honor code. In particular, students are expected to refrain from \u201clying, cheating, or stealing\u201d in the academic context. If you are unsure about which actions violate that honor code, please see me or consult honor.unc.edu . Accessibility \u00b6 The University of North Carolina at Chapel Hill facilitates the implementation of reasonable accommodations, including resources and services, for students with disabilities, chronic medical conditions, a temporary disability or pregnancy complications resulting in barriers to fully accessing University courses, programs and activities. Accommodations are determined through the Office of Accessibility Resources and Service (ARS) for individuals with documented qualifying disabilities in accordance with applicable state and federal laws. See the ARS Website for contact information: or email ars@unc.edu. Conseling \u00b6 CAPS is strongly committed to addressing the mental health needs of a diverse student body through timely access to consultation and connection to clinically appropriate services, whether for short or long-term needs. Go to their website: https://caps.unc.edu/ or visit their facilities on the third floor of the Campus Health Services building for a walk-in evaluation to learn more. Title IX Resources \u00b6 Any student who is impacted by discrimination, harassment, interpersonal (relationship) violence, sexual violence, sexual exploitation, or stalking is encouraged to seek resources on campus or in the community. Please contact the Director of Title IX Compliance (Adrienne Allison \u2013 Adrienne.allison@unc.edu), Report and Response Coordinators in the Equal Opportunity and Compliance Office (reportandresponse@unc.edu), Counseling and Psychological Services (confidential), or the Gender Violence Services Coordinators (gvsc@unc.edu; confidential) to discuss your specific needs. Additional resources are available at safe.unc.edu. Special consideration \u00b6 Students will not be granted special consideration if they have attempted a piece of assessment and then ask for special consideration. Unless it is impossible for you to do so, you must contact your lecturer before the assessment is due if you expect to miss an assessment task. Failure to do this will weaken your case. Final exams can only be rescheduled by the Academic Dean. If you have a conflict, you need to contact him/her. Past exams \u00b6 (material in early years differs substantially from current year): 2021 Spring: Midterm 2017 Spring: Midterm , final 2016 Spring: Midterm , final 2015 Spring: exam1 , exam2 , final 2013 Fall: exam1 , exam2 , final . 2012 Fall: exam1 , exam2 , final . 2012 Spring: exam1 , exam2 , final . 2010 (course title was Econ499): exam1 , exam2 , final .","title":"Econ520 - Syllabus #"},{"location":"econ520/syllabus520.html#econ520-syllabus","text":"","title":"Econ520 - Syllabus"},{"location":"econ520/syllabus520.html#fall-2021-prof-lutz-hendricks","text":"For those planning / buying ahead: the texts will be Charles Jones. Introduction to Economic Growth, 3rd edition, 2013, ISBN-13: 978-0393919172. * The 2nd edition is very similar to the 3rd edition. Optional. Olivier Blanchard. Macroeconomics, 8th ed., Pearson (ISBN-13: 9780136713883) Older editions of both books are ok and could be a lot less expensive. Ebooks are an affordable alternative. You will not need the MyLab access. Class meets: Tue, Thr 2-3:15 Caldwell 103 Check the course web site regularly for updates. It contains contact info, office hours, class times, exam dates, course outline, slides, etc.","title":"Fall 2021 - Prof. Lutz Hendricks"},{"location":"econ520/syllabus520.html#course-objective","text":"Econ520 develops macroeconomic models and applies them to real world issues. Topics include: Fiscal policy. Monetary policy. Open economy (exchange rates, transmission of shocks across countries). Economic inequality. Long-run growth. Economies are complex systems. To understand them, it is necessary to write down models . Models need not be mathematical; they could be computational. But in this course, since we want to develop an understanding how macro variables interact, the models will be mathematical. An integral part of the course is the term paper .","title":"Course objective:"},{"location":"econ520/syllabus520.html#grading","text":"Grades will be based on midterm (40%) final exam (45%) term paper (15%) If a student misses an exam for a good reason, the remaining exam accounts for 85% of the course grade. If a student misses an exam without a good reason, they will receive a score of 0 on that exam. Each exam focuses on the material covered since the last exam. However, as new material builds on previously covered material, anything covered in the course up to the date of the exam is fair game. Cutoffs for letter grades are: A: 85, B: 70, C: 55, D: 45. There will be fractional grades (e.g. A-).","title":"Grading"},{"location":"econ520/syllabus520.html#how-to-study-for-this-class","text":"Much of our time will be spent on analyzing models. There is only one way to learn how to do this: solve lots of practice problems . You will find such problems for each topic we cover posted on the course web page. The exam questions will similar in nature but tend to be shorter than the practice problems. If you feel that you are falling behind or if you have trouble with the practice problems, come to my office hours (listed on my web page). You should also read the textbook sections corresponding to the material we study in class. Additional reading material is listed at the end of the slides.","title":"How to Study for This Class"},{"location":"econ520/syllabus520.html#a-note-on-studying-and-classroom-participation","text":"The picture below shows Jean-Marc Cote's vision of the classroom in the year 2000. Unfortunately, this is not how it works... It is extremely important that you work through the practice problems for each section of the course. Also look at previous exams. If you find that you have trouble with these questions, come to my office hours. Source: Social Learning","title":"A note on studying and classroom participation:"},{"location":"econ520/syllabus520.html#feedback","text":"You can help improve this course by letting me know what you like and what you don't like. Drop me an e-mail or come to my office. Feel free to suggest topics you would like to discuss in class.","title":"Feedback"},{"location":"econ520/syllabus520.html#policies","text":"Please be on time when coming to class. Turn off your cell phones. The professor reserves the right to make changes to the syllabus, including project due dates and test dates. These changes will be announced as early as possible.","title":"Policies"},{"location":"econ520/syllabus520.html#prerequisites","text":"Students must have passed Econ420 (Intermediate Macroeconomics). Basic calculus (derivatives) will be needed. If you are not comfortable with math or models, this is not the right course for you. Students should work through the math review problems posted on the course web site as soon as possible.","title":"Prerequisites"},{"location":"econ520/syllabus520.html#covid-19","text":"This semester, while we are in the midst of a global pandemic, all enrolled students are required to wear a mask covering your mouth and nose at all times in our classroom. This requirement is to protect our educational community \u2014 your classmates and me \u2013 as we learn together. If you choose not to wear a mask, or wear it improperly, I will ask you to leave immediately, and I will submit a report to the Office of Student Conduct . At that point you will be disenrolled from this course for the protection of our educational community. Students who have an authorized accommodation from Accessibility Resources and Service have an exception. For additional information, see* Carolina Together .","title":"Covid-19"},{"location":"econ520/syllabus520.html#attendance-policy","text":"No right or privilege exists that permits a student to be absent from any class meetings, except for these University Approved Absences: Authorized University activities Disability/religious observance/pregnancy, as required by law and approved by Accessibility Resources and Service and/or the Equal Opportunity and Compliance Office (EOC) Significant health condition and/or personal/family emergency as approved by the Office of the Dean of Students , Gender Violence Service Coordinators, and/or the Equal Opportunity and Compliance Office (EOC).","title":"Attendance Policy"},{"location":"econ520/syllabus520.html#honor-code","text":"All students are expected to follow the guidelines of the UNC honor code. In particular, students are expected to refrain from \u201clying, cheating, or stealing\u201d in the academic context. If you are unsure about which actions violate that honor code, please see me or consult honor.unc.edu .","title":"Honor Code"},{"location":"econ520/syllabus520.html#accessibility","text":"The University of North Carolina at Chapel Hill facilitates the implementation of reasonable accommodations, including resources and services, for students with disabilities, chronic medical conditions, a temporary disability or pregnancy complications resulting in barriers to fully accessing University courses, programs and activities. Accommodations are determined through the Office of Accessibility Resources and Service (ARS) for individuals with documented qualifying disabilities in accordance with applicable state and federal laws. See the ARS Website for contact information: or email ars@unc.edu.","title":"Accessibility"},{"location":"econ520/syllabus520.html#conseling","text":"CAPS is strongly committed to addressing the mental health needs of a diverse student body through timely access to consultation and connection to clinically appropriate services, whether for short or long-term needs. Go to their website: https://caps.unc.edu/ or visit their facilities on the third floor of the Campus Health Services building for a walk-in evaluation to learn more.","title":"Conseling"},{"location":"econ520/syllabus520.html#title-ix-resources","text":"Any student who is impacted by discrimination, harassment, interpersonal (relationship) violence, sexual violence, sexual exploitation, or stalking is encouraged to seek resources on campus or in the community. Please contact the Director of Title IX Compliance (Adrienne Allison \u2013 Adrienne.allison@unc.edu), Report and Response Coordinators in the Equal Opportunity and Compliance Office (reportandresponse@unc.edu), Counseling and Psychological Services (confidential), or the Gender Violence Services Coordinators (gvsc@unc.edu; confidential) to discuss your specific needs. Additional resources are available at safe.unc.edu.","title":"Title IX Resources"},{"location":"econ520/syllabus520.html#special-consideration","text":"Students will not be granted special consideration if they have attempted a piece of assessment and then ask for special consideration. Unless it is impossible for you to do so, you must contact your lecturer before the assessment is due if you expect to miss an assessment task. Failure to do this will weaken your case. Final exams can only be rescheduled by the Academic Dean. If you have a conflict, you need to contact him/her.","title":"Special consideration"},{"location":"econ520/syllabus520.html#past-exams","text":"(material in early years differs substantially from current year): 2021 Spring: Midterm 2017 Spring: Midterm , final 2016 Spring: Midterm , final 2015 Spring: exam1 , exam2 , final 2013 Fall: exam1 , exam2 , final . 2012 Fall: exam1 , exam2 , final . 2012 Spring: exam1 , exam2 , final . 2010 (course title was Econ499): exam1 , exam2 , final .","title":"Past exams"},{"location":"econ520/term_paper.html","text":"Econ520 - Term Paper \u00b6 Fall 2021 - Prof. Lutz Hendricks \u00b6 The term paper picks a topic, critically reviews the literature, and clearly lays out arguments on both sides of the debate. The final version of the paper is due by the last class meeting. Learning objectives: Find, select, and organize a literature. Summarize arguments concisely, but in such a way that the reader understands how each argument is supported. Practice scientific writing. Timeline \u00b6 We will devote part of a class to questions such as: 1. What makes a good topic? 2. How to find literature? 3. How to summarize opposing arguments so that the reader can understand how each argument is supported. Timeline: By week 4, each student picks a topic. By week 6, each student has collected at least 5 references that represent both sides of the debate at an appropriate level. By the week after the midterm, each student submits an outline of the main arguments. As you write / develop your argument, you should get in touch with me periodically to make sure everything is on track (and to clarify questions). Please provide all files in pdf format (not MS Word). I do not need hardcopies. Expectations \u00b6 The paper should demonstrate understanding of the literature lay out arguments on both sides of a debate. give the reader an idea about how the cited studies reached their conclusions give an idea of magnitudes. Macro questions are often about quantifying tradeoffs. For example, it is obvious that more progressive taxes reduce inequality. But is this a big or small effect? I do not expect innovation, modeling, theory, or original data work. that you read academic journal articles (though you should try). that you reach a conclusion. If the experts disagree, I don't expect you to figure it out. There is no prescribed length. Obviously, you don't want to hand in 2 pages. Examples of well-written term papers: Negative interest rates , Racial inequality . These were done during a semester when the students spent less time on their papers. I expect more depth than these. Notes on Writing \u00b6 Cite your sources. When you make a claim, back it up. Use scientific citation styles. In the text: \"Smith (2020) says Blah.\" In the bibliography: \"Smith, Martin (2020). The Title. Journal of Economic Perspectives 3(4): 15-20\". Nice words come last. First decide what you want to write. Outline that. When you are happy with the substance, fill in the words. Visual structure. There should be (sub-)headings that let the reader see at a glance how the document is structured. Explain how conclusions are reached. Saying \"A study by X showed that increasing top marginal taxes reduce income inequality by Y\" is not all that informative by itself. How was that conclusion reached? Why do other studies disagree? Weave a narrative. You don't want a laundry list of \"A says X, B says Y, ...\". Instead, it is better to have: \"The main disagreements are about X and Y. On X, A says XA and backs it up as follows ... But B says XB and supports it as follows ...\" Related: Rather than separately summarizing the arguments pro and con, it is usually better to summarize how both sides view each argument. Example : Do minimum wages cost a lot of jobs? A con argument (no pun intended) may be: we don't see evidence in cities that have increased minimum wages. Those who hold the pro view may counter: there is a selection problem. Only cities where employment effects are small raise minimum wages. What Makes a Good Topic? \u00b6 We are looking for a question that is under active debate. The topic needs to be fairly narrow. Examples: Too broad: Why did income inequality rise over time? Better: Focus on one cause, such as international trade. Perhaps even narrow it to trade with China. Too broad: What are the implications of a flat tax? Better: Would a flat tax substantially increase income inequality? Assignment: Think about a potential topic that interests you (not listed here). We will debate its merits and look for literature. Possible Topics (but You May Choose Your Own) \u00b6 Below I list potential topics. They are generally phrased more broadly than what you would choose for a term paper. Growth: \u00b6 Do we need patent protection for innovation to occur? Why has manufacturing declined in the U.S. (international trade, technical change, ...)? Do certain policies stimulate long-run growth? Examples include tax cuts, deregulation, free trade agreements. Business cycles: \u00b6 Why was wage growth so slow during the recovery after the Great Recession? Fiscal policy: \u00b6 What are the limits to government debt? Will interest rates remain low for a long time? Do tax cuts pay for themselves? Are taxes the reason that Europeans work so much less than Americans? Monetary policy: \u00b6 Should the Fed target asset prices? Can the Fed pursue unconventional monetary policies (QE, asset purchases) forever? What are the limits? What will happen when the Fed starts to unwind its QE asset positions? Does QE generate inflation? Inequality: \u00b6 Effects of taxing the rich. Need to focus on specific policies (e.g. progressive income taxes) and specific outcomes (e.g. income distribution). Causes of rising income inequality. Potential policy responses. Labor market polarization: what will happen when more and more jobs get mechanized? Why has the labor share declined over time? What would happen if we taxed bequests? Or wealth? Focus on specific outcomes. Would a minimum wage cause lots of unemployment? Does income support to poor households discourage employment? Open economy: \u00b6 Are exchange rate devaluations expansionary? Why are we running a trade deficit with China? Other: \u00b6 Why did the U.S. saving rate decline over time? Finding Source Material \u00b6 Academic journal articles are generally hard to read. Feel free to look, though, and you will get an idea what professional economists actually do. More accessible references include: World Bank or IMF publications The Journal of Economic Perspectives Brookings Institution Federal Reserve Banks publish articles aimed at explaining research to the general public. Examples are the Economic Letters of the San Francisco Fed. the Economist, NY Times, or Wall Street Journal are fine, but you also want to dig deeper I maintain a short list . I would generally avoid political sources (Heritage Foundation; Congress; Cato Institute).","title":"Econ520 - Term Paper #"},{"location":"econ520/term_paper.html#econ520-term-paper","text":"","title":"Econ520 - Term Paper"},{"location":"econ520/term_paper.html#fall-2021-prof-lutz-hendricks","text":"The term paper picks a topic, critically reviews the literature, and clearly lays out arguments on both sides of the debate. The final version of the paper is due by the last class meeting. Learning objectives: Find, select, and organize a literature. Summarize arguments concisely, but in such a way that the reader understands how each argument is supported. Practice scientific writing.","title":"Fall 2021 - Prof. Lutz Hendricks"},{"location":"econ520/term_paper.html#timeline","text":"We will devote part of a class to questions such as: 1. What makes a good topic? 2. How to find literature? 3. How to summarize opposing arguments so that the reader can understand how each argument is supported. Timeline: By week 4, each student picks a topic. By week 6, each student has collected at least 5 references that represent both sides of the debate at an appropriate level. By the week after the midterm, each student submits an outline of the main arguments. As you write / develop your argument, you should get in touch with me periodically to make sure everything is on track (and to clarify questions). Please provide all files in pdf format (not MS Word). I do not need hardcopies.","title":"Timeline"},{"location":"econ520/term_paper.html#expectations","text":"The paper should demonstrate understanding of the literature lay out arguments on both sides of a debate. give the reader an idea about how the cited studies reached their conclusions give an idea of magnitudes. Macro questions are often about quantifying tradeoffs. For example, it is obvious that more progressive taxes reduce inequality. But is this a big or small effect? I do not expect innovation, modeling, theory, or original data work. that you read academic journal articles (though you should try). that you reach a conclusion. If the experts disagree, I don't expect you to figure it out. There is no prescribed length. Obviously, you don't want to hand in 2 pages. Examples of well-written term papers: Negative interest rates , Racial inequality . These were done during a semester when the students spent less time on their papers. I expect more depth than these.","title":"Expectations"},{"location":"econ520/term_paper.html#notes-on-writing","text":"Cite your sources. When you make a claim, back it up. Use scientific citation styles. In the text: \"Smith (2020) says Blah.\" In the bibliography: \"Smith, Martin (2020). The Title. Journal of Economic Perspectives 3(4): 15-20\". Nice words come last. First decide what you want to write. Outline that. When you are happy with the substance, fill in the words. Visual structure. There should be (sub-)headings that let the reader see at a glance how the document is structured. Explain how conclusions are reached. Saying \"A study by X showed that increasing top marginal taxes reduce income inequality by Y\" is not all that informative by itself. How was that conclusion reached? Why do other studies disagree? Weave a narrative. You don't want a laundry list of \"A says X, B says Y, ...\". Instead, it is better to have: \"The main disagreements are about X and Y. On X, A says XA and backs it up as follows ... But B says XB and supports it as follows ...\" Related: Rather than separately summarizing the arguments pro and con, it is usually better to summarize how both sides view each argument. Example : Do minimum wages cost a lot of jobs? A con argument (no pun intended) may be: we don't see evidence in cities that have increased minimum wages. Those who hold the pro view may counter: there is a selection problem. Only cities where employment effects are small raise minimum wages.","title":"Notes on Writing"},{"location":"econ520/term_paper.html#what-makes-a-good-topic","text":"We are looking for a question that is under active debate. The topic needs to be fairly narrow. Examples: Too broad: Why did income inequality rise over time? Better: Focus on one cause, such as international trade. Perhaps even narrow it to trade with China. Too broad: What are the implications of a flat tax? Better: Would a flat tax substantially increase income inequality? Assignment: Think about a potential topic that interests you (not listed here). We will debate its merits and look for literature.","title":"What Makes a Good Topic?"},{"location":"econ520/term_paper.html#possible-topics-but-you-may-choose-your-own","text":"Below I list potential topics. They are generally phrased more broadly than what you would choose for a term paper.","title":"Possible Topics (but You May Choose Your Own)"},{"location":"econ520/term_paper.html#growth","text":"Do we need patent protection for innovation to occur? Why has manufacturing declined in the U.S. (international trade, technical change, ...)? Do certain policies stimulate long-run growth? Examples include tax cuts, deregulation, free trade agreements.","title":"Growth:"},{"location":"econ520/term_paper.html#business-cycles","text":"Why was wage growth so slow during the recovery after the Great Recession?","title":"Business cycles:"},{"location":"econ520/term_paper.html#fiscal-policy","text":"What are the limits to government debt? Will interest rates remain low for a long time? Do tax cuts pay for themselves? Are taxes the reason that Europeans work so much less than Americans?","title":"Fiscal policy:"},{"location":"econ520/term_paper.html#monetary-policy","text":"Should the Fed target asset prices? Can the Fed pursue unconventional monetary policies (QE, asset purchases) forever? What are the limits? What will happen when the Fed starts to unwind its QE asset positions? Does QE generate inflation?","title":"Monetary policy:"},{"location":"econ520/term_paper.html#inequality","text":"Effects of taxing the rich. Need to focus on specific policies (e.g. progressive income taxes) and specific outcomes (e.g. income distribution). Causes of rising income inequality. Potential policy responses. Labor market polarization: what will happen when more and more jobs get mechanized? Why has the labor share declined over time? What would happen if we taxed bequests? Or wealth? Focus on specific outcomes. Would a minimum wage cause lots of unemployment? Does income support to poor households discourage employment?","title":"Inequality:"},{"location":"econ520/term_paper.html#open-economy","text":"Are exchange rate devaluations expansionary? Why are we running a trade deficit with China?","title":"Open economy:"},{"location":"econ520/term_paper.html#other","text":"Why did the U.S. saving rate decline over time?","title":"Other:"},{"location":"econ520/term_paper.html#finding-source-material","text":"Academic journal articles are generally hard to read. Feel free to look, though, and you will get an idea what professional economists actually do. More accessible references include: World Bank or IMF publications The Journal of Economic Perspectives Brookings Institution Federal Reserve Banks publish articles aimed at explaining research to the general public. Examples are the Economic Letters of the San Francisco Fed. the Economist, NY Times, or Wall Street Journal are fine, but you also want to dig deeper I maintain a short list . I would generally avoid political sources (Heritage Foundation; Congress; Cato Institute).","title":"Finding Source Material"},{"location":"econ520/term_paper_group_work.html","text":"Econ520 - Term Paper \u00b6 Fall 2021 - Prof. Lutz Hendricks \u00b6 The term paper picks a topic, critically reviews the literature, and clearly lays out arguments on both sides of the debate. The final version of the paper is due by the last class meeting. Students work on their term paper in groups of typically three students (let me know if you want a group of two). Learning objectives: Find and organize a literature. Summarize arguments concisely, but in such a way that the reader understands how each argument is supported. Practice scientific writing. Practice presentation skills. Timeline \u00b6 During the first week of classes, students form teams of three. We will discuss what makes a good topic in class. By week 3, each team picks a topic. We will devote part of a class to this process. By week 5, each team has collected 5 references that represent both sides of the debate at an appropriate level. Periodically, we will devote a class meeting to discussing each team's progress. By the week after the midterm, each team submits an outline of the main arguments. We will devote two half classes to short presentations and discussions of the outlines. Towards the end of the class, we will again devote two half classes to presentations and discussion (perhaps even two entire classes). As you write / develop your argument, you should get in touch with me periodically to make sure everything is on track (and to clarify questions). Please provide all files in pdf format (not MS Word). I do not need hardcopies. Expectations \u00b6 The paper should demonstrate understanding of the literature lay out arguments on both sides of a debate. give the reader an idea about how the cited studies reached their conclusions give an idea of magnitudes. Macro questions are often about quantifying tradeoffs. For example, it is obvious that more progressive taxes reduce inequality. But is this a big or small effect? I do not expect innovation, modeling, theory, or original data work. that you read academic journal articles. that you reach a conclusion. If the experts disagree, I don't expect you to figure it out. There is no prescribed length. Obviously, you don't want to hand in 2 pages. Examples of well-written term papers: Negative interest rates , Racial inequality . These were done during a semester when the students spent less time on their papers. I expect more depth than these. Notes on Writing \u00b6 Cite your sources. When you make a claim, back it up. Use scientific citation styles. In the text: \"Smith (2020) says Blah.\" In the bibliography: \"Smith, Martin (2020). The Title. Journal of Economic Perspectives 3(4): 15-20\". Nice words come last. First decide what you want to write. Outline that. When you are happy with the substance, fill in the words. Visual structure. There should be (sub-)headings that let the reader see at a glance how the document is structured. Explain how conclusions are reached. Saying \"A study by X showed that increasing top marginal taxes reduce income inequality by Y\" is not all that informative by itself. How was that conclusion reached? Why do other studies disagree? Weave a narrative. You don't want a laundry list of \"A says X, B says Y, ...\". Instead, it is better to have: \"The main disagreements are about X and Y. On X, A says XA and backs it up as follows ... But B says XB and supports it as follows ...\" Related: Rather than separately summarizing the arguments pro and con, it is usually better to summarize how both sides view each argument. Example: Do minimum wages cost a lot of jobs. A con argument (no pun intended) may be: we don't see evidence in cities that have increased minimum wages. Those who hold the pro view may counter: there is a selection problem. Only cities where employment effects are small raise minimum wages. Possible Topics (but You May Choose Your Own) \u00b6 The topic needs to be fairly narrow. Examples: You could study the importance of international trade for rising income inequality. Studying all possible causes of rising income inequality would be too broad. You could study the pros and cons of a particular tax proposal (e.g., the flat tax). Below I list potential topics. They are generally phrased more broadly than what you would choose for a term paper. Growth: Do we need patent protection for innovation to occur? Why has manufacturing declined in the U.S. (international trade, technical change, ...)? Do certain policies stimulate long-run growth? Examples include tax cuts, deregulation, free trade agreements. Business cycles: Why was wage growth so slow during the recovery after the Great Recession? Fiscal policy: Effects of austerity policies in Greece or other European countries. What are the limits to government debt? Will interest rates remain low for a long time? Do tax cuts pay for themselves? Monetary policy: Should the Fed target asset prices? Can the Fed pursue unconventional monetary policies (QE, asset purchases) forever? What are the limits? Inequality: Effects of taxing the rich. Causes of rising income inequality. Potential policy responses. Labor market polarization: what will happen when more and more jobs get mechanized? Why has the labor share declined over time? What would happen if we taxed bequests? Or wealth? Would a minimum wage cause lots of unemployment? Open economy: Are exchange rate devaluations expansionary? Why are we running a trade deficit with China? Finding source material \u00b6 Academic journal articles are generally hard to read. Feel free to look, though, and you will get an idea what professional economists actually do. More accessible references include: World Bank or IMF publications The Journal of Economic Perspectives Brookings Institution Federal Reserve Banks publish articles aimed at explaining research to the general public. Examples are the Economic Letters of the San Francisco Fed. the Economist, NY Times, or Wall Street Journal are fine, but you also want to dig deeper I maintain a short list . I would generally avoid political sources (Heritage Foundation; Congress; Cato Institute).","title":"Econ520 - Term Paper #"},{"location":"econ520/term_paper_group_work.html#econ520-term-paper","text":"","title":"Econ520 - Term Paper"},{"location":"econ520/term_paper_group_work.html#fall-2021-prof-lutz-hendricks","text":"The term paper picks a topic, critically reviews the literature, and clearly lays out arguments on both sides of the debate. The final version of the paper is due by the last class meeting. Students work on their term paper in groups of typically three students (let me know if you want a group of two). Learning objectives: Find and organize a literature. Summarize arguments concisely, but in such a way that the reader understands how each argument is supported. Practice scientific writing. Practice presentation skills.","title":"Fall 2021 - Prof. Lutz Hendricks"},{"location":"econ520/term_paper_group_work.html#timeline","text":"During the first week of classes, students form teams of three. We will discuss what makes a good topic in class. By week 3, each team picks a topic. We will devote part of a class to this process. By week 5, each team has collected 5 references that represent both sides of the debate at an appropriate level. Periodically, we will devote a class meeting to discussing each team's progress. By the week after the midterm, each team submits an outline of the main arguments. We will devote two half classes to short presentations and discussions of the outlines. Towards the end of the class, we will again devote two half classes to presentations and discussion (perhaps even two entire classes). As you write / develop your argument, you should get in touch with me periodically to make sure everything is on track (and to clarify questions). Please provide all files in pdf format (not MS Word). I do not need hardcopies.","title":"Timeline"},{"location":"econ520/term_paper_group_work.html#expectations","text":"The paper should demonstrate understanding of the literature lay out arguments on both sides of a debate. give the reader an idea about how the cited studies reached their conclusions give an idea of magnitudes. Macro questions are often about quantifying tradeoffs. For example, it is obvious that more progressive taxes reduce inequality. But is this a big or small effect? I do not expect innovation, modeling, theory, or original data work. that you read academic journal articles. that you reach a conclusion. If the experts disagree, I don't expect you to figure it out. There is no prescribed length. Obviously, you don't want to hand in 2 pages. Examples of well-written term papers: Negative interest rates , Racial inequality . These were done during a semester when the students spent less time on their papers. I expect more depth than these.","title":"Expectations"},{"location":"econ520/term_paper_group_work.html#notes-on-writing","text":"Cite your sources. When you make a claim, back it up. Use scientific citation styles. In the text: \"Smith (2020) says Blah.\" In the bibliography: \"Smith, Martin (2020). The Title. Journal of Economic Perspectives 3(4): 15-20\". Nice words come last. First decide what you want to write. Outline that. When you are happy with the substance, fill in the words. Visual structure. There should be (sub-)headings that let the reader see at a glance how the document is structured. Explain how conclusions are reached. Saying \"A study by X showed that increasing top marginal taxes reduce income inequality by Y\" is not all that informative by itself. How was that conclusion reached? Why do other studies disagree? Weave a narrative. You don't want a laundry list of \"A says X, B says Y, ...\". Instead, it is better to have: \"The main disagreements are about X and Y. On X, A says XA and backs it up as follows ... But B says XB and supports it as follows ...\" Related: Rather than separately summarizing the arguments pro and con, it is usually better to summarize how both sides view each argument. Example: Do minimum wages cost a lot of jobs. A con argument (no pun intended) may be: we don't see evidence in cities that have increased minimum wages. Those who hold the pro view may counter: there is a selection problem. Only cities where employment effects are small raise minimum wages.","title":"Notes on Writing"},{"location":"econ520/term_paper_group_work.html#possible-topics-but-you-may-choose-your-own","text":"The topic needs to be fairly narrow. Examples: You could study the importance of international trade for rising income inequality. Studying all possible causes of rising income inequality would be too broad. You could study the pros and cons of a particular tax proposal (e.g., the flat tax). Below I list potential topics. They are generally phrased more broadly than what you would choose for a term paper. Growth: Do we need patent protection for innovation to occur? Why has manufacturing declined in the U.S. (international trade, technical change, ...)? Do certain policies stimulate long-run growth? Examples include tax cuts, deregulation, free trade agreements. Business cycles: Why was wage growth so slow during the recovery after the Great Recession? Fiscal policy: Effects of austerity policies in Greece or other European countries. What are the limits to government debt? Will interest rates remain low for a long time? Do tax cuts pay for themselves? Monetary policy: Should the Fed target asset prices? Can the Fed pursue unconventional monetary policies (QE, asset purchases) forever? What are the limits? Inequality: Effects of taxing the rich. Causes of rising income inequality. Potential policy responses. Labor market polarization: what will happen when more and more jobs get mechanized? Why has the labor share declined over time? What would happen if we taxed bequests? Or wealth? Would a minimum wage cause lots of unemployment? Open economy: Are exchange rate devaluations expansionary? Why are we running a trade deficit with China?","title":"Possible Topics (but You May Choose Your Own)"},{"location":"econ520/term_paper_group_work.html#finding-source-material","text":"Academic journal articles are generally hard to read. Feel free to look, though, and you will get an idea what professional economists actually do. More accessible references include: World Bank or IMF publications The Journal of Economic Perspectives Brookings Institution Federal Reserve Banks publish articles aimed at explaining research to the general public. Examples are the Economic Letters of the San Francisco Fed. the Economist, NY Times, or Wall Street Journal are fine, but you also want to dig deeper I maintain a short list . I would generally avoid political sources (Heritage Foundation; Congress; Cato Institute).","title":"Finding source material"},{"location":"econ720/econ720.html","text":"Econ720: Advanced Macroeconomic Theory (PhD) \u00b6 Fall 2021. Prof. Lutz Hendricks. UNC Syllabus Schedule Announcements \u00b6 Welcome! The midterm will be Oct-7. The final exam will be on Final exam: Dec-7, 8-11am","title":"Econ720"},{"location":"econ720/econ720.html#econ720-advanced-macroeconomic-theory-phd","text":"Fall 2021. Prof. Lutz Hendricks. UNC Syllabus Schedule","title":"Econ720: Advanced Macroeconomic Theory (PhD)"},{"location":"econ720/econ720.html#announcements","text":"Welcome! The midterm will be Oct-7. The final exam will be on Final exam: Dec-7, 8-11am","title":"Announcements"},{"location":"econ720/schedule720.html","text":"Modern Macro \u00b6 Aug-19 (Thu): Modern macro , Here we talk about methods: how to set up a general equilibrium model and characterize its equilibrium. Aug-24 (Tue): Sequential trading and Arrow-Debreu Overlapping Generations \u00b6 Aug-26 (Thu): Model Aug-31 (Tue): OLG model (continued) Sep-2 (Thu): Dynamics and steady state , example (not yet active), PS1 , due Sep-9, solution Sep-7 (Tue): Efficiency and Social Security , RQ (review questions, not to be handed in) Sep-9 (Thu): Bequests Sep-14 (Tue): Money in OLG models , PS2 , due Sep-21, solution Infinite Horizon, Discrete Time Models \u00b6 Sep-16 (Thu): The growth model Sep-21 (Tue): Dynamic programming Sep-23 (Thu): Competitive equilibrium , RQ , PS3 , due Sep-30 Sep-28 (Tue): Cash in advance models , RQ , PS4 , due Oct-5 Sep-30 (Thu): Two sector models , RQ , (Skipped this year), Example: Asset pricing , RQ , Dynamic programming theorems , Notes on Dynamic Programming Infinite Horizon, Continuous Time Models \u00b6 Oct-5 (Tue): Solow model Oct-14 (Thu): Optimal control Oct-19 (Tue): The growth model Oct-26 (Tue): Competitive equilibrium , Dynamics and phase diagrams (skipped this year), RQ Oct-28 (Thu): Money in the utility function , PS5 , due Nov-2 Nov-2 (Tue): Perpetual youth , Aggregation issues (skipped this year) Endogenous Growth \u00b6 Nov-4 (Thu): Endogenous growth: AK model , RQ , Phase diagram (skipped this year), Increasing varieties , RQ Nov-9 (Tue): Increasing varieties, part II Nov-11 (Thu): Knowledge spillovers and scale effects , PS6 , due Nov-16 Nov-16 (Tue): Quality ladders , Quality ladders with firm dynamics Stochastic Growth \u00b6 Nov-18 (Thu): Stochastic optimization , Dynamic programming -- we will not talk about this in class. Think of it as a simple user guide to the results that are out there. Nov-23 (Tue): Asset pricing , Extensions , RQ , PS7 , due never Nov-30 (Tue): Stochastic growth model , RQ","title":"Schedule720"},{"location":"econ720/schedule720.html#modern-macro","text":"Aug-19 (Thu): Modern macro , Here we talk about methods: how to set up a general equilibrium model and characterize its equilibrium. Aug-24 (Tue): Sequential trading and Arrow-Debreu","title":"Modern Macro"},{"location":"econ720/schedule720.html#overlapping-generations","text":"Aug-26 (Thu): Model Aug-31 (Tue): OLG model (continued) Sep-2 (Thu): Dynamics and steady state , example (not yet active), PS1 , due Sep-9, solution Sep-7 (Tue): Efficiency and Social Security , RQ (review questions, not to be handed in) Sep-9 (Thu): Bequests Sep-14 (Tue): Money in OLG models , PS2 , due Sep-21, solution","title":"Overlapping Generations"},{"location":"econ720/schedule720.html#infinite-horizon-discrete-time-models","text":"Sep-16 (Thu): The growth model Sep-21 (Tue): Dynamic programming Sep-23 (Thu): Competitive equilibrium , RQ , PS3 , due Sep-30 Sep-28 (Tue): Cash in advance models , RQ , PS4 , due Oct-5 Sep-30 (Thu): Two sector models , RQ , (Skipped this year), Example: Asset pricing , RQ , Dynamic programming theorems , Notes on Dynamic Programming","title":"Infinite Horizon, Discrete Time Models"},{"location":"econ720/schedule720.html#infinite-horizon-continuous-time-models","text":"Oct-5 (Tue): Solow model Oct-14 (Thu): Optimal control Oct-19 (Tue): The growth model Oct-26 (Tue): Competitive equilibrium , Dynamics and phase diagrams (skipped this year), RQ Oct-28 (Thu): Money in the utility function , PS5 , due Nov-2 Nov-2 (Tue): Perpetual youth , Aggregation issues (skipped this year)","title":"Infinite Horizon, Continuous Time Models"},{"location":"econ720/schedule720.html#endogenous-growth","text":"Nov-4 (Thu): Endogenous growth: AK model , RQ , Phase diagram (skipped this year), Increasing varieties , RQ Nov-9 (Tue): Increasing varieties, part II Nov-11 (Thu): Knowledge spillovers and scale effects , PS6 , due Nov-16 Nov-16 (Tue): Quality ladders , Quality ladders with firm dynamics","title":"Endogenous Growth"},{"location":"econ720/schedule720.html#stochastic-growth","text":"Nov-18 (Thu): Stochastic optimization , Dynamic programming -- we will not talk about this in class. Think of it as a simple user guide to the results that are out there. Nov-23 (Tue): Asset pricing , Extensions , RQ , PS7 , due never Nov-30 (Tue): Stochastic growth model , RQ","title":"Stochastic Growth"},{"location":"econ720/schedule720_matlab.html","text":"Special dates \u00b6 Oct-07 (Thu): Midterm: Material covered: TBA. Nov-25 (Thu): Fall break Modern Macro \u00b6 Aug-19 (Thu): Modern macro , Here we talk about methods: how to set up a general equilibrium model and characterize its equilibrium. Aug-24 (Tue): Sequential trading and Arrow-Debreu Overlapping Generations \u00b6 Aug-26 (Thu): Model Aug-31 (Tue): OLG model (continued) Sep-02 (Thu): OLG model (continued) Sep-07 (Tue): Dynamics and steady state , example (not yet active), PS1 , due Sep-14 Sep-09 (Thu): Efficiency and Social Security , RQ (review questions, not to be handed in) Sep-14 (Tue): Bequests Sep-16 (Thu): Money in OLG models , PS2 , due Sep-21 Infinite Horizon, Discrete Time Models \u00b6 Sep-21 (Tue): The growth model Sep-23 (Thu): Dynamic programming Sep-28 (Tue): Competitive equilibrium , RQ , PS3 , due Oct-5 Sep-30 (Thu): Cash in advance models , RQ , PS4 , due Oct-12 Oct-05 (Tue): Two sector models , RQ , (Skipped this year) Example: Asset pricing , RQ Dynamic programming theorems , Notes on Dynamic Programming Infinite Horizon, Continuous Time Models \u00b6 Oct-12 (Tue): Solow model Oct-14 (Thu): Optimal control Oct-19 (Tue): The growth model Oct-21 (Thu): Competitive equilibrium Dynamics and phase diagrams (skipped this year), RQ Oct-26 (Tue): Money in the utility function , PS5 , due Nov-2 Oct-28 (Thu): Perpetual youth Aggregation issues (skipped this year) Endogenous Growth \u00b6 Nov-02 (Tue): Endogenous growth: AK model , RQ , Phase diagram (skipped this year) Increasing varieties , RQ Nov-04 (Thu): Increasing varieties, part II Nov-09 (Tue): Knowledge spillovers and scale effects , PS6 , due Nov-16 Nov-11 (Thu): Quality ladders Quality ladders with firm dynamics Stochastic Growth \u00b6 Nov-16 (Tue): Stochastic optimization Dynamic programming -- we will not talk about this in class. Think of it as a simple user guide to the results that are out there. Nov-18 (Thu): Asset pricing Nov-23 (Tue): Extensions , RQ , PS7 , due never Nov-30 (Tue): Stochastic growth model , RQ","title":"Schedule720 matlab"},{"location":"econ720/schedule720_matlab.html#special-dates","text":"Oct-07 (Thu): Midterm: Material covered: TBA. Nov-25 (Thu): Fall break","title":"Special dates"},{"location":"econ720/schedule720_matlab.html#modern-macro","text":"Aug-19 (Thu): Modern macro , Here we talk about methods: how to set up a general equilibrium model and characterize its equilibrium. Aug-24 (Tue): Sequential trading and Arrow-Debreu","title":"Modern Macro"},{"location":"econ720/schedule720_matlab.html#overlapping-generations","text":"Aug-26 (Thu): Model Aug-31 (Tue): OLG model (continued) Sep-02 (Thu): OLG model (continued) Sep-07 (Tue): Dynamics and steady state , example (not yet active), PS1 , due Sep-14 Sep-09 (Thu): Efficiency and Social Security , RQ (review questions, not to be handed in) Sep-14 (Tue): Bequests Sep-16 (Thu): Money in OLG models , PS2 , due Sep-21","title":"Overlapping Generations"},{"location":"econ720/schedule720_matlab.html#infinite-horizon-discrete-time-models","text":"Sep-21 (Tue): The growth model Sep-23 (Thu): Dynamic programming Sep-28 (Tue): Competitive equilibrium , RQ , PS3 , due Oct-5 Sep-30 (Thu): Cash in advance models , RQ , PS4 , due Oct-12 Oct-05 (Tue): Two sector models , RQ , (Skipped this year) Example: Asset pricing , RQ Dynamic programming theorems , Notes on Dynamic Programming","title":"Infinite Horizon, Discrete Time Models"},{"location":"econ720/schedule720_matlab.html#infinite-horizon-continuous-time-models","text":"Oct-12 (Tue): Solow model Oct-14 (Thu): Optimal control Oct-19 (Tue): The growth model Oct-21 (Thu): Competitive equilibrium Dynamics and phase diagrams (skipped this year), RQ Oct-26 (Tue): Money in the utility function , PS5 , due Nov-2 Oct-28 (Thu): Perpetual youth Aggregation issues (skipped this year)","title":"Infinite Horizon, Continuous Time Models"},{"location":"econ720/schedule720_matlab.html#endogenous-growth","text":"Nov-02 (Tue): Endogenous growth: AK model , RQ , Phase diagram (skipped this year) Increasing varieties , RQ Nov-04 (Thu): Increasing varieties, part II Nov-09 (Tue): Knowledge spillovers and scale effects , PS6 , due Nov-16 Nov-11 (Thu): Quality ladders Quality ladders with firm dynamics","title":"Endogenous Growth"},{"location":"econ720/schedule720_matlab.html#stochastic-growth","text":"Nov-16 (Tue): Stochastic optimization Dynamic programming -- we will not talk about this in class. Think of it as a simple user guide to the results that are out there. Nov-18 (Thu): Asset pricing Nov-23 (Tue): Extensions , RQ , PS7 , due never Nov-30 (Tue): Stochastic growth model , RQ","title":"Stochastic Growth"},{"location":"econ720/syllabus720.html","text":"Econ720 - Syllabus \u00b6 Fall 2021. Prof. Lutz Hendricks. UNC \u00b6 Course objective: \u00b6 Econ720 is the first course in the macro PhD sequence. Its objective is to learn about the standard models commonly used in macroeconomics. In parallel, the course develops the mathematical methods used to characterize the equilibria of the models. This is a largely a theory and methods course. But we will cover some applications to topics such as the distribution of wealth. The course schedule contains more detail. Organization \u00b6 Two lectures per week: Tue Thu 9:30-10:45, Gardner 7 Recitation: Fri 8:00 - 9:15, Gardner 106 TA: Yanran Guo Course website Sakai site (only for grades and discussion forum). For online discussions, I suggest to sign up at Econ StackExchange : there you can post questions that are not directly class related. The questions have to be specific (discussion questions are not permitted). For questions that are directly class related, please use the Sakai forum. You can of course also just email me directly, but using the forums has the benefit that others can see the conversations (and chime in). Grading \u00b6 Midterm: 40%. Final: 50%. Problem sets: 10%. Exams are closed book and cover all material taught. Per university requirement, the final will last 3 hours. Review problems are for your practice and not to be turned in. Many are questions from previous exams. If a student misses a midterm, the weight of that midterm in the course grade will be added to the weight on the student\u2019s final. An exception will be made for University-approved absences . Students with this type of absence may request a make-up examination at a time convenient to both student and instructor. Text \u00b6 We do not closely follow a text, but a good one is: Acemoglu, Introduction to Modern Economic Growth, MIT Press, ISBN-13: 978-0691132921 Also useful: Dirk Krueger\u2019s Macroeconomic Theory manuscript ([2012 version][]; this tends to move around on the web). Per Krusell\u2019s Real Macroeconomic Theory manuscript, 2014 version Additional readings are in the slides. Rules \u00b6 Questions and comments are always welcome. Come to my office hours! You should download the slides before each class. However, I tend to change details even after posting the slides. The professor reserves the right to make changes to the syllabus, including project due dates and test dates. These changes will be announced as early as possible. Covid-19 \u00b6 This semester, while we are in the midst of a global pandemic, all enrolled students are required to wear a mask covering your mouth and nose at all times in our classroom. This requirement is to protect our educational community \u2014 your classmates and me \u2013 as we learn together. If you choose not to wear a mask, or wear it improperly, I will ask you to leave immediately, and I will submit a report to the Office of Student Conduct . At that point you will be disenrolled from this course for the protection of our educational community. Students who have an authorized accommodation from Accessibility Resources and Service have an exception. For additional information, see Carolina Together . Attendance Policy \u00b6 No right or privilege exists that permits a student to be absent from any class meetings, except for these University Approved Absences: Authorized University activities Disability/religious observance/pregnancy, as required by law and approved by Accessibility Resources and Service and/or the Equal Opportunity and Compliance Office (EOC) Significant health condition and/or personal/family emergency as approved by the Office of the Dean of Students , Gender Violence Service Coordinators, and/or the Equal Opportunity and Compliance Office (EOC). Honor Code \u00b6 All students are expected to follow the guidelines of the UNC honor code. In particular, students are expected to refrain from \u201clying, cheating, or stealing\u201d in the academic context. If you are unsure about which actions violate that honor code, please see me or consult honor.unc.edu . Accessibility \u00b6 The University of North Carolina at Chapel Hill facilitates the implementation of reasonable accommodations, including resources and services, for students with disabilities, chronic medical conditions, a temporary disability or pregnancy complications resulting in barriers to fully accessing University courses, programs and activities. Accommodations are determined through the Office of Accessibility Resources and Service (ARS) for individuals with documented qualifying disabilities in accordance with applicable state and federal laws. See the ARS Website for contact information: or email ars@unc.edu. Conseling \u00b6 CAPS is strongly committed to addressing the mental health needs of a diverse student body through timely access to consultation and connection to clinically appropriate services, whether for short or long-term needs. Go to their website: https://caps.unc.edu/ or visit their facilities on the third floor of the Campus Health Services building for a walk-in evaluation to learn more. Title IX Resources \u00b6 Any student who is impacted by discrimination, harassment, interpersonal (relationship) violence, sexual violence, sexual exploitation, or stalking is encouraged to seek resources on campus or in the community. Please contact the Director of Title IX Compliance (Adrienne Allison \u2013 Adrienne.allison@unc.edu), Report and Response Coordinators in the Equal Opportunity and Compliance Office (reportandresponse@unc.edu), Counseling and Psychological Services (confidential), or the Gender Violence Services Coordinators (gvsc@unc.edu; confidential) to discuss your specific needs. Additional resources are available at safe.unc.edu. Previous Exams \u00b6 Qualifying exams: August 2009 , January 2010 , August 2010 , January 2011 , August 2011 , January 2012 , August 2012 , January 2013 , August 2013 , January 2014 , August 2014 , January 2015 , August 2015 , January 2016 , August 2016 , January 2017 , August 2017 , May 2018 , May 2019 , Aug 2019 , June 2020 , Aug 2020 , Jan 2021 , June 2021 , August 2021 . Final exams: 2009 , 2010 , 2011 , 2012 , 2013 , 2014 , 2015 , 2016 , 2017 , 2018 , 2019 , 2020 . Midterms: 2008 (Iowa State), 2009 , 2009 take 3 , 2010 , 2011 , 2012 , 2013 , 2014 , 2015 , 2016 , 2017 , 2018 , 2019 , 2020 . If answers are missing, the exam questions are usually reused as problem sets. Required University Boilerplate Text \u00b6 This fall semester, while we are in the midst of a global pandemic, all enrolled students are required to wear a mask covering your mouth and nose at all times in our classroom. This requirement is to protect our educational community \u2014 your classmates and me \u2013 as we learn together. If you choose not to wear a mask, or wear it improperly, I will ask you to leave immediately, and I will submit a report to the Office of Student Conduct. At that point you will be disenrolled from this course for the protection of our educational community. An exemption to the mask wearing community standard will not typically be considered to be a reasonable accommodation. Individuals with a disability or health condition that prevents them from safely\u202fwearing a face\u202fmask must seek alternative accommodations through the Accessibility Resources and Service. For additional information, see Carolina Together. Any student who is impacted by discrimination, harassment, interpersonal (relationship) violence, sexual violence, sexual exploitation, or stalking is encouraged to seek resources on campus or in the community. Please contact the Director of Title IX Compliance (Adrienne Allison \u2013 Adrienne.allison@unc.edu), Report and Response Coordinators in the Equal Opportunity and Compliance Office (reportandresponse@unc.edu), Counseling and Psychological Services (confidential), or the Gender Violence Services Coordinators (gvsc@unc.edu; confidential) to discuss your specific needs. Additional resources are available at safe.unc.edu.","title":"Econ720 - Syllabus"},{"location":"econ720/syllabus720.html#econ720-syllabus","text":"","title":"Econ720 - Syllabus"},{"location":"econ720/syllabus720.html#fall-2021-prof-lutz-hendricks-unc","text":"","title":"Fall 2021. Prof. Lutz Hendricks. UNC"},{"location":"econ720/syllabus720.html#course-objective","text":"Econ720 is the first course in the macro PhD sequence. Its objective is to learn about the standard models commonly used in macroeconomics. In parallel, the course develops the mathematical methods used to characterize the equilibria of the models. This is a largely a theory and methods course. But we will cover some applications to topics such as the distribution of wealth. The course schedule contains more detail.","title":"Course objective:"},{"location":"econ720/syllabus720.html#organization","text":"Two lectures per week: Tue Thu 9:30-10:45, Gardner 7 Recitation: Fri 8:00 - 9:15, Gardner 106 TA: Yanran Guo Course website Sakai site (only for grades and discussion forum). For online discussions, I suggest to sign up at Econ StackExchange : there you can post questions that are not directly class related. The questions have to be specific (discussion questions are not permitted). For questions that are directly class related, please use the Sakai forum. You can of course also just email me directly, but using the forums has the benefit that others can see the conversations (and chime in).","title":"Organization"},{"location":"econ720/syllabus720.html#grading","text":"Midterm: 40%. Final: 50%. Problem sets: 10%. Exams are closed book and cover all material taught. Per university requirement, the final will last 3 hours. Review problems are for your practice and not to be turned in. Many are questions from previous exams. If a student misses a midterm, the weight of that midterm in the course grade will be added to the weight on the student\u2019s final. An exception will be made for University-approved absences . Students with this type of absence may request a make-up examination at a time convenient to both student and instructor.","title":"Grading"},{"location":"econ720/syllabus720.html#text","text":"We do not closely follow a text, but a good one is: Acemoglu, Introduction to Modern Economic Growth, MIT Press, ISBN-13: 978-0691132921 Also useful: Dirk Krueger\u2019s Macroeconomic Theory manuscript ([2012 version][]; this tends to move around on the web). Per Krusell\u2019s Real Macroeconomic Theory manuscript, 2014 version Additional readings are in the slides.","title":"Text"},{"location":"econ720/syllabus720.html#rules","text":"Questions and comments are always welcome. Come to my office hours! You should download the slides before each class. However, I tend to change details even after posting the slides. The professor reserves the right to make changes to the syllabus, including project due dates and test dates. These changes will be announced as early as possible.","title":"Rules"},{"location":"econ720/syllabus720.html#covid-19","text":"This semester, while we are in the midst of a global pandemic, all enrolled students are required to wear a mask covering your mouth and nose at all times in our classroom. This requirement is to protect our educational community \u2014 your classmates and me \u2013 as we learn together. If you choose not to wear a mask, or wear it improperly, I will ask you to leave immediately, and I will submit a report to the Office of Student Conduct . At that point you will be disenrolled from this course for the protection of our educational community. Students who have an authorized accommodation from Accessibility Resources and Service have an exception. For additional information, see Carolina Together .","title":"Covid-19"},{"location":"econ720/syllabus720.html#attendance-policy","text":"No right or privilege exists that permits a student to be absent from any class meetings, except for these University Approved Absences: Authorized University activities Disability/religious observance/pregnancy, as required by law and approved by Accessibility Resources and Service and/or the Equal Opportunity and Compliance Office (EOC) Significant health condition and/or personal/family emergency as approved by the Office of the Dean of Students , Gender Violence Service Coordinators, and/or the Equal Opportunity and Compliance Office (EOC).","title":"Attendance Policy"},{"location":"econ720/syllabus720.html#honor-code","text":"All students are expected to follow the guidelines of the UNC honor code. In particular, students are expected to refrain from \u201clying, cheating, or stealing\u201d in the academic context. If you are unsure about which actions violate that honor code, please see me or consult honor.unc.edu .","title":"Honor Code"},{"location":"econ720/syllabus720.html#accessibility","text":"The University of North Carolina at Chapel Hill facilitates the implementation of reasonable accommodations, including resources and services, for students with disabilities, chronic medical conditions, a temporary disability or pregnancy complications resulting in barriers to fully accessing University courses, programs and activities. Accommodations are determined through the Office of Accessibility Resources and Service (ARS) for individuals with documented qualifying disabilities in accordance with applicable state and federal laws. See the ARS Website for contact information: or email ars@unc.edu.","title":"Accessibility"},{"location":"econ720/syllabus720.html#conseling","text":"CAPS is strongly committed to addressing the mental health needs of a diverse student body through timely access to consultation and connection to clinically appropriate services, whether for short or long-term needs. Go to their website: https://caps.unc.edu/ or visit their facilities on the third floor of the Campus Health Services building for a walk-in evaluation to learn more.","title":"Conseling"},{"location":"econ720/syllabus720.html#title-ix-resources","text":"Any student who is impacted by discrimination, harassment, interpersonal (relationship) violence, sexual violence, sexual exploitation, or stalking is encouraged to seek resources on campus or in the community. Please contact the Director of Title IX Compliance (Adrienne Allison \u2013 Adrienne.allison@unc.edu), Report and Response Coordinators in the Equal Opportunity and Compliance Office (reportandresponse@unc.edu), Counseling and Psychological Services (confidential), or the Gender Violence Services Coordinators (gvsc@unc.edu; confidential) to discuss your specific needs. Additional resources are available at safe.unc.edu.","title":"Title IX Resources"},{"location":"econ720/syllabus720.html#previous-exams","text":"Qualifying exams: August 2009 , January 2010 , August 2010 , January 2011 , August 2011 , January 2012 , August 2012 , January 2013 , August 2013 , January 2014 , August 2014 , January 2015 , August 2015 , January 2016 , August 2016 , January 2017 , August 2017 , May 2018 , May 2019 , Aug 2019 , June 2020 , Aug 2020 , Jan 2021 , June 2021 , August 2021 . Final exams: 2009 , 2010 , 2011 , 2012 , 2013 , 2014 , 2015 , 2016 , 2017 , 2018 , 2019 , 2020 . Midterms: 2008 (Iowa State), 2009 , 2009 take 3 , 2010 , 2011 , 2012 , 2013 , 2014 , 2015 , 2016 , 2017 , 2018 , 2019 , 2020 . If answers are missing, the exam questions are usually reused as problem sets.","title":"Previous Exams"},{"location":"econ720/syllabus720.html#required-university-boilerplate-text","text":"This fall semester, while we are in the midst of a global pandemic, all enrolled students are required to wear a mask covering your mouth and nose at all times in our classroom. This requirement is to protect our educational community \u2014 your classmates and me \u2013 as we learn together. If you choose not to wear a mask, or wear it improperly, I will ask you to leave immediately, and I will submit a report to the Office of Student Conduct. At that point you will be disenrolled from this course for the protection of our educational community. An exemption to the mask wearing community standard will not typically be considered to be a reasonable accommodation. Individuals with a disability or health condition that prevents them from safely\u202fwearing a face\u202fmask must seek alternative accommodations through the Accessibility Resources and Service. For additional information, see Carolina Together. Any student who is impacted by discrimination, harassment, interpersonal (relationship) violence, sexual violence, sexual exploitation, or stalking is encouraged to seek resources on campus or in the community. Please contact the Director of Title IX Compliance (Adrienne Allison \u2013 Adrienne.allison@unc.edu), Report and Response Coordinators in the Equal Opportunity and Compliance Office (reportandresponse@unc.edu), Counseling and Psychological Services (confidential), or the Gender Violence Services Coordinators (gvsc@unc.edu; confidential) to discuss your specific needs. Additional resources are available at safe.unc.edu.","title":"Required University Boilerplate Text"},{"location":"econ821/code_organization.html","text":"{{econ821_header.txt}} Organizing our code \u00b6 Directory structure \u00b6 Course home directory (e.g. ~/documents/econ821 ) shared : code for general purpose functions put on the matlab path by go_econ821 contains a function that returns constants shared by all projects: const_821.m shared code as zip file projectX : code for each project mat : matrix files .mat out : output files, such as figures, tables Project code \u00b6 Suffix each file with a project name, such as _olg . This ensures unique names. const_olg : defines all constants for a project model parameters directories figure formatting etc","title":"Code organization"},{"location":"econ821/code_organization.html#organizing-our-code","text":"","title":"Organizing our code"},{"location":"econ821/code_organization.html#directory-structure","text":"Course home directory (e.g. ~/documents/econ821 ) shared : code for general purpose functions put on the matlab path by go_econ821 contains a function that returns constants shared by all projects: const_821.m shared code as zip file projectX : code for each project mat : matrix files .mat out : output files, such as figures, tables","title":"Directory structure"},{"location":"econ821/code_organization.html#project-code","text":"Suffix each file with a project name, such as _olg . This ensures unique names. const_olg : defines all constants for a project model parameters directories figure formatting etc","title":"Project code"},{"location":"econ821/econ821%202016.html","text":"{{econ821_header.txt}} {{../markdown_header.txt}} Econ821: \"Monetary Economics\" \u00b6 [%ClassTerm]. Prof. Lutz Hendricks. UNC \u00b6 Outline: Announcements \u00b6 Organization \u00b6 Objectives \u00b6 Learn about state of the art research in selected areas of macro. Learn how to compute models and take them to the data. Identify potential topics for dissertation research. See my notes on finding research topics. We cover the following broad topics: \u00b6 Economic growth Cross-country income gaps Within country income / wealth inequality. Class structure \u00b6 A mixture of lectures, student presentations , and hands-on programming. The lectures present key papers in each topic. We will then replicate the results of select papers using Matlab . This class is somewhat experimental. We will have to figure out how to efficiently do programming in class as we go along. Suggestions are welcome. Grading \u00b6 The class is graded based on participation in class. Students are expected to present and discuss state-of-the art papers on the topics we will cover. Outline \u00b6 Matlab and Programming [matlab] \u00b6 Jan-12 to 21: The material for this section is hosted at ReadTheDocs Solving heterogeneous agent OLG models [olg] \u00b6 Jan-26: Partial equilibrium (these are slides presented in class) General equilibrium The code for this lives in the olg2d folder on Github . Jan-28: Stochastic model Feb-2: Many period stochastic model Feb-4: Computing the multi-period model Wealth Distribution [wealth] \u00b6 Feb-9: Background lecture Bequests Feb-11: Entrepreneurship Other extensions Feb-16: Student presentations ( notes on their format ) David: Cozzi Feb-18: Student presentations Deepak: Boserum Andrew: de Nardi (2016) Feb-23: Kanat: Campanale (2007) Redistribution \u00b6 Feb-25: Redistribution I Mar-1: Redistribution II Economic Growth [growth] \u00b6 Mar-3: Growth facts Data sources Cross-Country Income Differences [incomeGaps] \u00b6 Mar-8: Background on cross-country income gaps Human Capital \u00b6 Mar-8: Human capital quality Mar-10: Immigrant earnings Mar-15 to 17: Spring break Mar-22 to 29: Presentation and discussion of current papers (by students). possible papers are listed at the end of the slides (you may suggest others) Andrew: Jones (2014) Kanat: Lagakos et al \"Experience matters\" (now with a changed title) David: Manuelli & Seshadri (2014) Deepak: Hanushek & Woessman (2012) Misallocation \u00b6 Mar-31: Misallocation: Agriculture Misallocation: Plants Apr-7 to 12: Student presentations Kanat: Hsieh et al. (2013) David: Gollin et al. (2013) Andrew: Lagakos & Waugh (2013) Deepak: Restuccia & Santaeulalia (2015) Computing Manuelli & Seshadri (2014 AER) \u00b6 Apr-19: Notes on the model Apr-21: Computation: household problem my code is on github Apr-26: Last class The rise in US educational attainment End of Class \u00b6","title":"Econ821 2016"},{"location":"econ821/econ821%202016.html#econ821-monetary-economics","text":"","title":"Econ821: \"Monetary Economics\""},{"location":"econ821/econ821%202016.html#classterm-prof-lutz-hendricks-unc","text":"Outline:","title":"[%ClassTerm]. Prof. Lutz Hendricks. UNC"},{"location":"econ821/econ821%202016.html#announcements","text":"","title":"Announcements"},{"location":"econ821/econ821%202016.html#organization","text":"","title":"Organization"},{"location":"econ821/econ821%202016.html#objectives","text":"Learn about state of the art research in selected areas of macro. Learn how to compute models and take them to the data. Identify potential topics for dissertation research. See my notes on finding research topics.","title":"Objectives"},{"location":"econ821/econ821%202016.html#we-cover-the-following-broad-topics","text":"Economic growth Cross-country income gaps Within country income / wealth inequality.","title":"We cover the following broad topics:"},{"location":"econ821/econ821%202016.html#class-structure","text":"A mixture of lectures, student presentations , and hands-on programming. The lectures present key papers in each topic. We will then replicate the results of select papers using Matlab . This class is somewhat experimental. We will have to figure out how to efficiently do programming in class as we go along. Suggestions are welcome.","title":"Class structure"},{"location":"econ821/econ821%202016.html#grading","text":"The class is graded based on participation in class. Students are expected to present and discuss state-of-the art papers on the topics we will cover.","title":"Grading"},{"location":"econ821/econ821%202016.html#outline","text":"","title":"Outline"},{"location":"econ821/econ821%202016.html#matlab-and-programming-matlab","text":"Jan-12 to 21: The material for this section is hosted at ReadTheDocs","title":"Matlab and Programming [matlab]"},{"location":"econ821/econ821%202016.html#solving-heterogeneous-agent-olg-models-olg","text":"Jan-26: Partial equilibrium (these are slides presented in class) General equilibrium The code for this lives in the olg2d folder on Github . Jan-28: Stochastic model Feb-2: Many period stochastic model Feb-4: Computing the multi-period model","title":"Solving heterogeneous agent OLG models [olg]"},{"location":"econ821/econ821%202016.html#wealth-distribution-wealth","text":"Feb-9: Background lecture Bequests Feb-11: Entrepreneurship Other extensions Feb-16: Student presentations ( notes on their format ) David: Cozzi Feb-18: Student presentations Deepak: Boserum Andrew: de Nardi (2016) Feb-23: Kanat: Campanale (2007)","title":"Wealth Distribution [wealth]"},{"location":"econ821/econ821%202016.html#redistribution","text":"Feb-25: Redistribution I Mar-1: Redistribution II","title":"Redistribution"},{"location":"econ821/econ821%202016.html#economic-growth-growth","text":"Mar-3: Growth facts Data sources","title":"Economic Growth [growth]"},{"location":"econ821/econ821%202016.html#cross-country-income-differences-incomegaps","text":"Mar-8: Background on cross-country income gaps","title":"Cross-Country Income Differences [incomeGaps]"},{"location":"econ821/econ821%202016.html#human-capital","text":"Mar-8: Human capital quality Mar-10: Immigrant earnings Mar-15 to 17: Spring break Mar-22 to 29: Presentation and discussion of current papers (by students). possible papers are listed at the end of the slides (you may suggest others) Andrew: Jones (2014) Kanat: Lagakos et al \"Experience matters\" (now with a changed title) David: Manuelli & Seshadri (2014) Deepak: Hanushek & Woessman (2012)","title":"Human Capital"},{"location":"econ821/econ821%202016.html#misallocation","text":"Mar-31: Misallocation: Agriculture Misallocation: Plants Apr-7 to 12: Student presentations Kanat: Hsieh et al. (2013) David: Gollin et al. (2013) Andrew: Lagakos & Waugh (2013) Deepak: Restuccia & Santaeulalia (2015)","title":"Misallocation"},{"location":"econ821/econ821%202016.html#computing-manuelli-seshadri-2014-aer","text":"Apr-19: Notes on the model Apr-21: Computation: household problem my code is on github Apr-26: Last class The rise in US educational attainment","title":"Computing Manuelli &amp; Seshadri (2014 AER)"},{"location":"econ821/econ821%202016.html#end-of-class","text":"","title":"End of Class"},{"location":"econ821/student_presentations.html","text":"{{econ821_header.txt}} {{../markdown_header.txt}} Econ821: \"Monetary Economics\" \u00b6 [%ClassTerm]. Prof. Lutz Hendricks. UNC \u00b6 Student Presentations \u00b6 Format: short summary of what the paper does (assume everyone has read it) focus on key features of the analysis (no details) comment on what drives results / key assumptions identify weaknesses / opportunities for improvements Duration: aim for 35 minutes including class discussion Send me slides a few days before the presentation","title":"Student presentations"},{"location":"econ821/student_presentations.html#econ821-monetary-economics","text":"","title":"Econ821: \"Monetary Economics\""},{"location":"econ821/student_presentations.html#classterm-prof-lutz-hendricks-unc","text":"","title":"[%ClassTerm]. Prof. Lutz Hendricks. UNC"},{"location":"econ821/student_presentations.html#student-presentations","text":"Format: short summary of what the paper does (assume everyone has read it) focus on key features of the analysis (no details) comment on what drives results / key assumptions identify weaknesses / opportunities for improvements Duration: aim for 35 minutes including class discussion Send me slides a few days before the presentation","title":"Student Presentations"},{"location":"econ890/econ890.html","text":"Econ890: Topics in Income and Wealth Distribution \u00b6 Spring 2021. Prof. Lutz Hendricks. UNC Announcements \u00b6 Mar-16: Background lecture on top incomes Mar-4: Material on programming and Julia Feb-20: Background lecture on earnings distribution . Course Description \u00b6 Econ890 is a graduate course aimed at PhD students in their second year or higher. It is part of the macro field but may be of interest to students specializing in public policy or even applied micro. The course will focus on wealth and income inequality , mostly within countries. The objectives will be: Learn about state of the art research in the area of inequality and perhaps cross-country income differences. Develop ideas for research projects in the area. Organization \u00b6 The class meets MW 9:05-10:20 in Carolina 104. The sakai site mainly holds material that should not be visible to the public. The organization will be similar to a reading group. There will be a few lectures to provide background material and review classic papers from the literature. But most of the course will consist of student presentations that would be structured like discussions at a conference. The assumption is that everyone has read the papers discussed in each class meeting (probably 4 papers a week). The presenters offer insights into what makes each paper tick, what is compelling and what is not. Much of the time will be spent on simply discussing each paper. Over time, students come up with project ideas. Once a promising idea is identified, each student develops it as far as possible. This will at least entail placing the idea into the context of the literature, identifying the contribution, and outlining a model. The end product would be a fully written up research proposal. At various points during the class, students present their project ideas and receive comments from the class. In the past, this course covered computational methods as well. I have come to the conclusion that mixing these with the economic material is not productive. The department needs a dedicated course on computing structural models, but Econ890 is not that. (But, this too, is up for discussion.) Grading \u00b6 Grades will be based on: class presentations (35%) class participation (40%) research proposal(s) (25%) Student Presentations \u00b6 A typical class will discuss two papers; so we have about 35 minutes per paper. The discussion will be structured around a presentation that should be structured like a discussion at a conference. The presentation should accomplish the following: Briefly summarize what the paper does (assume everyone has read it). Focus on key features of the analysis (no details). Comment on what drives results / key assumptions. Identify weaknesses / opportunities for improvements. Send me your slides a few days before the presentation. Examples of what good discussions look like: Ellen McGrattan Research proposal(s) \u00b6 At various points in time, students are expected to present ideas for possible research papers. At the end of the course, one of these ideas will be written up as a proposal. This will look a bit like the introduction to a paper: state the question explain why it is important explain how it contributes to the literature explain the approach and why it is reasonable sketch a model and possible data sources outline possible conclusions / the paper's message. Outline \u00b6 The outline links to the papers that we will discuss. The exact dates will be filled in as students sign up for presentations. Links \u00b6 Online course in macro development","title":"Econ890"},{"location":"econ890/econ890.html#econ890-topics-in-income-and-wealth-distribution","text":"Spring 2021. Prof. Lutz Hendricks. UNC","title":"Econ890: Topics in Income and Wealth Distribution"},{"location":"econ890/econ890.html#announcements","text":"Mar-16: Background lecture on top incomes Mar-4: Material on programming and Julia Feb-20: Background lecture on earnings distribution .","title":"Announcements"},{"location":"econ890/econ890.html#course-description","text":"Econ890 is a graduate course aimed at PhD students in their second year or higher. It is part of the macro field but may be of interest to students specializing in public policy or even applied micro. The course will focus on wealth and income inequality , mostly within countries. The objectives will be: Learn about state of the art research in the area of inequality and perhaps cross-country income differences. Develop ideas for research projects in the area.","title":"Course Description"},{"location":"econ890/econ890.html#organization","text":"The class meets MW 9:05-10:20 in Carolina 104. The sakai site mainly holds material that should not be visible to the public. The organization will be similar to a reading group. There will be a few lectures to provide background material and review classic papers from the literature. But most of the course will consist of student presentations that would be structured like discussions at a conference. The assumption is that everyone has read the papers discussed in each class meeting (probably 4 papers a week). The presenters offer insights into what makes each paper tick, what is compelling and what is not. Much of the time will be spent on simply discussing each paper. Over time, students come up with project ideas. Once a promising idea is identified, each student develops it as far as possible. This will at least entail placing the idea into the context of the literature, identifying the contribution, and outlining a model. The end product would be a fully written up research proposal. At various points during the class, students present their project ideas and receive comments from the class. In the past, this course covered computational methods as well. I have come to the conclusion that mixing these with the economic material is not productive. The department needs a dedicated course on computing structural models, but Econ890 is not that. (But, this too, is up for discussion.)","title":"Organization"},{"location":"econ890/econ890.html#grading","text":"Grades will be based on: class presentations (35%) class participation (40%) research proposal(s) (25%)","title":"Grading"},{"location":"econ890/econ890.html#student-presentations","text":"A typical class will discuss two papers; so we have about 35 minutes per paper. The discussion will be structured around a presentation that should be structured like a discussion at a conference. The presentation should accomplish the following: Briefly summarize what the paper does (assume everyone has read it). Focus on key features of the analysis (no details). Comment on what drives results / key assumptions. Identify weaknesses / opportunities for improvements. Send me your slides a few days before the presentation. Examples of what good discussions look like: Ellen McGrattan","title":"Student Presentations"},{"location":"econ890/econ890.html#research-proposals","text":"At various points in time, students are expected to present ideas for possible research papers. At the end of the course, one of these ideas will be written up as a proposal. This will look a bit like the introduction to a paper: state the question explain why it is important explain how it contributes to the literature explain the approach and why it is reasonable sketch a model and possible data sources outline possible conclusions / the paper's message.","title":"Research proposal(s)"},{"location":"econ890/econ890.html#outline","text":"The outline links to the papers that we will discuss. The exact dates will be filled in as students sign up for presentations.","title":"Outline"},{"location":"econ890/econ890.html#links","text":"Online course in macro development","title":"Links"},{"location":"econ890/julia/arrays.html","text":"Arrays \u00b6 An array is an n-dimensional matrix. The elements are accessed by \"row\" and \"column\" indices. Vectors \u00b6 A Vector is just what you think it is: a 1-dimensional array. In Julia, these are always column vectors (sort of always). To create a vector, simply fill it with values: a = [ 1 , 2 , 3 ] 3 - element Array { Int64 , 1 } : 1 2 3 Note that the return values is a one-dimensional array . Vector is simply an alias for this. julia > Vector { Int } === Array { Int , 1 } true There are no row vectors in Julia. A row vector is a 1xN Matrix : julia > a = [ 1 2 3 ] 1 \u00d73 Array { Int64 , 2 } : 1 2 3 julia > a isa Matrix { Int } true Indexing \u00b6 To extract elements from a vector, hand it a list of indices. julia > a = [ 2 , 3 , 4 , 5 ]; julia > a [ 1 ] 2 # Note the double brackets julia > a [[ 1 , 3 ]] 2 - element Array { Int64 , 1 } : 2 4 # What we are really doing is idx = [ 1 , 3 ]; a [ idx ] Then there is logical indexing: a = [ 1 , 2 , 3 ]; a [[ true , false , true ]] 2 - element Array { Int64 , 1 } : 1 3 Arrays are \"mutable\", meaning that the elements can be changed \"in-place\": julia > a = [ 1 , 2 , 3 ] 3 - element Vector { Int64 } : 1 2 3 julia > a [ 2 ] = 22 22 julia > a 3 - element Vector { Int64 } : 1 22 3 Ranges \u00b6 In Matlab, 1:3 is a Vector , but not in Julia: julia > 1 : 3 1 : 3 julia > typeof ( 1 : 3 ) UnitRange { Int64 } The main difference between a Vector and a Range is that the vector is allocated upon construction (its values are computed and stored in memory). A Range is an Iterator . You can iteratore over its elements, but they are not computed until needed. Therefore, the Range does not allocate memory. This is a big deal when lots of values are involved. However, a Range is an AbstractArray ; so all the indexing that works on Vectors also works on Range s. collect makes a Range into a Vector . Exercises \u00b6 Start with x = 1 : 3 : 30 . Find all even elements. Find all elements between 5 and 20. Set all even elements to their negative values. Matrices \u00b6 A Matrix is a 2-dimensional array. There are also n-dimensional arrays (see below). To create a matrix, simply fill it with values. julia > a = [ 1 2 3 ; 4 5 6 ] 2 \u00d73 Array { Int64 , 2 } : 1 2 3 4 5 6 Many commands work directly on matrices. julia > a = [ 1 2 3 ]; b = [ 2 ; 1 ; 1 ]; a * b 1 - element Array { Int64 , 1 } : 7 julia > c = b * a 3 \u00d73 Array { Int64 , 2 } : 2 4 6 1 2 3 1 2 3 To extract elements: julia > c [ 1 , 2 ] 4 julia > c [ 1 : 2 , 2 : 3 ] 2 \u00d72 Array { Int64 , 2 } : 4 6 2 3 To extract a row (but note that this produces a Vector ): julia > c [ 1 , : ] 3 - element Array { Int64 , 1 } : 2 4 6 Linear indexing works as well: julia > c [ 4 ] 4 julia > c [ 4 ] == c [ 1 , 2 ] true In memory, Arrays are stored like Vectors . The compiler just keeps track of how the user wants to interpret the data. Multi-dimensional Arrays \u00b6 Arrays can have more than 2 dimensions. julia > using Random julia > a = rand ( 4 , 3 , 2 ) 4 \u00d73\u00d72 Array { Float64 , 3 } : [ : , : , 1 ] = 0.146411 0.908415 0.568039 0.444156 0.434034 0.875361 0.429705 0.704086 0.71789 0.502228 0.124412 0.771808 [ : , : , 2 ] = 0.862953 0.58189 0.549077 0.722745 0.677342 0.330188 0.0543144 0.161877 0.358381 0.312414 0.0681076 0.822319 Indexing generates new arrays with potentially fewer dimensions: julia > a [ : , 1 , : ] 4 \u00d72 Array { Float64 , 2 } : 0.146411 0.862953 0.444156 0.722745 0.429705 0.0543144 0.502228 0.312414 Array Exercises \u00b6 Construct a matrix A with elements [2,4,...,20] in row 1 and [1,4,7,...,28] in row 2. Replace row 1 with its square. Find all columns where row 1 > row 2. Let x=ones(10,1) . Compute Ax .","title":"Arrays"},{"location":"econ890/julia/arrays.html#arrays","text":"An array is an n-dimensional matrix. The elements are accessed by \"row\" and \"column\" indices.","title":"Arrays"},{"location":"econ890/julia/arrays.html#vectors","text":"A Vector is just what you think it is: a 1-dimensional array. In Julia, these are always column vectors (sort of always). To create a vector, simply fill it with values: a = [ 1 , 2 , 3 ] 3 - element Array { Int64 , 1 } : 1 2 3 Note that the return values is a one-dimensional array . Vector is simply an alias for this. julia > Vector { Int } === Array { Int , 1 } true There are no row vectors in Julia. A row vector is a 1xN Matrix : julia > a = [ 1 2 3 ] 1 \u00d73 Array { Int64 , 2 } : 1 2 3 julia > a isa Matrix { Int } true","title":"Vectors"},{"location":"econ890/julia/arrays.html#indexing","text":"To extract elements from a vector, hand it a list of indices. julia > a = [ 2 , 3 , 4 , 5 ]; julia > a [ 1 ] 2 # Note the double brackets julia > a [[ 1 , 3 ]] 2 - element Array { Int64 , 1 } : 2 4 # What we are really doing is idx = [ 1 , 3 ]; a [ idx ] Then there is logical indexing: a = [ 1 , 2 , 3 ]; a [[ true , false , true ]] 2 - element Array { Int64 , 1 } : 1 3 Arrays are \"mutable\", meaning that the elements can be changed \"in-place\": julia > a = [ 1 , 2 , 3 ] 3 - element Vector { Int64 } : 1 2 3 julia > a [ 2 ] = 22 22 julia > a 3 - element Vector { Int64 } : 1 22 3","title":"Indexing"},{"location":"econ890/julia/arrays.html#ranges","text":"In Matlab, 1:3 is a Vector , but not in Julia: julia > 1 : 3 1 : 3 julia > typeof ( 1 : 3 ) UnitRange { Int64 } The main difference between a Vector and a Range is that the vector is allocated upon construction (its values are computed and stored in memory). A Range is an Iterator . You can iteratore over its elements, but they are not computed until needed. Therefore, the Range does not allocate memory. This is a big deal when lots of values are involved. However, a Range is an AbstractArray ; so all the indexing that works on Vectors also works on Range s. collect makes a Range into a Vector .","title":"Ranges"},{"location":"econ890/julia/arrays.html#exercises","text":"Start with x = 1 : 3 : 30 . Find all even elements. Find all elements between 5 and 20. Set all even elements to their negative values.","title":"Exercises"},{"location":"econ890/julia/arrays.html#matrices","text":"A Matrix is a 2-dimensional array. There are also n-dimensional arrays (see below). To create a matrix, simply fill it with values. julia > a = [ 1 2 3 ; 4 5 6 ] 2 \u00d73 Array { Int64 , 2 } : 1 2 3 4 5 6 Many commands work directly on matrices. julia > a = [ 1 2 3 ]; b = [ 2 ; 1 ; 1 ]; a * b 1 - element Array { Int64 , 1 } : 7 julia > c = b * a 3 \u00d73 Array { Int64 , 2 } : 2 4 6 1 2 3 1 2 3 To extract elements: julia > c [ 1 , 2 ] 4 julia > c [ 1 : 2 , 2 : 3 ] 2 \u00d72 Array { Int64 , 2 } : 4 6 2 3 To extract a row (but note that this produces a Vector ): julia > c [ 1 , : ] 3 - element Array { Int64 , 1 } : 2 4 6 Linear indexing works as well: julia > c [ 4 ] 4 julia > c [ 4 ] == c [ 1 , 2 ] true In memory, Arrays are stored like Vectors . The compiler just keeps track of how the user wants to interpret the data.","title":"Matrices"},{"location":"econ890/julia/arrays.html#multi-dimensional-arrays","text":"Arrays can have more than 2 dimensions. julia > using Random julia > a = rand ( 4 , 3 , 2 ) 4 \u00d73\u00d72 Array { Float64 , 3 } : [ : , : , 1 ] = 0.146411 0.908415 0.568039 0.444156 0.434034 0.875361 0.429705 0.704086 0.71789 0.502228 0.124412 0.771808 [ : , : , 2 ] = 0.862953 0.58189 0.549077 0.722745 0.677342 0.330188 0.0543144 0.161877 0.358381 0.312414 0.0681076 0.822319 Indexing generates new arrays with potentially fewer dimensions: julia > a [ : , 1 , : ] 4 \u00d72 Array { Float64 , 2 } : 0.146411 0.862953 0.444156 0.722745 0.429705 0.0543144 0.502228 0.312414","title":"Multi-dimensional Arrays"},{"location":"econ890/julia/arrays.html#array-exercises","text":"Construct a matrix A with elements [2,4,...,20] in row 1 and [1,4,7,...,28] in row 2. Replace row 1 with its square. Find all columns where row 1 > row 2. Let x=ones(10,1) . Compute Ax .","title":"Array Exercises"},{"location":"econ890/julia/code_loading.html","text":"Code Loading \u00b6 When you write a file with some code, how does Julia know where to find it? From the REPL include(/path/to/file.jl) does the trick. This has the same effect as typing the code in the REPL. The same can be done inside another file. But what if you have a big chunk of code that you want to be reusable? What if you want to use someone else's code? This is where packages come into play. The LOAD_PATH \u00b6 You can also load modules that are not packaged as packages by putting their directories into the LOAD_PATH environment variable. We will not use this approach. It is easier to package everything as a package instead.","title":"Code Loading"},{"location":"econ890/julia/code_loading.html#code-loading","text":"When you write a file with some code, how does Julia know where to find it? From the REPL include(/path/to/file.jl) does the trick. This has the same effect as typing the code in the REPL. The same can be done inside another file. But what if you have a big chunk of code that you want to be reusable? What if you want to use someone else's code? This is where packages come into play.","title":"Code Loading"},{"location":"econ890/julia/code_loading.html#the-load_path","text":"You can also load modules that are not packaged as packages by putting their directories into the LOAD_PATH environment variable. We will not use this approach. It is easier to package everything as a package instead.","title":"The LOAD_PATH"},{"location":"econ890/julia/debugging.html","text":"Debugging \u00b6 Some general notes and tips on debuggers are here . The Upshot \u00b6 I almost never use a debugger (put tastes vary). My main debugging tool is Infiltrator.jl . It works like Matlab 's keyboard command (though it's a bit less powerful). Example: examples/infiltrator.jl . Another good option is Exfiltrator.jl (which is all of 37 lines of code!). Stacktraces \u00b6 A stacktrace shows the stack of functions that were called to get to a particular line of code. You mostly see them where there is an error. Here is a contrived example: julia > foo ( x ) = sin ( UInt8 ( x )) foo ( generic function with 2 methods ) julia > foo ( 1234567 ) ERROR : InexactError : trunc ( UInt8 , 1234567 ) Stacktrace : [ 1 ] throw_inexacterror ( f :: Symbol , #unused#::Type{UInt8}, val::Int64) @ Core ./ boot . jl : 602 [ 2 ] checked_trunc_uint @ ./ boot . jl : 632 [ inlined ] [ 3 ] toUInt8 @ ./ boot . jl : 694 [ inlined ] [ 4 ] UInt8 @ ./ boot . jl : 754 [ inlined ] [ 5 ] foo ( x :: Int64 ) @ Main ./ REPL [ 16 ] : 1 [ 6 ] top - level scope @ REPL [ 17 ] : 1 Stacktraces are often very long and look confusing. There are 2 key lines: ERROR: Inexacterror: ... : this tells you what went wrong. [5] foo(x::Int64) : this is the line of your code that caused the error. Entries [1] to [4] are Base code that you did not write. This will generally be correct and is often irrelevant. The key is to patiently parse the stacktrace until you understand what actually went wrong. InexactError tells you that something was truncated. It even tells you the instruction that went wrong: trunc(Uint8, 1234567) . In words this says: You told me to convert a big Int64 to a UInt8 . This caused an overflow. Common mistakes \u00b6 Passing arguments in the wrong order. \u00b6 Often functions have lots of input arguments. This is generally a sign of poor design, but sometimes hard to avoid in economic applications. It is easy to confuse the order and write myfun(b,a) instead of myfun(a,b) . To avoid this: check that inputs have admissible values. Reusing variable names. \u00b6 It is easy to use a variable name twice without noticing. This can produce tricky bugs. One way of avoiding this: keep your functions short . Some experts advocate that functions should be 4 lines of code or less. This is probably not realistic, but you get the idea. Indexing problems. \u00b6 It is easy to make mistakes when extracting elements from matrices. This is especially true for code that wraps a loop into a single line of code. For example, this is easy to read: for ix = 1 : nx zV [ ix ] = xV [ ix + 2 ] + yV [ nx + 2 - ix ]; end This is the same thing, more compact but harder to read: zV = xV [ 3 : nx + 2 ] .+ yV [ nx + 1 : - 1 : 2 ]; Tip: Write out code explicitly. Once it works, one can still make it faster (if that is even worthwhile). You can keep the slow version in a unit test. Note that vectorizing code does not improve speed in Julia (unless you exploit the parallel execution capabilities of modern CPUs). Another common indexing mistake is to use too few arguments. For example: x = rand ([ 3 , 4 ]); y = x ( 3 ); This should produce a syntax error, but it does not. Instead, it flattens x into a vector and then takes the 3rd element.","title":"Debugging"},{"location":"econ890/julia/debugging.html#debugging","text":"Some general notes and tips on debuggers are here .","title":"Debugging"},{"location":"econ890/julia/debugging.html#the-upshot","text":"I almost never use a debugger (put tastes vary). My main debugging tool is Infiltrator.jl . It works like Matlab 's keyboard command (though it's a bit less powerful). Example: examples/infiltrator.jl . Another good option is Exfiltrator.jl (which is all of 37 lines of code!).","title":"The Upshot"},{"location":"econ890/julia/debugging.html#stacktraces","text":"A stacktrace shows the stack of functions that were called to get to a particular line of code. You mostly see them where there is an error. Here is a contrived example: julia > foo ( x ) = sin ( UInt8 ( x )) foo ( generic function with 2 methods ) julia > foo ( 1234567 ) ERROR : InexactError : trunc ( UInt8 , 1234567 ) Stacktrace : [ 1 ] throw_inexacterror ( f :: Symbol , #unused#::Type{UInt8}, val::Int64) @ Core ./ boot . jl : 602 [ 2 ] checked_trunc_uint @ ./ boot . jl : 632 [ inlined ] [ 3 ] toUInt8 @ ./ boot . jl : 694 [ inlined ] [ 4 ] UInt8 @ ./ boot . jl : 754 [ inlined ] [ 5 ] foo ( x :: Int64 ) @ Main ./ REPL [ 16 ] : 1 [ 6 ] top - level scope @ REPL [ 17 ] : 1 Stacktraces are often very long and look confusing. There are 2 key lines: ERROR: Inexacterror: ... : this tells you what went wrong. [5] foo(x::Int64) : this is the line of your code that caused the error. Entries [1] to [4] are Base code that you did not write. This will generally be correct and is often irrelevant. The key is to patiently parse the stacktrace until you understand what actually went wrong. InexactError tells you that something was truncated. It even tells you the instruction that went wrong: trunc(Uint8, 1234567) . In words this says: You told me to convert a big Int64 to a UInt8 . This caused an overflow.","title":"Stacktraces"},{"location":"econ890/julia/debugging.html#common-mistakes","text":"","title":"Common mistakes"},{"location":"econ890/julia/debugging.html#passing-arguments-in-the-wrong-order","text":"Often functions have lots of input arguments. This is generally a sign of poor design, but sometimes hard to avoid in economic applications. It is easy to confuse the order and write myfun(b,a) instead of myfun(a,b) . To avoid this: check that inputs have admissible values.","title":"Passing arguments in the wrong order."},{"location":"econ890/julia/debugging.html#reusing-variable-names","text":"It is easy to use a variable name twice without noticing. This can produce tricky bugs. One way of avoiding this: keep your functions short . Some experts advocate that functions should be 4 lines of code or less. This is probably not realistic, but you get the idea.","title":"Reusing variable names."},{"location":"econ890/julia/debugging.html#indexing-problems","text":"It is easy to make mistakes when extracting elements from matrices. This is especially true for code that wraps a loop into a single line of code. For example, this is easy to read: for ix = 1 : nx zV [ ix ] = xV [ ix + 2 ] + yV [ nx + 2 - ix ]; end This is the same thing, more compact but harder to read: zV = xV [ 3 : nx + 2 ] .+ yV [ nx + 1 : - 1 : 2 ]; Tip: Write out code explicitly. Once it works, one can still make it faster (if that is even worthwhile). You can keep the slow version in a unit test. Note that vectorizing code does not improve speed in Julia (unless you exploit the parallel execution capabilities of modern CPUs). Another common indexing mistake is to use too few arguments. For example: x = rand ([ 3 , 4 ]); y = x ( 3 ); This should produce a syntax error, but it does not. Instead, it flattens x into a vector and then takes the 3rd element.","title":"Indexing problems."},{"location":"econ890/julia/econ_examples.html","text":"Econ Examples \u00b6 Example: Two period household \u00b6 Household solves \\(\\max u\\left(c,g\\right)\\) subject to \\(y=c+s \\) and \\(g=z+sR\\) A solution: \\(c,g,s\\) that solve 2 budget constraints and Euler equation \\(u_{c}=u_{g} R \\) Assume \\(u\\left(c,g\\right)=\\frac{c^{1-\\sigma}}{1-\\sigma}+\\beta\\frac{g^{1-\\sigma}}{1-\\sigma} \\) Pseudo code \u00b6 This is not a trivial program to write. So we break it down into trivial steps. See Tips on programming We design top-down. Level 1: \u00b6 Task: Find optimal \\(c\\). Set parameters. Set up a grid of values for c For each c: Calculate deviation from Euler equation. Find the c with the smallest deviation. Note: Usually one would not restrict \\(c\\) to lie on a grid. Level 2: \u00b6 Task: Calculate deviation from Euler equation. Given: guess for \\(c\\), parameter values Use budget constraints to calculate \\(s,g\\) Return deviation: \\( dev=u_{c}-u_{g}R \\) Level 3: \u00b6 Utility function. Return \\(u_{c} \\) and \\(u_{g} \\) for given \\(c,g\\) and parameters. Code \u00b6 We write the code bottom up. Utility function: Allow matrix inputs (cM, gM). Parameters as arguments. This should really be a general purpose function (my library contains an OOP version ). Sample call: >> hh_example_821 ( 2 , 0.5 , 1.04 , 0.9 , 1.5 ) c = 1.224490 Dev = 0.034947 Exercises \u00b6 Write a CES utility function that computes \\(u'(c)\\) and \\(u(c)\\). Write a function that computes the inverse of \\(u'(c)\\). Write a test function that checks properties of the utility function: The inverse of the inverse equals \\(u'(c)\\). Marginal utility is decreasing. Extra credit: Package all of that into an object (a user defined data type). Now write all of this for \\(u(c)=e^{-\\phi c}\\). In your test function, set things up so that you only need to change a single line of code to test both utility functions (the benefit of OOP in action).","title":"Econ Examples"},{"location":"econ890/julia/econ_examples.html#econ-examples","text":"","title":"Econ Examples"},{"location":"econ890/julia/econ_examples.html#example-two-period-household","text":"Household solves \\(\\max u\\left(c,g\\right)\\) subject to \\(y=c+s \\) and \\(g=z+sR\\) A solution: \\(c,g,s\\) that solve 2 budget constraints and Euler equation \\(u_{c}=u_{g} R \\) Assume \\(u\\left(c,g\\right)=\\frac{c^{1-\\sigma}}{1-\\sigma}+\\beta\\frac{g^{1-\\sigma}}{1-\\sigma} \\)","title":"Example: Two period household"},{"location":"econ890/julia/econ_examples.html#pseudo-code","text":"This is not a trivial program to write. So we break it down into trivial steps. See Tips on programming We design top-down.","title":"Pseudo code"},{"location":"econ890/julia/econ_examples.html#level-1","text":"Task: Find optimal \\(c\\). Set parameters. Set up a grid of values for c For each c: Calculate deviation from Euler equation. Find the c with the smallest deviation. Note: Usually one would not restrict \\(c\\) to lie on a grid.","title":"Level 1:"},{"location":"econ890/julia/econ_examples.html#level-2","text":"Task: Calculate deviation from Euler equation. Given: guess for \\(c\\), parameter values Use budget constraints to calculate \\(s,g\\) Return deviation: \\( dev=u_{c}-u_{g}R \\)","title":"Level 2:"},{"location":"econ890/julia/econ_examples.html#level-3","text":"Utility function. Return \\(u_{c} \\) and \\(u_{g} \\) for given \\(c,g\\) and parameters.","title":"Level 3:"},{"location":"econ890/julia/econ_examples.html#code","text":"We write the code bottom up. Utility function: Allow matrix inputs (cM, gM). Parameters as arguments. This should really be a general purpose function (my library contains an OOP version ). Sample call: >> hh_example_821 ( 2 , 0.5 , 1.04 , 0.9 , 1.5 ) c = 1.224490 Dev = 0.034947","title":"Code"},{"location":"econ890/julia/econ_examples.html#exercises","text":"Write a CES utility function that computes \\(u'(c)\\) and \\(u(c)\\). Write a function that computes the inverse of \\(u'(c)\\). Write a test function that checks properties of the utility function: The inverse of the inverse equals \\(u'(c)\\). Marginal utility is decreasing. Extra credit: Package all of that into an object (a user defined data type). Now write all of this for \\(u(c)=e^{-\\phi c}\\). In your test function, set things up so that you only need to change a single line of code to test both utility functions (the benefit of OOP in action).","title":"Exercises"},{"location":"econ890/julia/functions.html","text":"Functions \u00b6 The code base for big projects is very complex -- possibly tens of thousands of lines of code. How to make this comprehensible for humans? A key idea of structured programming : package code into self-contained functions avoid side effects A function should only change the rest of the world through the outputs it explicitly returns. This is called encapsulation . Then we can reason about small pieces of code in isolation. We don't have to worry about what the other code does. Rule of thumb: All of your code should be inside functions. Scripts \u00b6 Scripts are simply collections of commands that are run as if they were typed at the command prompt. Example \u00b6 Create a file called test1.jl that contains x = 2 ; println ( \"We defined x to be $x \" ); Now running this file with include(\"test1.jl\") is exactly the same as typing those lines in the REPL. julia > include ( \"test1.jl\" ) We defined x to be 2 julia > x 2 Note that the value of x \"leaks out\" of the script -- exactly as if we had typed the code in the REPL. In computer lingo, the script runs in the global namespace . More precisely, everything in the script becomes a global object in the Main module. This is bad! Everything is visible everywhere. To avoid polluting the global namespace, we use functions. Rule of thumb: Always use functions, never scripts! Functions \u00b6 Functions are similar to scripts with one crucial difference: All variables inside a function are private . Other functions cannot see the variables inside a function ( encapsulation ). Any variable a function should know must be passed to it as an input argument. Any variable to be retained after the function finishes must be passed out of it as a return argument. A function looks like this: function f ( x , y ) # Do stuff with x and y -> z return z end It takes two inputs ( x, y ), hopefully without modifying them, and affects the rest of the world only through its return value z . A side note: Even built-in commands are often written in Julia. Encapsulation \u00b6 A function creates a local scope or a namespace . Only items explicitly defined in the namespace are visible there. Note: Module s are another way of creating a namespace. We will talk about those soon. By default, all objects are local : they are only visible inside the current function. Some objects are explicitly declared global : they are visible everywhere (in the current module ). Rule: Avoid globals like the plague, unless they are constants. Example: \u00b6 julia > function f ( x ) a = 5 ; y = x + a ; return y end f ( generic function with 1 method ) julia > a = 3 ; julia > y = f ( 0 ) 5 julia > a # Calling `f` did not change `a` on the \"outside\" 3 # Now the converse julia > function g ( x ) # Note that `a` is not defined in `g` z = x + a ; end g ( generic function with 1 method ) julia > g ( 1 ) 4 # `g` used the `global a` Note that g could see the variable a=3 defined in the REPL, but not the a inside of f . Setting a=3 in the REPL defined a global variable which is visible everywhere. Defining a variable inside a function produces a local variable instead. Passing by reference \u00b6 What happens if we modify a function argument? Are the changes visible on the outside? In Julia, the answer is \"yes\" (unless an objects is immutable ). Variables are passed into functions \"by reference.\" Modifying a function argument changes its value after the function returns julia > function h ( x ) x [ 1 ] = 2 ; println ( x ); return nothing end h ( generic function with 1 method ) julia > z = [ 1 , 2 ]; julia > h ( z ) [ 2 , 2 ] julia > z 2 - element Array { Int64 , 1 } : 2 2 But note that this does not happen when the argument is immutable . julia > function h2 ( x ) x = 19 ; @show x ; return nothing end h2 ( generic function with 1 method ) julia > z = \"input\" \"input\" julia > h2 ( z ) x = 19 julia > z \"input\" Generally, it is cleaner to avoid mutating arguments. But this can be inefficient. When arguments are mutated, the function name should end in ! . Example julia > x = [ 3 , 1 , 4 , 2 ] 4 - element Vector { Int64 } : 3 1 4 2 julia > sort ( x ) 4 - element Vector { Int64 } : 1 2 3 4 julia > x 4 - element Vector { Int64 } : 3 1 4 2 julia > sort! ( x ); julia > x 4 - element Vector { Int64 } : 1 2 3 4 Global Variables \u00b6 To make a variable visible from anywhere, define it as a global . Remark: Avoid globals where possible. Unless they are constants. A function should be a self-contained unit with a clear interface to the outside world (via its input and output arguments). Globals create confusion.","title":"Functions"},{"location":"econ890/julia/functions.html#functions","text":"The code base for big projects is very complex -- possibly tens of thousands of lines of code. How to make this comprehensible for humans? A key idea of structured programming : package code into self-contained functions avoid side effects A function should only change the rest of the world through the outputs it explicitly returns. This is called encapsulation . Then we can reason about small pieces of code in isolation. We don't have to worry about what the other code does. Rule of thumb: All of your code should be inside functions.","title":"Functions"},{"location":"econ890/julia/functions.html#scripts","text":"Scripts are simply collections of commands that are run as if they were typed at the command prompt.","title":"Scripts"},{"location":"econ890/julia/functions.html#example","text":"Create a file called test1.jl that contains x = 2 ; println ( \"We defined x to be $x \" ); Now running this file with include(\"test1.jl\") is exactly the same as typing those lines in the REPL. julia > include ( \"test1.jl\" ) We defined x to be 2 julia > x 2 Note that the value of x \"leaks out\" of the script -- exactly as if we had typed the code in the REPL. In computer lingo, the script runs in the global namespace . More precisely, everything in the script becomes a global object in the Main module. This is bad! Everything is visible everywhere. To avoid polluting the global namespace, we use functions. Rule of thumb: Always use functions, never scripts!","title":"Example"},{"location":"econ890/julia/functions.html#functions_1","text":"Functions are similar to scripts with one crucial difference: All variables inside a function are private . Other functions cannot see the variables inside a function ( encapsulation ). Any variable a function should know must be passed to it as an input argument. Any variable to be retained after the function finishes must be passed out of it as a return argument. A function looks like this: function f ( x , y ) # Do stuff with x and y -> z return z end It takes two inputs ( x, y ), hopefully without modifying them, and affects the rest of the world only through its return value z . A side note: Even built-in commands are often written in Julia.","title":"Functions"},{"location":"econ890/julia/functions.html#encapsulation","text":"A function creates a local scope or a namespace . Only items explicitly defined in the namespace are visible there. Note: Module s are another way of creating a namespace. We will talk about those soon. By default, all objects are local : they are only visible inside the current function. Some objects are explicitly declared global : they are visible everywhere (in the current module ). Rule: Avoid globals like the plague, unless they are constants.","title":"Encapsulation"},{"location":"econ890/julia/functions.html#example_1","text":"julia > function f ( x ) a = 5 ; y = x + a ; return y end f ( generic function with 1 method ) julia > a = 3 ; julia > y = f ( 0 ) 5 julia > a # Calling `f` did not change `a` on the \"outside\" 3 # Now the converse julia > function g ( x ) # Note that `a` is not defined in `g` z = x + a ; end g ( generic function with 1 method ) julia > g ( 1 ) 4 # `g` used the `global a` Note that g could see the variable a=3 defined in the REPL, but not the a inside of f . Setting a=3 in the REPL defined a global variable which is visible everywhere. Defining a variable inside a function produces a local variable instead.","title":"Example:"},{"location":"econ890/julia/functions.html#passing-by-reference","text":"What happens if we modify a function argument? Are the changes visible on the outside? In Julia, the answer is \"yes\" (unless an objects is immutable ). Variables are passed into functions \"by reference.\" Modifying a function argument changes its value after the function returns julia > function h ( x ) x [ 1 ] = 2 ; println ( x ); return nothing end h ( generic function with 1 method ) julia > z = [ 1 , 2 ]; julia > h ( z ) [ 2 , 2 ] julia > z 2 - element Array { Int64 , 1 } : 2 2 But note that this does not happen when the argument is immutable . julia > function h2 ( x ) x = 19 ; @show x ; return nothing end h2 ( generic function with 1 method ) julia > z = \"input\" \"input\" julia > h2 ( z ) x = 19 julia > z \"input\" Generally, it is cleaner to avoid mutating arguments. But this can be inefficient. When arguments are mutated, the function name should end in ! . Example julia > x = [ 3 , 1 , 4 , 2 ] 4 - element Vector { Int64 } : 3 1 4 2 julia > sort ( x ) 4 - element Vector { Int64 } : 1 2 3 4 julia > x 4 - element Vector { Int64 } : 3 1 4 2 julia > sort! ( x ); julia > x 4 - element Vector { Int64 } : 1 2 3 4","title":"Passing by reference"},{"location":"econ890/julia/functions.html#global-variables","text":"To make a variable visible from anywhere, define it as a global . Remark: Avoid globals where possible. Unless they are constants. A function should be a self-contained unit with a clear interface to the outside world (via its input and output arguments). Globals create confusion.","title":"Global Variables"},{"location":"econ890/julia/getting_started.html","text":"Installing Julia \u00b6 I recommend running Julia from a terminal window with Visual Studio Code as editor. Installation hints Info on VS Code You may have another favorite text editor, but you will lose integration with the Julia language. Useful guides to getting started: QuantEcon The Julia documentation is really very good. It should be your go-to place for getting started. I find it useful to install a documentation browser (on MacOS that would be Dash ). It is faster to interact with the docs this way. Installation details \u00b6 Download the binary for your platform. Follow the instructions in the \"help\" link for your platform. You should add a path to the Julia binary in the terminal. Try that you can start Julia by typing julia from a terminal window. You should see the REPL . If this fails, create a symlink (linux or macos) to the julia binary. The installation instructions describe how to do this, depending on the OS. Interacting with Julia \u00b6 At the terminal, type julia to start a Julia session. You will see the REPL, which is similar to Matlab's command line. At the REPL, you can type any Julia command and see the results displayed. Note the REPL inputs (and all Julia commands) are case sensitive. ? switches to REPL help mode . For example, ?abs will give help on the abs function: ? abs abs ( x ) The absolute value of `x` . When `abs` is applied to signed integers , overflow may occur , resulting in the return of a negative value . This overflow occurs only when `abs` is applied to the minimum representable value of a signed integer . That is , when `x == typemin(typeof(x))` , `abs(x) == x < 0` , not `-x` as might be expected . # Examples [ ... ] Hint: A documentation browser, such as Dash makes life a lot easier. After Installation \u00b6 Once Julia is installed and running, it is useful to install a few helper packages. In the REPL, type using Pkg; Pkg.add(\"OhMyREPL\"); Pkg.add(\"Revise\"); This will take some time to execute. OhMyREPL formats REPL output. Revise.jl is practically a required package. It massively improves the Julia workflow. After making changes to installed packages, you should always restart the REPL. Ctrl-D quits the REPL. Edit \"~/.julia/config/startup.jl\" and add the line using OhMyREPL, Revise . This ensures that those packages are used every time you start Julia. Hint: Set the JULIA_EDITOR environment variable to point to your editor. For VSCode: julia > ENV [ \"JULIA_EDITOR\" ] \"/usr/local/bin/code\" This allows you to open files by either clicking on file paths in the REPL (if your terminal supports this) or by typing edit(path/to/file.jl) . To check that everything worked correctly, start Julia and type Revise at the REPL prompt. Make sure this does not give an error message. Configure VSCode \u00b6 Install the Julia VS Code extension. Set the julia.executablePath to point to the Julia binary. If you created a symlink as recommended above, that would be /usr/local/bin/julia (on MacOS / Linux). See also VSCode: the future for Julia development - TechyTok Check point: Everybody should have Julia 1.6 installed and running. a good text editor with the Julia extension running.","title":"Installing Julia"},{"location":"econ890/julia/getting_started.html#installing-julia","text":"I recommend running Julia from a terminal window with Visual Studio Code as editor. Installation hints Info on VS Code You may have another favorite text editor, but you will lose integration with the Julia language. Useful guides to getting started: QuantEcon The Julia documentation is really very good. It should be your go-to place for getting started. I find it useful to install a documentation browser (on MacOS that would be Dash ). It is faster to interact with the docs this way.","title":"Installing Julia"},{"location":"econ890/julia/getting_started.html#installation-details","text":"Download the binary for your platform. Follow the instructions in the \"help\" link for your platform. You should add a path to the Julia binary in the terminal. Try that you can start Julia by typing julia from a terminal window. You should see the REPL . If this fails, create a symlink (linux or macos) to the julia binary. The installation instructions describe how to do this, depending on the OS.","title":"Installation details"},{"location":"econ890/julia/getting_started.html#interacting-with-julia","text":"At the terminal, type julia to start a Julia session. You will see the REPL, which is similar to Matlab's command line. At the REPL, you can type any Julia command and see the results displayed. Note the REPL inputs (and all Julia commands) are case sensitive. ? switches to REPL help mode . For example, ?abs will give help on the abs function: ? abs abs ( x ) The absolute value of `x` . When `abs` is applied to signed integers , overflow may occur , resulting in the return of a negative value . This overflow occurs only when `abs` is applied to the minimum representable value of a signed integer . That is , when `x == typemin(typeof(x))` , `abs(x) == x < 0` , not `-x` as might be expected . # Examples [ ... ] Hint: A documentation browser, such as Dash makes life a lot easier.","title":"Interacting with Julia"},{"location":"econ890/julia/getting_started.html#after-installation","text":"Once Julia is installed and running, it is useful to install a few helper packages. In the REPL, type using Pkg; Pkg.add(\"OhMyREPL\"); Pkg.add(\"Revise\"); This will take some time to execute. OhMyREPL formats REPL output. Revise.jl is practically a required package. It massively improves the Julia workflow. After making changes to installed packages, you should always restart the REPL. Ctrl-D quits the REPL. Edit \"~/.julia/config/startup.jl\" and add the line using OhMyREPL, Revise . This ensures that those packages are used every time you start Julia. Hint: Set the JULIA_EDITOR environment variable to point to your editor. For VSCode: julia > ENV [ \"JULIA_EDITOR\" ] \"/usr/local/bin/code\" This allows you to open files by either clicking on file paths in the REPL (if your terminal supports this) or by typing edit(path/to/file.jl) . To check that everything worked correctly, start Julia and type Revise at the REPL prompt. Make sure this does not give an error message.","title":"After Installation"},{"location":"econ890/julia/getting_started.html#configure-vscode","text":"Install the Julia VS Code extension. Set the julia.executablePath to point to the Julia binary. If you created a symlink as recommended above, that would be /usr/local/bin/julia (on MacOS / Linux). See also VSCode: the future for Julia development - TechyTok Check point: Everybody should have Julia 1.6 installed and running. a good text editor with the Julia extension running.","title":"Configure VSCode"},{"location":"econ890/julia/learning.html","text":"Learning Julia \u00b6 The documentation is a must-read. It is long and probably hard to understand the first time around. Like with all complex material, read it again and again. The Julia Discourse is a great place to ask questions and get expert answers. Be sure to first read the PSA . Skimming the replies of experienced people is a great way of discovering language features and packages that you did not know about.","title":"Learning Julia"},{"location":"econ890/julia/learning.html#learning-julia","text":"The documentation is a must-read. It is long and probably hard to understand the first time around. Like with all complex material, read it again and again. The Julia Discourse is a great place to ask questions and get expert answers. Be sure to first read the PSA . Skimming the replies of experienced people is a great way of discovering language features and packages that you did not know about.","title":"Learning Julia"},{"location":"econ890/julia/methods.html","text":"Methods and Multiple Dispatch \u00b6 Now we get to one of the key distinguishing features of Julia: multiple dispatch. Methods \u00b6 When we create a function, we get a strange status message: julia > baz ( x ) = 2 * x baz ( generic function with 1 method ) We just created a \"generic function\" (we will pretty much never worry about what that means) with 1 method . But now try julia > function foo end foo ( generic function with 0 methods ) We just created a function foo with 0 methods . What does this mean? If we try to call foo , we get a MethodError : julia > foo ( 1 ) ERROR : MethodError : no method matching foo ( :: Int64 ) Now let's define a method : julia > foo ( x :: Int ) = @show x foo ( generic function with 1 method ) julia > foo ( 10 ) x = 10 And a second one: julia > foo ( x :: String ) = println ( \" $x is a string\" ) foo ( generic function with 2 methods ) julia > foo ( \"abc\" ) abc is a string What methods do we have? julia > methods ( foo ) # 2 methods for generic function \"foo\": [ 1 ] foo ( x :: String ) in Main at REPL [ 4 ] : 1 [ 2 ] foo ( x :: Int64 ) in Main at REPL [ 5 ] : 1 Calling foo with anything other than an Int or String produces a MethodError . So what are functions and methods? A function is just a name. We actually cannot do anything with it. A method specifies what to do when we call foo with a specific set of arguments. Key point: foo(x::Int) and foo(x::String) are not different functions. They are methods of the same function . A function is really a way of grouping method s. Multiple Dispatch \u00b6 What do methods do? When we call foo(1) , the compiler looks in the method table for a method that matches the signature foo(::Int64) . If this exists, it is compiled and run. And, yes, it is compiled only when called. If this does not exist, we get a MethodError . Methods allow us to execute different code for the same function call, depending on the type of the input argument. julia > foo ( 1 ); x = 1 julia > foo ( \"abc\" ); abc is a string Why do we want this to happen? Benefit 1: We don't have to worry about name conflicts Contrast with Matlab: There can only be one function (and method) named foo . Every time to write a function, you need to create a globally unique name. This makes code reuse very difficult. If two libraries contain a function foo , they cannot both be used at the same time. In Julia: You can always create a new method foo(::Int64) , even if foo is already defined. You only get an error if the exact method foo(::Int64) already exists. Benefit 2: Generic programming We can write an algorithm that can handle any type of input object. See below. This is similar to object oriented programming where method s are owned by specific objects. The key difference is that, in Julia, this also works with multiple arguments: julia > foo ( x , y ) = @show x , y foo ( generic function with 3 methods ) julia > foo ( x :: String , y ) = println ( \" $x is a string, but $y can be anything\" ) foo ( generic function with 4 methods ) julia > foo ( 1 , 2 ) ( x , y ) = ( 1 , 2 ) ( 1 , 2 ) julia > foo ( \"abc\" , 2 ); abc is a string , but 2 can be anything Notes: We can have methods that have different numbers of arguments (here: 1 or 2). If we have two methods with the same number of arguments, the more specific one is called. foo(x,y) is a fallback method that gets called unless a more specific method exists. There is a famous talk by Stefan Karpinski called \"The unreasonable effectiveness of multiple dispatch\" which explains why this is so powerful. Type Annotations \u00b6 What happens if we omit type annotations? julia > foo ( x , y ) = @show x , y foo ( generic function with 1 method ) Julia tells us that we have one method. But actually, we have infinitely many! Try foo(1, \"a\") or foo([1,2], [\"a\" \"b\"]) . They all work. foo(x,y) is actually a shorthand for julia > foo ( x :: T1 , y :: T2 ) where { T1 <: Any , T2 <: Any } which is the same as julia > foo ( x :: Any , y :: Any ) In words, we have implicitly defined a method for any combination of types for (x,y) . Here is a key point for performance: Julia still specializes the code for each combination of types that we actually use. This means: When we call foo(1,2) , Julia compiles foo(::Int64, ::Int64) and calls that method. It follows that we get the same performance as if we had defined foo(::Int64, ::Int64) by hand. Type annotations have no effect on performance. Why then do we need them? Avoiding name conflicts (again). Suppose you have an object for which you want to define name(x) . You can define name(x :: MyType) without worrying about name conflicts. Different code for different types. Consider the example of show(x) . Clearly, each object needs its own show method. There is \"generic\" useful way of showing an object in the REPL. This is typical for \"low level\" operations. For example, + works differently (at the hardware level) for Float64 vs UInt8 . Example \u00b6 Write a function myshow(x) that prints that value of x with a little type annotation: julia > myshow ( 1 ) \"Int64 1\" julia > myshow ( 1.2345 ) # Note the rounding! \"Float64 1.2\" julia > myshow ( \"any other type\" ) \"I do not know this type: String\" Generic Programming \u00b6 Suppose I want to sort the Vector x = [1, \"a\", 4, 2] . Calling sort(x) gives an error: ERROR: MethodError: no method matching isless(::String, ::Int64) Now let's define that missing method and see what happens: julia > Base . isless ( x :: String , y :: Number ) = true julia > sort ([ 3 , 1 , \"a\" , 4 , 2 ]) 5 - element Vector { Any } : \"a\" 1 2 3 4 The sorting algorithm is generic . It works on any Vector as long as isless(x,y) is defined. This makes the algorithm highly reusable. We can define a new DataType and apply the existing sorting algorithms. Conversely, we can write algorithms without type annotations. They will just work on any type (even if defined \"after the fact\") that supports a few methods. This is not only possible, it is very common in Julia. Extending existing functions \u00b6 For this to work, we need to be able to extend functions that were defined by others (in modules, including Base ) to new data types. This is exactly what we did in our sorting example: For example, suppose we want to be able to sum String s (this is a bad idea, but we can do it): julia > Base . isless ( x :: String , y :: Number ) = true Note that we wrote Base.isless , not just isless . Had we written julia > isless ( x :: String , y :: Number ) = true we would have defined a new function Main.isless , not a new method. Then calling sort[1, \"abc\"] would have failed with the same MethodError that we originally encountered. The reason is that sort lives in module Base (we talk soon about what modules are). Therefore, any unqualified call to isless translates into Base.isless , which is a different function (not method) from Main.isless . Another, less clear, way of extending an existing function: julia > import Base : isless julia > isless ( x :: String , y :: Number ) = true More on Type Annotations \u00b6 We can annotate types in various ways. # No annotation foo ( x , y ) == foo ( x :: Any , y :: Any ) # Give an abstract type # Defines one method for each concrete T <: Real foo ( x :: Real ) == foo ( x :: T ) where T <: Real # Concrete types foo ( x :: Float64 ) Again: none of this has any impact on performance. We can impose type restrictions: # Force (x,y) to be the same type # where T is the same as `where T <: Any` foo ( x :: T , y :: T ) where T # Now this works foo ( 1 , 2 ) # and this errors foo ( 1 , 2.0 )","title":"Methods and Multiple Dispatch"},{"location":"econ890/julia/methods.html#methods-and-multiple-dispatch","text":"Now we get to one of the key distinguishing features of Julia: multiple dispatch.","title":"Methods and Multiple Dispatch"},{"location":"econ890/julia/methods.html#methods","text":"When we create a function, we get a strange status message: julia > baz ( x ) = 2 * x baz ( generic function with 1 method ) We just created a \"generic function\" (we will pretty much never worry about what that means) with 1 method . But now try julia > function foo end foo ( generic function with 0 methods ) We just created a function foo with 0 methods . What does this mean? If we try to call foo , we get a MethodError : julia > foo ( 1 ) ERROR : MethodError : no method matching foo ( :: Int64 ) Now let's define a method : julia > foo ( x :: Int ) = @show x foo ( generic function with 1 method ) julia > foo ( 10 ) x = 10 And a second one: julia > foo ( x :: String ) = println ( \" $x is a string\" ) foo ( generic function with 2 methods ) julia > foo ( \"abc\" ) abc is a string What methods do we have? julia > methods ( foo ) # 2 methods for generic function \"foo\": [ 1 ] foo ( x :: String ) in Main at REPL [ 4 ] : 1 [ 2 ] foo ( x :: Int64 ) in Main at REPL [ 5 ] : 1 Calling foo with anything other than an Int or String produces a MethodError . So what are functions and methods? A function is just a name. We actually cannot do anything with it. A method specifies what to do when we call foo with a specific set of arguments. Key point: foo(x::Int) and foo(x::String) are not different functions. They are methods of the same function . A function is really a way of grouping method s.","title":"Methods"},{"location":"econ890/julia/methods.html#multiple-dispatch","text":"What do methods do? When we call foo(1) , the compiler looks in the method table for a method that matches the signature foo(::Int64) . If this exists, it is compiled and run. And, yes, it is compiled only when called. If this does not exist, we get a MethodError . Methods allow us to execute different code for the same function call, depending on the type of the input argument. julia > foo ( 1 ); x = 1 julia > foo ( \"abc\" ); abc is a string Why do we want this to happen? Benefit 1: We don't have to worry about name conflicts Contrast with Matlab: There can only be one function (and method) named foo . Every time to write a function, you need to create a globally unique name. This makes code reuse very difficult. If two libraries contain a function foo , they cannot both be used at the same time. In Julia: You can always create a new method foo(::Int64) , even if foo is already defined. You only get an error if the exact method foo(::Int64) already exists. Benefit 2: Generic programming We can write an algorithm that can handle any type of input object. See below. This is similar to object oriented programming where method s are owned by specific objects. The key difference is that, in Julia, this also works with multiple arguments: julia > foo ( x , y ) = @show x , y foo ( generic function with 3 methods ) julia > foo ( x :: String , y ) = println ( \" $x is a string, but $y can be anything\" ) foo ( generic function with 4 methods ) julia > foo ( 1 , 2 ) ( x , y ) = ( 1 , 2 ) ( 1 , 2 ) julia > foo ( \"abc\" , 2 ); abc is a string , but 2 can be anything Notes: We can have methods that have different numbers of arguments (here: 1 or 2). If we have two methods with the same number of arguments, the more specific one is called. foo(x,y) is a fallback method that gets called unless a more specific method exists. There is a famous talk by Stefan Karpinski called \"The unreasonable effectiveness of multiple dispatch\" which explains why this is so powerful.","title":"Multiple Dispatch"},{"location":"econ890/julia/methods.html#type-annotations","text":"What happens if we omit type annotations? julia > foo ( x , y ) = @show x , y foo ( generic function with 1 method ) Julia tells us that we have one method. But actually, we have infinitely many! Try foo(1, \"a\") or foo([1,2], [\"a\" \"b\"]) . They all work. foo(x,y) is actually a shorthand for julia > foo ( x :: T1 , y :: T2 ) where { T1 <: Any , T2 <: Any } which is the same as julia > foo ( x :: Any , y :: Any ) In words, we have implicitly defined a method for any combination of types for (x,y) . Here is a key point for performance: Julia still specializes the code for each combination of types that we actually use. This means: When we call foo(1,2) , Julia compiles foo(::Int64, ::Int64) and calls that method. It follows that we get the same performance as if we had defined foo(::Int64, ::Int64) by hand. Type annotations have no effect on performance. Why then do we need them? Avoiding name conflicts (again). Suppose you have an object for which you want to define name(x) . You can define name(x :: MyType) without worrying about name conflicts. Different code for different types. Consider the example of show(x) . Clearly, each object needs its own show method. There is \"generic\" useful way of showing an object in the REPL. This is typical for \"low level\" operations. For example, + works differently (at the hardware level) for Float64 vs UInt8 .","title":"Type Annotations"},{"location":"econ890/julia/methods.html#example","text":"Write a function myshow(x) that prints that value of x with a little type annotation: julia > myshow ( 1 ) \"Int64 1\" julia > myshow ( 1.2345 ) # Note the rounding! \"Float64 1.2\" julia > myshow ( \"any other type\" ) \"I do not know this type: String\"","title":"Example"},{"location":"econ890/julia/methods.html#generic-programming","text":"Suppose I want to sort the Vector x = [1, \"a\", 4, 2] . Calling sort(x) gives an error: ERROR: MethodError: no method matching isless(::String, ::Int64) Now let's define that missing method and see what happens: julia > Base . isless ( x :: String , y :: Number ) = true julia > sort ([ 3 , 1 , \"a\" , 4 , 2 ]) 5 - element Vector { Any } : \"a\" 1 2 3 4 The sorting algorithm is generic . It works on any Vector as long as isless(x,y) is defined. This makes the algorithm highly reusable. We can define a new DataType and apply the existing sorting algorithms. Conversely, we can write algorithms without type annotations. They will just work on any type (even if defined \"after the fact\") that supports a few methods. This is not only possible, it is very common in Julia.","title":"Generic Programming"},{"location":"econ890/julia/methods.html#extending-existing-functions","text":"For this to work, we need to be able to extend functions that were defined by others (in modules, including Base ) to new data types. This is exactly what we did in our sorting example: For example, suppose we want to be able to sum String s (this is a bad idea, but we can do it): julia > Base . isless ( x :: String , y :: Number ) = true Note that we wrote Base.isless , not just isless . Had we written julia > isless ( x :: String , y :: Number ) = true we would have defined a new function Main.isless , not a new method. Then calling sort[1, \"abc\"] would have failed with the same MethodError that we originally encountered. The reason is that sort lives in module Base (we talk soon about what modules are). Therefore, any unqualified call to isless translates into Base.isless , which is a different function (not method) from Main.isless . Another, less clear, way of extending an existing function: julia > import Base : isless julia > isless ( x :: String , y :: Number ) = true","title":"Extending existing functions"},{"location":"econ890/julia/methods.html#more-on-type-annotations","text":"We can annotate types in various ways. # No annotation foo ( x , y ) == foo ( x :: Any , y :: Any ) # Give an abstract type # Defines one method for each concrete T <: Real foo ( x :: Real ) == foo ( x :: T ) where T <: Real # Concrete types foo ( x :: Float64 ) Again: none of this has any impact on performance. We can impose type restrictions: # Force (x,y) to be the same type # where T is the same as `where T <: Any` foo ( x :: T , y :: T ) where T # Now this works foo ( 1 , 2 ) # and this errors foo ( 1 , 2.0 )","title":"More on Type Annotations"},{"location":"econ890/julia/modules.html","text":"Modules \u00b6 A namespace is a set of functions or scripts that can \"see\" the same objects. In Julia, namespaces are created by modules. A module is created by julia > module Foo export g f ( x ) = x ^ 2 ; g ( x ) = x / 2 ; end Main . Foo Even what you run in the REPL lives in a module called Main . This is why the module that we just created is Main.Foo (not just Foo ). It is a sub-module of Main . To access the objects inside of Foo we need to import the module: # We did not import `Foo`, so we get an error. julia > f ( 2 ) ERROR : UndefVarError : f not defined Stacktrace : [ 1 ] top - level scope at REPL [ 3 ] : 1 # This imports `Foo` julia > using . Foo julia > Foo . f ( 2 ) 4 We still cannot just type f(2) because Foo did not export f Only objects that are exported can be called without the module name as a qualifier. julia > g ( 2 ) 1","title":"Modules"},{"location":"econ890/julia/modules.html#modules","text":"A namespace is a set of functions or scripts that can \"see\" the same objects. In Julia, namespaces are created by modules. A module is created by julia > module Foo export g f ( x ) = x ^ 2 ; g ( x ) = x / 2 ; end Main . Foo Even what you run in the REPL lives in a module called Main . This is why the module that we just created is Main.Foo (not just Foo ). It is a sub-module of Main . To access the objects inside of Foo we need to import the module: # We did not import `Foo`, so we get an error. julia > f ( 2 ) ERROR : UndefVarError : f not defined Stacktrace : [ 1 ] top - level scope at REPL [ 3 ] : 1 # This imports `Foo` julia > using . Foo julia > Foo . f ( 2 ) 4 We still cannot just type f(2) because Foo did not export f Only objects that are exported can be called without the module name as a qualifier. julia > g ( 2 ) 1","title":"Modules"},{"location":"econ890/julia/oop.html","text":"Object Oriented Programming (OOP) \u00b6 The Idea \u00b6 OOP takes structured programming to the next level. Structured programming encapsulates local data in a function. The user does not need to know anything about the function other than the interface (inputs and outputs). OOP recognizes that some groups of functions \"hang together\" because they operate on the same object. One idea is to group these functions together. The second idea is that certain persistent data \"belong to\" an object. They should only be manipulated by functions that also \"belong to\" the object. OOP therefore bundles data (called properties ) and functions (called methods ) together. Example: Utility function \u00b6 \\(u(c,l) = c ^{(1-\\sigma)} / (1-\\sigma) + \\phi \\log(l)\\) Persistent data include: parameters ( \\(\\sigma, \\phi\\) ). Methods include: compute \\(u_{c}, u(c,l)\\) , inverse marginal utility, indifference curves. Benefits \u00b6 There is nothing that OOP can do that could not be done without OOP. The benefits lie in code organization. The programmer sees all methods that operate on the object in one place. That makes it easier to test the code modify the code ensure consistency Since all code is in one place, it is easy to swap out. Imagine you want to compute a model with different utility functions. With OOP, all you need to do is swap out the utility function object. Ideally, the other code remains unchanged. Drawbacks \u00b6 Some view OOP as misguided. The focus should be on algorithms or interfaces, not objects. I don't think there is a right answer. Some code \"naturally\" structures itself around objects. Example: Utility functions, their parameters, and the obvious methods (computing utility, marginal utility, ...). Other code \"naturally\" structures itself around algorithms. This is particularly true for \"lower level\" tasks, such as sorting. OOP in Julia \u00b6 Julia is not an OOP language. There is no inheritance . But it is easy to create user defined types that store their persistent state and to define methods that \"belong\" to those types. Example: Utility Function \u00b6 struct CRRA { T } sigma :: T end utility ( u :: CRRA { T }, c ) where T = ( c .^ ( one ( T ) - u . sigma )) ./ ( one ( T ) - u . sigma ); marginal_utility ( u :: CRRA { T }, c ) where T = c .^ ( - u . sigma ); julia > u = CRRA ( 2.0 ) CRRA { Float64 }( 2.0 ) julia > utility ( u , [ 2.0 , 3.0 ]) 2 - element Vector { Float64 } : - 0.5 - 0.3333333333333333 Digression: parametric types \u00b6 CRRA{T} is a parametric type . T parameterizes the CRRA object. This is more general than hard-wiring the type of sigma , but has the same performance. Not annotating the type, as in struct CRRA sigma end would be slower (because Julia would not be able to specialize methods on the type of sigma ). Why do we care? \u00b6 When we solve structural models, OOP is a natural approach. Example: julia > abstract type AbstractUtility { T } end julia > struct CRRA { T } <: AbstractUtility { T } \u03c3 :: T end julia > abstract type AbstractProductionFunction { T } end julia > struct CobbDouglas { T } <: AbstractProductionFunction { T } \u03b1 :: T tfp :: T end julia > struct Model { T } util :: AbstractUtility { T } prodFct :: AbstractProductionFunction { T } end julia > m = Model ( CRRA ( 2.0 ), CobbDouglas ( 0.3 , 1.5 )) Model { Float64 }( CRRA { Float64 }( 2.0 ), CobbDouglas { Float64 }( 0.3 , 1.5 )) Now we change our mind and go for exponential utility: julia > struct ExponentialUtil { T } <: AbstractUtility { T } \u03bc :: T end julia > m = Model ( ExponentialUtil ( 0.7 ), CobbDouglas ( 0.3 , 1.5 )) Model { Float64 }( ExponentialUtil { Float64 }( 0.7 ), CobbDouglas { Float64 }( 0.3 , 1.5 )) As long as utility(u, c) is defined for each utility function, nothing in our code changes when we replace one utility function with another. And the model automatically keeps track of the parameters that actually matter in this model version. Models become like Legos. Note: struct Model{T} is not efficient. We should have written # Note the `T` in the parametric type definition struct Model { T , U <: AbstractUtility { T }, F <: AbstractProdFct { T }} util :: U prodFct :: F end See notes on parametric types . References \u00b6 Matlab documentation on object oriented programming .","title":"Object Oriented Programming (OOP)"},{"location":"econ890/julia/oop.html#object-oriented-programming-oop","text":"","title":"Object Oriented Programming (OOP)"},{"location":"econ890/julia/oop.html#the-idea","text":"OOP takes structured programming to the next level. Structured programming encapsulates local data in a function. The user does not need to know anything about the function other than the interface (inputs and outputs). OOP recognizes that some groups of functions \"hang together\" because they operate on the same object. One idea is to group these functions together. The second idea is that certain persistent data \"belong to\" an object. They should only be manipulated by functions that also \"belong to\" the object. OOP therefore bundles data (called properties ) and functions (called methods ) together.","title":"The Idea"},{"location":"econ890/julia/oop.html#example-utility-function","text":"\\(u(c,l) = c ^{(1-\\sigma)} / (1-\\sigma) + \\phi \\log(l)\\) Persistent data include: parameters ( \\(\\sigma, \\phi\\) ). Methods include: compute \\(u_{c}, u(c,l)\\) , inverse marginal utility, indifference curves.","title":"Example: Utility function"},{"location":"econ890/julia/oop.html#benefits","text":"There is nothing that OOP can do that could not be done without OOP. The benefits lie in code organization. The programmer sees all methods that operate on the object in one place. That makes it easier to test the code modify the code ensure consistency Since all code is in one place, it is easy to swap out. Imagine you want to compute a model with different utility functions. With OOP, all you need to do is swap out the utility function object. Ideally, the other code remains unchanged.","title":"Benefits"},{"location":"econ890/julia/oop.html#drawbacks","text":"Some view OOP as misguided. The focus should be on algorithms or interfaces, not objects. I don't think there is a right answer. Some code \"naturally\" structures itself around objects. Example: Utility functions, their parameters, and the obvious methods (computing utility, marginal utility, ...). Other code \"naturally\" structures itself around algorithms. This is particularly true for \"lower level\" tasks, such as sorting.","title":"Drawbacks"},{"location":"econ890/julia/oop.html#oop-in-julia","text":"Julia is not an OOP language. There is no inheritance . But it is easy to create user defined types that store their persistent state and to define methods that \"belong\" to those types.","title":"OOP in Julia"},{"location":"econ890/julia/oop.html#example-utility-function_1","text":"struct CRRA { T } sigma :: T end utility ( u :: CRRA { T }, c ) where T = ( c .^ ( one ( T ) - u . sigma )) ./ ( one ( T ) - u . sigma ); marginal_utility ( u :: CRRA { T }, c ) where T = c .^ ( - u . sigma ); julia > u = CRRA ( 2.0 ) CRRA { Float64 }( 2.0 ) julia > utility ( u , [ 2.0 , 3.0 ]) 2 - element Vector { Float64 } : - 0.5 - 0.3333333333333333","title":"Example: Utility Function"},{"location":"econ890/julia/oop.html#digression-parametric-types","text":"CRRA{T} is a parametric type . T parameterizes the CRRA object. This is more general than hard-wiring the type of sigma , but has the same performance. Not annotating the type, as in struct CRRA sigma end would be slower (because Julia would not be able to specialize methods on the type of sigma ).","title":"Digression: parametric types"},{"location":"econ890/julia/oop.html#why-do-we-care","text":"When we solve structural models, OOP is a natural approach. Example: julia > abstract type AbstractUtility { T } end julia > struct CRRA { T } <: AbstractUtility { T } \u03c3 :: T end julia > abstract type AbstractProductionFunction { T } end julia > struct CobbDouglas { T } <: AbstractProductionFunction { T } \u03b1 :: T tfp :: T end julia > struct Model { T } util :: AbstractUtility { T } prodFct :: AbstractProductionFunction { T } end julia > m = Model ( CRRA ( 2.0 ), CobbDouglas ( 0.3 , 1.5 )) Model { Float64 }( CRRA { Float64 }( 2.0 ), CobbDouglas { Float64 }( 0.3 , 1.5 )) Now we change our mind and go for exponential utility: julia > struct ExponentialUtil { T } <: AbstractUtility { T } \u03bc :: T end julia > m = Model ( ExponentialUtil ( 0.7 ), CobbDouglas ( 0.3 , 1.5 )) Model { Float64 }( ExponentialUtil { Float64 }( 0.7 ), CobbDouglas { Float64 }( 0.3 , 1.5 )) As long as utility(u, c) is defined for each utility function, nothing in our code changes when we replace one utility function with another. And the model automatically keeps track of the parameters that actually matter in this model version. Models become like Legos. Note: struct Model{T} is not efficient. We should have written # Note the `T` in the parametric type definition struct Model { T , U <: AbstractUtility { T }, F <: AbstractProdFct { T }} util :: U prodFct :: F end See notes on parametric types .","title":"Why do we care?"},{"location":"econ890/julia/oop.html#references","text":"Matlab documentation on object oriented programming .","title":"References"},{"location":"econ890/julia/outline.html","text":"Julia for Economists \u00b6 Our approach will be to compute a version of the classic Huggett (1996) model. We will start simple, but eventually (time permitting) get to the point where our code will be well structured, reusable, and tested. Table of Contents \u00b6 Basics \u00b6 Getting started Types and variables Arrays Functions Methods and multiple dispatch User defined types Writing solid code Learning Julia Beyond the basics \u00b6 Object oriented programming Modules Packages Testing Debugging Solving a Permanent Income Model \u00b6 Simple minded approach OOP approach Shooting approach Policy function iteration Solving Huggett 1996","title":"Julia for Economists"},{"location":"econ890/julia/outline.html#julia-for-economists","text":"Our approach will be to compute a version of the classic Huggett (1996) model. We will start simple, but eventually (time permitting) get to the point where our code will be well structured, reusable, and tested.","title":"Julia for Economists"},{"location":"econ890/julia/outline.html#table-of-contents","text":"","title":"Table of Contents"},{"location":"econ890/julia/outline.html#basics","text":"Getting started Types and variables Arrays Functions Methods and multiple dispatch User defined types Writing solid code Learning Julia","title":"Basics"},{"location":"econ890/julia/outline.html#beyond-the-basics","text":"Object oriented programming Modules Packages Testing Debugging","title":"Beyond the basics"},{"location":"econ890/julia/outline.html#solving-a-permanent-income-model","text":"Simple minded approach OOP approach Shooting approach Policy function iteration Solving Huggett 1996","title":"Solving a Permanent Income Model"},{"location":"econ890/julia/packages.html","text":"Packages \u00b6 A package is a basically a directory that contains a module declares all of its dependencies The idea is to make code reusable : we can copy the package directory to another computer and run it there. You encounter packages in two ways: when you use code written by others (as in using Revise ) when you write your own code; because Julia really wants you to wrap it in packages. Environments \u00b6 If a block of related code were totally self-contained, life would be easy. Reusing code would be a simple as copying a directory full of .jl files. This is how languages without dependency management (such as Matlab ) work. But writing self-contained packages would be very hard. Imagine having to code random number generation each time you want to draw some random numbers. So we want to be able to use packages that use other packages that use other packages... To do so, our code needs to declare what other code (packages) is needed to run it. These are dependencies . In Julia, dependencies are declared in Project.toml files. They basically contain a list of packages, their versions, and the locations of their code. But which Project.toml should Julia use when you type using Revise ? The short (not quite accurate) answer is: Julia looks for Project.toml is the current environment . The longer (more accurate) answer is that Julia also looks in all the directories listed in the DEPOT_PATH environment variable. My recommendation is never to touch it and never to worry about it. At any point in time, exactly one directory is \"activated\" as the current environment. To see which one, type ] st . This does two things: the ] switches the REPL to package mode . the prompt changes to (@v1.6) pkg> the (@v1.6) part of the prompt tells us that the active environment is v1.6 , which is Julia's startup environment the pkg> part reminds you that your commands are interpreted as package commands, not regular REPL commands. the st is short for status . The same info can be displayed by issuing Pkg commands directly: julia > using Pkg julia > Pkg . status () Status `~/.julia/environments/v1.5/Project.toml` [ 5 fb14364 ] OhMyREPL v0 . 5.10 [ 295 af30f ] Revise v3 . 1.12 Or you can look at Project.toml directly: # To switch to shell prompt, type `;` shell> cat ~/.julia/environments/v1.6/Project.toml [deps] OhMyREPL = \"5fb14364-9ced-5910-84b2-373655c76a03\" Revise = \"295af30f-e4ad-537b-8983-00126c2a3abe\" Each line gives the name and UUID (a unique id) of each available package. This means that using Revise will make the code in Revise.jl available. But if I try using Plots , I get an error message: julia> using Plots ERROR: ArgumentError: Package Plots not found in current path: - Run `import Pkg; Pkg.add(\"Plots\")` to install the Plots package. This basically says: Julia cannot find an entry for Plots in Project.toml . So the code cannot be used until I run Pkg.add(\"Plots\") . Tip: keep the startup environment minimal. Here you just want to list packages that you use while developing your code (e.g. Revise.jl ). Activating an environment \u00b6 Pkg.activate(\"/path/to/dir\") activates this directory as the current environment. Equivalently, we can use cd ( \"/path/to/dir\" ); ] activate . The . always means \"the current directory\". Note: The current directory (set using cd ) and the active environment need not be the same. Exercise: Create a directory for the code that you will write in this class. Make this the current environment. Stacked environments \u00b6 If you activate a different directory using Pkg.activate(\"/path/to/dir\") , additional packages become available. Note that the packages known from v1.6 are not \"forgotten.\" Each time I activate a new environment, packages get added to the known list of loadable packages. This is known as stacked environments . They are stacked in the sense that activating another environment retains the packages that are already activated. This is the reason why you want your v1.5 environment to be minimal. This can lead to great confusion. E.g.: You try to update to a new version of a package, but it does not work because the old one was already loaded in the previous environment. Adding packages \u00b6 To add a registered package to the list of known dependencies, use Pkg.add(\"Revise\") . In response, Julia looks up Revise in the General Registry and adds an entry for Revise to Project.toml (for the current environment). Now we can issue using Revise . Julia then downloads the code from the package's github repo. copies the code into a hidden directory in .julia/packages . Each version of Revise that you ever use gets stored there. You rarely need to worry about where this code lives. precompiles Revise Exercise: After activating the Econ890 environment, add the package DataFrames Check that using DataFrames works Check that DataFrames is listed as a dependency in Project.toml Type ] st -m to see all the dependencies that you just added! Remove DataFrames by typing ] rm DataFrames Check that DataFrames and all its dependencies have disappeared But note that using DataFrames still works (because it is already loaded) To really get rid of it, restart the REPL Tip: After updating package info, it is usually a good idea to restart the REPL. If a package is not registered , presumably because you wrote it yourself, using it gets a bit more complicated. A good approach is to create your own local registry (using LocalRegistry.jl ). Then your not officially registered packages are treated like registered ones. For starter purposes, the alternative is to develop your packages instead with Pkg.develop(/path/to/MyPackage) . What does this do? It simply adds an entry in Project.toml that links the package name MyPackage to the directory where the code can be found. There is one fundamental difference between add and develop . add fixes the version of the package until you manually Pkg.update(\"MyPackage\") . Even if the developer changes the code, the version that you are using remains unchanged. develop tells Julia to track whatever code changes happen in the directory where the package code resides (the one you provide with the develop command). Packages \u00b6 So, what is a package? It really is a special case of an environment that satisfies some additional criteria (e.g., a specific directory structure is present). One expectation is that src/MyPackage.jl defines the module MyPackage plus types and functions. To use a package, write using MyPackage and voila - all the types and functions defined in MyPackage are available in your code, including the code MyPackage requires from other packages. Dependency Hell \u00b6 So, you create an environment and add packages A and B . Both A and B depend on X and Y , but X also depends on Y . But when different people wrote A , B , and X they were using different versions of Y (and perhaps also of X ). How can the resulting code possibly run successfully? This problem is called \"dependency hell\". The solution relies on meaningful version numbers together with explicity compatibility specifications. Version numbers (at least for registered packages) have precise meaning. Minor version bumps (e.g. from 1.4 to 1.5 ) are expected to be non-breaking . They can add features, but not change the existing API. This is called semantic versioning and it is the cornerstone of decentralized software development. Each package's Project.toml contains a [compat] section that specifies the versions of all packages that are compatible. The package manager's job is to combine the Project.toml s of all packages used (directly or indirectly) and to figure out a combination of version numbers that satisfies all compatibility requirements. One might expect that this could never work in a project that uses dozens of packages, but, surprisingly, it generally works out just fine. The result is that basically all Julia software heavily relies on packages written by others. Items that we cover later \u00b6 Creating packages","title":"Packages"},{"location":"econ890/julia/packages.html#packages","text":"A package is a basically a directory that contains a module declares all of its dependencies The idea is to make code reusable : we can copy the package directory to another computer and run it there. You encounter packages in two ways: when you use code written by others (as in using Revise ) when you write your own code; because Julia really wants you to wrap it in packages.","title":"Packages"},{"location":"econ890/julia/packages.html#environments","text":"If a block of related code were totally self-contained, life would be easy. Reusing code would be a simple as copying a directory full of .jl files. This is how languages without dependency management (such as Matlab ) work. But writing self-contained packages would be very hard. Imagine having to code random number generation each time you want to draw some random numbers. So we want to be able to use packages that use other packages that use other packages... To do so, our code needs to declare what other code (packages) is needed to run it. These are dependencies . In Julia, dependencies are declared in Project.toml files. They basically contain a list of packages, their versions, and the locations of their code. But which Project.toml should Julia use when you type using Revise ? The short (not quite accurate) answer is: Julia looks for Project.toml is the current environment . The longer (more accurate) answer is that Julia also looks in all the directories listed in the DEPOT_PATH environment variable. My recommendation is never to touch it and never to worry about it. At any point in time, exactly one directory is \"activated\" as the current environment. To see which one, type ] st . This does two things: the ] switches the REPL to package mode . the prompt changes to (@v1.6) pkg> the (@v1.6) part of the prompt tells us that the active environment is v1.6 , which is Julia's startup environment the pkg> part reminds you that your commands are interpreted as package commands, not regular REPL commands. the st is short for status . The same info can be displayed by issuing Pkg commands directly: julia > using Pkg julia > Pkg . status () Status `~/.julia/environments/v1.5/Project.toml` [ 5 fb14364 ] OhMyREPL v0 . 5.10 [ 295 af30f ] Revise v3 . 1.12 Or you can look at Project.toml directly: # To switch to shell prompt, type `;` shell> cat ~/.julia/environments/v1.6/Project.toml [deps] OhMyREPL = \"5fb14364-9ced-5910-84b2-373655c76a03\" Revise = \"295af30f-e4ad-537b-8983-00126c2a3abe\" Each line gives the name and UUID (a unique id) of each available package. This means that using Revise will make the code in Revise.jl available. But if I try using Plots , I get an error message: julia> using Plots ERROR: ArgumentError: Package Plots not found in current path: - Run `import Pkg; Pkg.add(\"Plots\")` to install the Plots package. This basically says: Julia cannot find an entry for Plots in Project.toml . So the code cannot be used until I run Pkg.add(\"Plots\") . Tip: keep the startup environment minimal. Here you just want to list packages that you use while developing your code (e.g. Revise.jl ).","title":"Environments"},{"location":"econ890/julia/packages.html#activating-an-environment","text":"Pkg.activate(\"/path/to/dir\") activates this directory as the current environment. Equivalently, we can use cd ( \"/path/to/dir\" ); ] activate . The . always means \"the current directory\". Note: The current directory (set using cd ) and the active environment need not be the same. Exercise: Create a directory for the code that you will write in this class. Make this the current environment.","title":"Activating an environment"},{"location":"econ890/julia/packages.html#stacked-environments","text":"If you activate a different directory using Pkg.activate(\"/path/to/dir\") , additional packages become available. Note that the packages known from v1.6 are not \"forgotten.\" Each time I activate a new environment, packages get added to the known list of loadable packages. This is known as stacked environments . They are stacked in the sense that activating another environment retains the packages that are already activated. This is the reason why you want your v1.5 environment to be minimal. This can lead to great confusion. E.g.: You try to update to a new version of a package, but it does not work because the old one was already loaded in the previous environment.","title":"Stacked environments"},{"location":"econ890/julia/packages.html#adding-packages","text":"To add a registered package to the list of known dependencies, use Pkg.add(\"Revise\") . In response, Julia looks up Revise in the General Registry and adds an entry for Revise to Project.toml (for the current environment). Now we can issue using Revise . Julia then downloads the code from the package's github repo. copies the code into a hidden directory in .julia/packages . Each version of Revise that you ever use gets stored there. You rarely need to worry about where this code lives. precompiles Revise Exercise: After activating the Econ890 environment, add the package DataFrames Check that using DataFrames works Check that DataFrames is listed as a dependency in Project.toml Type ] st -m to see all the dependencies that you just added! Remove DataFrames by typing ] rm DataFrames Check that DataFrames and all its dependencies have disappeared But note that using DataFrames still works (because it is already loaded) To really get rid of it, restart the REPL Tip: After updating package info, it is usually a good idea to restart the REPL. If a package is not registered , presumably because you wrote it yourself, using it gets a bit more complicated. A good approach is to create your own local registry (using LocalRegistry.jl ). Then your not officially registered packages are treated like registered ones. For starter purposes, the alternative is to develop your packages instead with Pkg.develop(/path/to/MyPackage) . What does this do? It simply adds an entry in Project.toml that links the package name MyPackage to the directory where the code can be found. There is one fundamental difference between add and develop . add fixes the version of the package until you manually Pkg.update(\"MyPackage\") . Even if the developer changes the code, the version that you are using remains unchanged. develop tells Julia to track whatever code changes happen in the directory where the package code resides (the one you provide with the develop command).","title":"Adding packages"},{"location":"econ890/julia/packages.html#packages_1","text":"So, what is a package? It really is a special case of an environment that satisfies some additional criteria (e.g., a specific directory structure is present). One expectation is that src/MyPackage.jl defines the module MyPackage plus types and functions. To use a package, write using MyPackage and voila - all the types and functions defined in MyPackage are available in your code, including the code MyPackage requires from other packages.","title":"Packages"},{"location":"econ890/julia/packages.html#dependency-hell","text":"So, you create an environment and add packages A and B . Both A and B depend on X and Y , but X also depends on Y . But when different people wrote A , B , and X they were using different versions of Y (and perhaps also of X ). How can the resulting code possibly run successfully? This problem is called \"dependency hell\". The solution relies on meaningful version numbers together with explicity compatibility specifications. Version numbers (at least for registered packages) have precise meaning. Minor version bumps (e.g. from 1.4 to 1.5 ) are expected to be non-breaking . They can add features, but not change the existing API. This is called semantic versioning and it is the cornerstone of decentralized software development. Each package's Project.toml contains a [compat] section that specifies the versions of all packages that are compatible. The package manager's job is to combine the Project.toml s of all packages used (directly or indirectly) and to figure out a combination of version numbers that satisfies all compatibility requirements. One might expect that this could never work in a project that uses dozens of packages, but, surprisingly, it generally works out just fine. The result is that basically all Julia software heavily relies on packages written by others.","title":"Dependency Hell"},{"location":"econ890/julia/packages.html#items-that-we-cover-later","text":"Creating packages","title":"Items that we cover later"},{"location":"econ890/julia/solid_code.html","text":"Writing Solid Code \u00b6 This section discusses general programming concepts. The key idea: It's about structure, not algorithms. Structured Programming \u00b6 Structured Programming is an old concept that is now essentially baked into programming languages. The original idea was to avoid \"spaghetti code\" where go to statements were used to jump around the code. This is no longer an issue. But the broader ideas remain important. One key insight is that code needs to be readable and maintainable. Good code reads a lot like text. A long process is broken down into a few steps. Each step becomes a function that carries out exactly one task (ideally). Example: function run_model () m = initialize_model (); sol = solve_model ( m ); sim = simulate_model ( m , sol ); show_results ( sim ); end Notes: The code is self-explanatory. There is little need for comments. All objects are passed explicitly into and out of functions. No side-effects. No global states. The main function is short. The flow is linear. Top Down Design \u00b6 One daunting task is to go from the problem description Solve and simulate the model. Generate figures. to the actual code. The task seems unmanageably big. The idea of top down by stepwise refinement design is to simply write out at a high level of abstraction which steps need to be taken. The top level of the code could literally look like the example above. Then each step gets refined. For example: function solve_model ( m ) sol = initialize_solution (); solve_household! ( sol , m ); solve_firm! ( sol , m ); return sol end Note: The function is again short. All steps are at the same level of abstraction . Each function performs exactly one task. At some point, we arrive at a task that is sufficiently small that we write actual code. Some people first write pseudo code . Others just write the code directly. It depends on how easy the task is. Then, right away, write unit tests . Really. Reusable code \u00b6 Quite a bit of code is not project specific. Examples: Utility functions, production functions, helpers for figures and tables. It pays off over time to make this code generic / reusable and factor it out into a separate package. Some rules \u00b6 Style matters \u00b6 This point is hard to overstate. It is extremely important to write code that is easy to understand and easy to maintain. In practice, you often revisit programs months or years after they were written. They need to be well documented and well structured. The programs needed to solve a stochastic OLG model have thousands of lines of code. The only way to understand something this complex is to break it into logical, self-contained pieces (a function that solves the household problem, another that solves the firm problem, etc.). One example of how important this is: Air traffic control centers still operate with hardware from the 1970s. The reason is that nobody understands the software well enough to port it to new hardware. The FAA has already spent billions of dollars on unsuccessful attempts to rewrite this mess. Another example is the Space Shuttle, which runs (now \"ran\") on hardware from the 1960s. The reason is again that the software engineers can no longer understand the existing code. There are many books on good programming style. One that I like is Writing Solid Code by Steve Maguire. Read it! Test, test, test \u00b6 Write small functions with lots of automated unit tests. It may seem like a waste of time to test something that is \"obviously correct.\" But remember: One typo turns the obviously correct function into a very hard to find bug. Code that is not general purpose (or very performance critical) should contain lots of self-testing code. Catching bugs early makes them easier to find. A trick to prevent your code from getting slowed down by self-testing: add a debugging switch as an input argument to each function (I call it dbg ). if dbg == false : go for speed and turn off self-testing if dbg == true , run all self-test code The process is then: Write code. Make sure it runs (correct syntax). Make sure it is correct (run all self-test code -- slow) When you are confident that your code is good, set dbg = false and go for speed But every now and then, randomly switch dbg on so that self tests are run (little cost in terms of run time; a lot of gain in terms of confidence in your code). Avoid literals \u00b6 Your code should rarely use specific values for any object. When you refer to an object, do so by its name. When you see x=zeros([5,3]) or for i1 = 1 : 57 something is probably wrong. This kind of code is not maintainable. What if you want 58 values instead of 57? Do you want to go throught 10k LOC to find all occurrences of 57 that need to be replaced? It is much better to write: const nTypes = 57 ; for i1 = 1 : nTypes [ ... ] end The Golden Rule is: Every literal must have a name. Its value is defined in one place only. Related to this: do not hard-code functional forms . If you want to compute the marginal product of capital, write a function for it. Otherwise, if you want to switch from Cobb-Douglas to CES, you have to rewrite all your programs. Object oriented programming makes it easy to swap out entire parts of a model. We will talk about this later. Avoid globals \u00b6 Globals make it hard to reason about your code (unless they are constant). Globals make it hard to test your code. You never know who changed them. A common mistake in economics is to make the model parameters into globals. The reasoning is that they are used everywhere, so they need to be global. This is a terrible idea. It is hard to remember what each parameter exactly means. One typo that changes a parameter value leads to very interesting debugging sessions. Where the parameter values are set is hard to keep track of. A much better alternative is to store the parameters inside the model objects. Optimization \u00b6 Optimization refers to program modifications that speed up execution. Think before you optimize! Most code runs so fast that optimization is simply a waste of time. Also: Beware of your intuition about where the program spends most of its time. Here is an example: Consider the function that solves a stochastic OLG model. It turns out that it spends 80% of its time running the Matlab interpolation function interp1 ! There is little point optimizing the rest of the code. To find out what makes your program slow, use a Profiler. Material for Economists \u00b6 Quantitative Economics by Sargent and Stachursky a really nice collection of lectures and exercises that covers both programming and the economics of the material (in Julia and Python) Tony Smith: Tips for quantitative work in economics Material Not for Economists \u00b6 Lifehacker: teach yourself how to code \"Clean Code\" by Robert Martin is a classic. It uses Java, but the general ideas apply everywhere. \"Writing Solid Code\" by Steve Maguire.","title":"Writing Solid Code"},{"location":"econ890/julia/solid_code.html#writing-solid-code","text":"This section discusses general programming concepts. The key idea: It's about structure, not algorithms.","title":"Writing Solid Code"},{"location":"econ890/julia/solid_code.html#structured-programming","text":"Structured Programming is an old concept that is now essentially baked into programming languages. The original idea was to avoid \"spaghetti code\" where go to statements were used to jump around the code. This is no longer an issue. But the broader ideas remain important. One key insight is that code needs to be readable and maintainable. Good code reads a lot like text. A long process is broken down into a few steps. Each step becomes a function that carries out exactly one task (ideally). Example: function run_model () m = initialize_model (); sol = solve_model ( m ); sim = simulate_model ( m , sol ); show_results ( sim ); end Notes: The code is self-explanatory. There is little need for comments. All objects are passed explicitly into and out of functions. No side-effects. No global states. The main function is short. The flow is linear.","title":"Structured Programming"},{"location":"econ890/julia/solid_code.html#top-down-design","text":"One daunting task is to go from the problem description Solve and simulate the model. Generate figures. to the actual code. The task seems unmanageably big. The idea of top down by stepwise refinement design is to simply write out at a high level of abstraction which steps need to be taken. The top level of the code could literally look like the example above. Then each step gets refined. For example: function solve_model ( m ) sol = initialize_solution (); solve_household! ( sol , m ); solve_firm! ( sol , m ); return sol end Note: The function is again short. All steps are at the same level of abstraction . Each function performs exactly one task. At some point, we arrive at a task that is sufficiently small that we write actual code. Some people first write pseudo code . Others just write the code directly. It depends on how easy the task is. Then, right away, write unit tests . Really.","title":"Top Down Design"},{"location":"econ890/julia/solid_code.html#reusable-code","text":"Quite a bit of code is not project specific. Examples: Utility functions, production functions, helpers for figures and tables. It pays off over time to make this code generic / reusable and factor it out into a separate package.","title":"Reusable code"},{"location":"econ890/julia/solid_code.html#some-rules","text":"","title":"Some rules"},{"location":"econ890/julia/solid_code.html#style-matters","text":"This point is hard to overstate. It is extremely important to write code that is easy to understand and easy to maintain. In practice, you often revisit programs months or years after they were written. They need to be well documented and well structured. The programs needed to solve a stochastic OLG model have thousands of lines of code. The only way to understand something this complex is to break it into logical, self-contained pieces (a function that solves the household problem, another that solves the firm problem, etc.). One example of how important this is: Air traffic control centers still operate with hardware from the 1970s. The reason is that nobody understands the software well enough to port it to new hardware. The FAA has already spent billions of dollars on unsuccessful attempts to rewrite this mess. Another example is the Space Shuttle, which runs (now \"ran\") on hardware from the 1960s. The reason is again that the software engineers can no longer understand the existing code. There are many books on good programming style. One that I like is Writing Solid Code by Steve Maguire. Read it!","title":"Style matters"},{"location":"econ890/julia/solid_code.html#test-test-test","text":"Write small functions with lots of automated unit tests. It may seem like a waste of time to test something that is \"obviously correct.\" But remember: One typo turns the obviously correct function into a very hard to find bug. Code that is not general purpose (or very performance critical) should contain lots of self-testing code. Catching bugs early makes them easier to find. A trick to prevent your code from getting slowed down by self-testing: add a debugging switch as an input argument to each function (I call it dbg ). if dbg == false : go for speed and turn off self-testing if dbg == true , run all self-test code The process is then: Write code. Make sure it runs (correct syntax). Make sure it is correct (run all self-test code -- slow) When you are confident that your code is good, set dbg = false and go for speed But every now and then, randomly switch dbg on so that self tests are run (little cost in terms of run time; a lot of gain in terms of confidence in your code).","title":"Test, test, test"},{"location":"econ890/julia/solid_code.html#avoid-literals","text":"Your code should rarely use specific values for any object. When you refer to an object, do so by its name. When you see x=zeros([5,3]) or for i1 = 1 : 57 something is probably wrong. This kind of code is not maintainable. What if you want 58 values instead of 57? Do you want to go throught 10k LOC to find all occurrences of 57 that need to be replaced? It is much better to write: const nTypes = 57 ; for i1 = 1 : nTypes [ ... ] end The Golden Rule is: Every literal must have a name. Its value is defined in one place only. Related to this: do not hard-code functional forms . If you want to compute the marginal product of capital, write a function for it. Otherwise, if you want to switch from Cobb-Douglas to CES, you have to rewrite all your programs. Object oriented programming makes it easy to swap out entire parts of a model. We will talk about this later.","title":"Avoid literals"},{"location":"econ890/julia/solid_code.html#avoid-globals","text":"Globals make it hard to reason about your code (unless they are constant). Globals make it hard to test your code. You never know who changed them. A common mistake in economics is to make the model parameters into globals. The reasoning is that they are used everywhere, so they need to be global. This is a terrible idea. It is hard to remember what each parameter exactly means. One typo that changes a parameter value leads to very interesting debugging sessions. Where the parameter values are set is hard to keep track of. A much better alternative is to store the parameters inside the model objects.","title":"Avoid globals"},{"location":"econ890/julia/solid_code.html#optimization","text":"Optimization refers to program modifications that speed up execution. Think before you optimize! Most code runs so fast that optimization is simply a waste of time. Also: Beware of your intuition about where the program spends most of its time. Here is an example: Consider the function that solves a stochastic OLG model. It turns out that it spends 80% of its time running the Matlab interpolation function interp1 ! There is little point optimizing the rest of the code. To find out what makes your program slow, use a Profiler.","title":"Optimization"},{"location":"econ890/julia/solid_code.html#material-for-economists","text":"Quantitative Economics by Sargent and Stachursky a really nice collection of lectures and exercises that covers both programming and the economics of the material (in Julia and Python) Tony Smith: Tips for quantitative work in economics","title":"Material for Economists"},{"location":"econ890/julia/solid_code.html#material-not-for-economists","text":"Lifehacker: teach yourself how to code \"Clean Code\" by Robert Martin is a classic. It uses Java, but the general ideas apply everywhere. \"Writing Solid Code\" by Steve Maguire.","title":"Material Not for Economists"},{"location":"econ890/julia/testing.html","text":"Testing \u00b6 The golden rule: When you write a function, write a set of tests to go with it. It is hard to overstate the importance of automated testing. It gives you peace of mind. When you change some code, you can simply rerun your test suite and ensure that nothing has been broken. The key is to fully automate the testing. Your project should have a single function that runs all tests in order. All programming languages have unit testing frameworks that make it easy to automate this process. Julia's is described here . Testing basics \u00b6 The testing framework (and really all of Julia) is designed to work with packages . But we can explore the basics even without creating a package (yet). The key elements are: The @test macro: @test 1 == 1 runs silently @test 1 == 2 produces an error, but tests keep running The @testset macro groups tests for clearer reporting. Example: testing.jl and testing_test.jl .","title":"Testing"},{"location":"econ890/julia/testing.html#testing","text":"The golden rule: When you write a function, write a set of tests to go with it. It is hard to overstate the importance of automated testing. It gives you peace of mind. When you change some code, you can simply rerun your test suite and ensure that nothing has been broken. The key is to fully automate the testing. Your project should have a single function that runs all tests in order. All programming languages have unit testing frameworks that make it easy to automate this process. Julia's is described here .","title":"Testing"},{"location":"econ890/julia/testing.html#testing-basics","text":"The testing framework (and really all of Julia) is designed to work with packages . But we can explore the basics even without creating a package (yet). The key elements are: The @test macro: @test 1 == 1 runs silently @test 1 == 2 produces an error, but tests keep running The @testset macro groups tests for clearer reporting. Example: testing.jl and testing_test.jl .","title":"Testing basics"},{"location":"econ890/julia/types.html","text":"Variables and Types \u00b6 When you issue an assignment statement, such as x = 2 you create a variable called x . What does this actually mean? Julia creates a place in memory where the value 2 is stored. It then creates a \"binding\" so that the symbol :x from now on points to that location in memory. (This is actually not the way it works for scalar real numbers, but we will set this detail aside right now.) The memory location now has a type . In this case, it is Int64 : typeof ( x ) Int64 Julia is dynamically typed . This means that I can change the type of x by simply reassigning a new value or by converting the value to a different type: x = Float64 ( x ) 2.0 Doing this kind of thing is generally a bad idea, but it is legal. It is a bad idea because it confuses the reader of the code and the compiler. Important types include: Scalar numbers, such as 1 or 1.0 . Strings, such as \"this is a string\". Arrays of numbers, such as [1 2; 3 4] . Dict : a container that maps names to values; similar to a struct in Matlab. Struct : a composite, user-defined type with fixed fields; similar to a class in Matlab. Supertypes and Subtypes \u00b6 One DataType is Number . This includes integers, floating point numbers, etc. Types come in hierarchies. For example: Base . show_supertypes ( Int64 ) Int64 <: Signed <: Integer <: Real <: Number <: Any shows that Int64 is a subtype of Signed etc. Only the \"lowest\" types in the hierarchy are concrete types that can actually be assigned values. The higher up types are abstract . They only exist to make a type hierarchy. Why do types come in a hierarchy? Mainly because some functions are defined on certain groups of types, but not on others. For example, sin(\"abc\") does not make sense, but sin(x) makes sense for various types of Number . Scalar Numbers \u00b6 The main Number types that we care about are integers and floats. Integers come in various flavors depending on how many digits they can store and whether or not they are signed. The default is Int64 which stores 64 bits and is signed. UInt8 requires only 8 bits, but it cannot store large values. Julia knows standard operators on numbers and is smart enough to convert types as needed: julia > x = 1 + 2.0 3.0 julia > typeof ( x ) Float64 Overflow warning: If you assign a value that is too large for a type to store, you get overflow issues: y = UInt8 ( 12345678 ) InexactError : trunc ( UInt8 , 12345678 ) Stacktrace : [ 1 ] throw_inexacterror ( :: Symbol , :: Type { UInt8 }, :: Int64 ) at ./ boot . jl : 558 [ 2 ] checked_trunc_uint at ./ boot . jl : 588 [ inlined ] [ 3 ] toUInt8 at ./ boot . jl : 650 [ inlined ] [ 4 ] UInt8 ( :: Int64 ) at ./ boot . jl : 710 [ 5 ] top - level scope at In [ 5 ] : 1 [ 6 ] include_string ( :: Function , :: Module , :: String , :: String ) at ./ loading . jl : 1091 This throws an error because Julia cannot convert a large number to a UInt8 . The several lines below the error message are a stacktrace . It shows where in your code the error occurred. This is important for debugging. We will talk about arrays separately. Strings \u00b6 In contrast to Matlab, Strings are not Vector{Char} . They are their own type. A String is created by providing characters inside quotes: a = \"This is a string\" But strings can be indexed like character vectors: julia > a [ 4 ] 's' : ASCII / Unicode U + 0073 ( category Ll : Letter , lowercase )","title":"Variables and Types"},{"location":"econ890/julia/types.html#variables-and-types","text":"When you issue an assignment statement, such as x = 2 you create a variable called x . What does this actually mean? Julia creates a place in memory where the value 2 is stored. It then creates a \"binding\" so that the symbol :x from now on points to that location in memory. (This is actually not the way it works for scalar real numbers, but we will set this detail aside right now.) The memory location now has a type . In this case, it is Int64 : typeof ( x ) Int64 Julia is dynamically typed . This means that I can change the type of x by simply reassigning a new value or by converting the value to a different type: x = Float64 ( x ) 2.0 Doing this kind of thing is generally a bad idea, but it is legal. It is a bad idea because it confuses the reader of the code and the compiler. Important types include: Scalar numbers, such as 1 or 1.0 . Strings, such as \"this is a string\". Arrays of numbers, such as [1 2; 3 4] . Dict : a container that maps names to values; similar to a struct in Matlab. Struct : a composite, user-defined type with fixed fields; similar to a class in Matlab.","title":"Variables and Types"},{"location":"econ890/julia/types.html#supertypes-and-subtypes","text":"One DataType is Number . This includes integers, floating point numbers, etc. Types come in hierarchies. For example: Base . show_supertypes ( Int64 ) Int64 <: Signed <: Integer <: Real <: Number <: Any shows that Int64 is a subtype of Signed etc. Only the \"lowest\" types in the hierarchy are concrete types that can actually be assigned values. The higher up types are abstract . They only exist to make a type hierarchy. Why do types come in a hierarchy? Mainly because some functions are defined on certain groups of types, but not on others. For example, sin(\"abc\") does not make sense, but sin(x) makes sense for various types of Number .","title":"Supertypes and Subtypes"},{"location":"econ890/julia/types.html#scalar-numbers","text":"The main Number types that we care about are integers and floats. Integers come in various flavors depending on how many digits they can store and whether or not they are signed. The default is Int64 which stores 64 bits and is signed. UInt8 requires only 8 bits, but it cannot store large values. Julia knows standard operators on numbers and is smart enough to convert types as needed: julia > x = 1 + 2.0 3.0 julia > typeof ( x ) Float64 Overflow warning: If you assign a value that is too large for a type to store, you get overflow issues: y = UInt8 ( 12345678 ) InexactError : trunc ( UInt8 , 12345678 ) Stacktrace : [ 1 ] throw_inexacterror ( :: Symbol , :: Type { UInt8 }, :: Int64 ) at ./ boot . jl : 558 [ 2 ] checked_trunc_uint at ./ boot . jl : 588 [ inlined ] [ 3 ] toUInt8 at ./ boot . jl : 650 [ inlined ] [ 4 ] UInt8 ( :: Int64 ) at ./ boot . jl : 710 [ 5 ] top - level scope at In [ 5 ] : 1 [ 6 ] include_string ( :: Function , :: Module , :: String , :: String ) at ./ loading . jl : 1091 This throws an error because Julia cannot convert a large number to a UInt8 . The several lines below the error message are a stacktrace . It shows where in your code the error occurred. This is important for debugging. We will talk about arrays separately.","title":"Scalar Numbers"},{"location":"econ890/julia/types.html#strings","text":"In contrast to Matlab, Strings are not Vector{Char} . They are their own type. A String is created by providing characters inside quotes: a = \"This is a string\" But strings can be indexed like character vectors: julia > a [ 4 ] 's' : ASCII / Unicode U + 0073 ( category Ll : Letter , lowercase )","title":"Strings"},{"location":"econ890/julia/user_defined_types.html","text":"User Defined Types \u00b6 It is very common to define new types in Julia. One reason is multiple dispatch , which we discussed when we talked about functions . Example julia > struct Point x y end julia > z = Point ( 1 , 2 ) Point ( 1 , 2 ) We have now defined the type Point . By default, Julia also created a function, called a constructor that \"makes\" Point objects: julia > methods ( Point ) # 1 method for type constructor: [ 1 ] Point ( x , y ) in Main at REPL [ 21 ] : 2 This says that there is a function Point , which is the constructor for the Point data type. We can now write functions that take Point arguments, such as julia > function sum_points ( p1 :: Point , p2 :: Point ) return Point ( p1 . x + p2 . x , p1 . y + p2 . y ) end sum_points ( generic function with 1 method ) julia > sum_points ( Point ( 1 , 2 ), Point ( 2 , 3 )) Point ( 3 , 5 ) But it gets even better: we can \"overload\" an existing function like so: julia > function Base . sum ( p1 :: Point , p2 :: Point ) return Point ( p1 . x + p2 . x , p1 . y + p2 . y ) end julia > sum ( Point ( 1 , 2 ), Point ( 2 , 3 )) Point ( 3 , 5 ) Now the \"built-in\" function (in module Base ) has an additional method. Before, Julia only knew how to sum numbers (and a few other things). Now Julia knows how to sum points. This means that any algorithm that makes sense and uses summation can now be applied to our new Point datatype. Example: Suppose we wanted to sort Points. We don't have to write a new sorting function. Instead we can define julia > function Base . isless ( p1 :: Point , p2 :: Point ) if p1 . x < p2 . x return true elseif ( p1 . x == p2 . x ) && ( p1 . y < p2 . y ) return true else return false end end julia > isless ( Point ( 1 , 2 ), Point ( 2 , 3 )) true And, voila, we can sort Vector s of Point : julia > sort ([ Point ( 1 , 2 ), Point ( 3 , 4 ), Point ( 1 , 3 )]) 3 - element Vector { Point } : Point ( 1 , 2 ) Point ( 1 , 3 ) Point ( 3 , 4 ) It is worth reading the documentation on types and constructors . Parametric Types \u00b6 Clearly, the concept of Point would make sense for different types of coordinates (e.g., Float64 , Float32 ). We can define a generic version of Point that works for any coordinate type: struct Point { T } x :: T y :: T end julia > Point ( 1 , 2 ) Point { Int64 }( 1 , 2 ) julia > Point ( 1.0 , 2.0 ) Point { Float64 }( 1.0 , 2.0 ) This is a parametric type , parameterized by T . When we define methods , we have julia > function Base . isless ( p1 :: Point { T }, p2 :: Point { T }) where T if p1 . x < p2 . x return true elseif ( p1 . x == p2 . x ) && ( p1 . y < p2 . y ) return true else return false end end This defines a method for each parameterization of Point . It is probably obvious why this is essential. Point is a data container that is equally valid for different types of data held. We don't want to be forced to write separate code for each parametric version of Point . Mutable Types \u00b6 struct Foo end is immutable . Once a Foo is constructed, it cannot be changed. mutable struct Foo x end is mutable . I can change its fields with Foo.x = 1 . Benefits of immutable types: Efficiency: The compiler can apply many optimizations based on knowing that Foo.x can never change. Immutable types can often be allocated on the \"stack\" which is much faster than on the \"heap\". Easier to reason about code. Excercise \u00b6 Construct a parametric type Model that contains a utility function CRRA{T} and a production function CobbDouglas{T} for the same T . abstract type AbstractUtility { T } end struct CRRA { T } <: AbstractUtility { T } \u03c3 :: T end abstract type AbstractProdFct { T } end struct CobbDouglas { T } <: AbstractProdFct { T } \u03b1 :: T end # Note the `T` in the parametric type definition struct Model { T , U <: AbstractUtility { T }, F <: AbstractProdFct { T }} util :: U prodFct :: F end m = Model ( CRRA ( 2.0 ), CobbDouglas ( 0.3 )) @show m try m2 = Model ( CRRA ( Float32 ( 2 )), CobbDouglas ( 0.3 )) @show m2 catch println ( \"This errors because the parametric types don't match.\" ); end","title":"User Defined Types"},{"location":"econ890/julia/user_defined_types.html#user-defined-types","text":"It is very common to define new types in Julia. One reason is multiple dispatch , which we discussed when we talked about functions . Example julia > struct Point x y end julia > z = Point ( 1 , 2 ) Point ( 1 , 2 ) We have now defined the type Point . By default, Julia also created a function, called a constructor that \"makes\" Point objects: julia > methods ( Point ) # 1 method for type constructor: [ 1 ] Point ( x , y ) in Main at REPL [ 21 ] : 2 This says that there is a function Point , which is the constructor for the Point data type. We can now write functions that take Point arguments, such as julia > function sum_points ( p1 :: Point , p2 :: Point ) return Point ( p1 . x + p2 . x , p1 . y + p2 . y ) end sum_points ( generic function with 1 method ) julia > sum_points ( Point ( 1 , 2 ), Point ( 2 , 3 )) Point ( 3 , 5 ) But it gets even better: we can \"overload\" an existing function like so: julia > function Base . sum ( p1 :: Point , p2 :: Point ) return Point ( p1 . x + p2 . x , p1 . y + p2 . y ) end julia > sum ( Point ( 1 , 2 ), Point ( 2 , 3 )) Point ( 3 , 5 ) Now the \"built-in\" function (in module Base ) has an additional method. Before, Julia only knew how to sum numbers (and a few other things). Now Julia knows how to sum points. This means that any algorithm that makes sense and uses summation can now be applied to our new Point datatype. Example: Suppose we wanted to sort Points. We don't have to write a new sorting function. Instead we can define julia > function Base . isless ( p1 :: Point , p2 :: Point ) if p1 . x < p2 . x return true elseif ( p1 . x == p2 . x ) && ( p1 . y < p2 . y ) return true else return false end end julia > isless ( Point ( 1 , 2 ), Point ( 2 , 3 )) true And, voila, we can sort Vector s of Point : julia > sort ([ Point ( 1 , 2 ), Point ( 3 , 4 ), Point ( 1 , 3 )]) 3 - element Vector { Point } : Point ( 1 , 2 ) Point ( 1 , 3 ) Point ( 3 , 4 ) It is worth reading the documentation on types and constructors .","title":"User Defined Types"},{"location":"econ890/julia/user_defined_types.html#parametric-types","text":"Clearly, the concept of Point would make sense for different types of coordinates (e.g., Float64 , Float32 ). We can define a generic version of Point that works for any coordinate type: struct Point { T } x :: T y :: T end julia > Point ( 1 , 2 ) Point { Int64 }( 1 , 2 ) julia > Point ( 1.0 , 2.0 ) Point { Float64 }( 1.0 , 2.0 ) This is a parametric type , parameterized by T . When we define methods , we have julia > function Base . isless ( p1 :: Point { T }, p2 :: Point { T }) where T if p1 . x < p2 . x return true elseif ( p1 . x == p2 . x ) && ( p1 . y < p2 . y ) return true else return false end end This defines a method for each parameterization of Point . It is probably obvious why this is essential. Point is a data container that is equally valid for different types of data held. We don't want to be forced to write separate code for each parametric version of Point .","title":"Parametric Types"},{"location":"econ890/julia/user_defined_types.html#mutable-types","text":"struct Foo end is immutable . Once a Foo is constructed, it cannot be changed. mutable struct Foo x end is mutable . I can change its fields with Foo.x = 1 . Benefits of immutable types: Efficiency: The compiler can apply many optimizations based on knowing that Foo.x can never change. Immutable types can often be allocated on the \"stack\" which is much faster than on the \"heap\". Easier to reason about code.","title":"Mutable Types"},{"location":"econ890/julia/user_defined_types.html#excercise","text":"Construct a parametric type Model that contains a utility function CRRA{T} and a production function CobbDouglas{T} for the same T . abstract type AbstractUtility { T } end struct CRRA { T } <: AbstractUtility { T } \u03c3 :: T end abstract type AbstractProdFct { T } end struct CobbDouglas { T } <: AbstractProdFct { T } \u03b1 :: T end # Note the `T` in the parametric type definition struct Model { T , U <: AbstractUtility { T }, F <: AbstractProdFct { T }} util :: U prodFct :: F end m = Model ( CRRA ( 2.0 ), CobbDouglas ( 0.3 )) @show m try m2 = Model ( CRRA ( Float32 ( 2 )), CobbDouglas ( 0.3 )) @show m2 catch println ( \"This errors because the parametric types don't match.\" ); end","title":"Excercise"},{"location":"econ890/julia/pih/huggett96.html","text":"Solving the Huggett (1996) Model \u00b6 First, let's review the model setup . Goals \u00b6 Code can be modified easily. In a research project, you want to try different functional forms, calibration targets, ... Model objects are OOP objects. Code can be maintained easily. In a research project, it may take years from first submission to accepted paper. Code needs to be readable. Structure is important. It is not enough for the code to run. Small functions that do one thing. Locally trivial. Code still runs in a couple of years. This is where package management is important. Fix versions of dependencies. Code is correct . Everything needs to be tested. Tests run automatically after code is modified. For maintanability: test the small functions. Strategy: Writing the Code \u00b6 This will be a combination of bottom-up and top-down. Typically, we start with the model elements: demographics, preferences, ... We make a struct for each block that holds the parameters and can do some basic things. Examples: the utility function computes utility (we have already done that) the endowments can draw labor endowments at birth and simulate them over time Once we have most of these building blocks in place, we start to write the solution algorithm. some of the building block code will still be \"scaffolding\" at this stage we don't know yet how we need the details to work, so we defer them Building Blocks \u00b6 For each building block, we make a struct write a function that initializes the struct for testing write tests Demographics \u00b6 This knows parameters such as life-span, retirement age. Easy. Endowments \u00b6 Holds the efficiency grid with transition probabilities. Needs to be able to give probability distribution over tomorrow's labor efficiencies. Capital grid \u00b6 We keep that very simple: the same linear grid for each age. We can always swap out the implementation later by defining a new CapitalGrid object. Budget \u00b6 Needs to be able to compute \\(k'\\) from consumption and the other way around. Also holds the age efficiency profile (it's simpler here than in endowments). Solution \u00b6 This is a tricky one: how do we want to store the solution to the model? These are policy functions. The easiest approach seems to store the continuous approximations of these functions: during the retirement phase: \\(k' = G(k, t)\\) and \\(c = H(k, t)\\) during the work phase: we have one of these for each efficiency grid point (a Vector of functions). So we define object that hold a WorkerSolution and a RetiredSolution . Note: There will probably be quite a bit of overlap between the two that we figure out as we go along. So we will likely make these subtypes of AbstractSolution at some point. Model \u00b6 The Model now simply collects all the objects in a container. We need to be able to construct a model for testing. So each objects gets a init_test_object() function. Tips \u00b6 Writing code is an iterative process . You try something. It gets complicated. You redesign. Writing code is procrastination . You write high level code. When it gets complicated, you just push the complicated bits into functions to be written later. Procrastination is good. Update your tests as you write code. Your tests should always run. Sometimes you need to write \"stubs\" -- functions that \"pretend\" to do something complicated that you have not written yet. Refactor incrementally . Refactoring means restructuring code that already works, but is not optimally structured. Do this in tiny steps and make sure your tests are always running. Writing the Solution Algorithm \u00b6 Now we switch to top-down. The solution is simply backward induction: function solve_model ( m :: Model ) sol = initialize_solution (); solve_last_period! ( m , sol ); for t = T : - 1 : 1 if isretired ( m , t ) solve_retire_period! ( m , sol , t ); else solve_work_period! ( m , sol , t ); end end end return sol Note the procrastination. All the difficult stuff is hidden in function calls. Procrastination is good. Note that the code is entirely self-explanatory. There is no need for comments. Next we write the code for each function, starting with solve_last_period . That's actually the same code as for our permanent income model, so we just copy and paste it. Note: The moment you hear \"copy and paste\" you should think: \"I need to package that code so I can reuse it.\" This could (and probably should) be done with the PIH code. But getting this right so it is reasonably general would be quite a bit of work. So we won't do it for this class.","title":"Solving the Huggett (1996) Model"},{"location":"econ890/julia/pih/huggett96.html#solving-the-huggett-1996-model","text":"First, let's review the model setup .","title":"Solving the Huggett (1996) Model"},{"location":"econ890/julia/pih/huggett96.html#goals","text":"Code can be modified easily. In a research project, you want to try different functional forms, calibration targets, ... Model objects are OOP objects. Code can be maintained easily. In a research project, it may take years from first submission to accepted paper. Code needs to be readable. Structure is important. It is not enough for the code to run. Small functions that do one thing. Locally trivial. Code still runs in a couple of years. This is where package management is important. Fix versions of dependencies. Code is correct . Everything needs to be tested. Tests run automatically after code is modified. For maintanability: test the small functions.","title":"Goals"},{"location":"econ890/julia/pih/huggett96.html#strategy-writing-the-code","text":"This will be a combination of bottom-up and top-down. Typically, we start with the model elements: demographics, preferences, ... We make a struct for each block that holds the parameters and can do some basic things. Examples: the utility function computes utility (we have already done that) the endowments can draw labor endowments at birth and simulate them over time Once we have most of these building blocks in place, we start to write the solution algorithm. some of the building block code will still be \"scaffolding\" at this stage we don't know yet how we need the details to work, so we defer them","title":"Strategy: Writing the Code"},{"location":"econ890/julia/pih/huggett96.html#building-blocks","text":"For each building block, we make a struct write a function that initializes the struct for testing write tests","title":"Building Blocks"},{"location":"econ890/julia/pih/huggett96.html#demographics","text":"This knows parameters such as life-span, retirement age. Easy.","title":"Demographics"},{"location":"econ890/julia/pih/huggett96.html#endowments","text":"Holds the efficiency grid with transition probabilities. Needs to be able to give probability distribution over tomorrow's labor efficiencies.","title":"Endowments"},{"location":"econ890/julia/pih/huggett96.html#capital-grid","text":"We keep that very simple: the same linear grid for each age. We can always swap out the implementation later by defining a new CapitalGrid object.","title":"Capital grid"},{"location":"econ890/julia/pih/huggett96.html#budget","text":"Needs to be able to compute \\(k'\\) from consumption and the other way around. Also holds the age efficiency profile (it's simpler here than in endowments).","title":"Budget"},{"location":"econ890/julia/pih/huggett96.html#solution","text":"This is a tricky one: how do we want to store the solution to the model? These are policy functions. The easiest approach seems to store the continuous approximations of these functions: during the retirement phase: \\(k' = G(k, t)\\) and \\(c = H(k, t)\\) during the work phase: we have one of these for each efficiency grid point (a Vector of functions). So we define object that hold a WorkerSolution and a RetiredSolution . Note: There will probably be quite a bit of overlap between the two that we figure out as we go along. So we will likely make these subtypes of AbstractSolution at some point.","title":"Solution"},{"location":"econ890/julia/pih/huggett96.html#model","text":"The Model now simply collects all the objects in a container. We need to be able to construct a model for testing. So each objects gets a init_test_object() function.","title":"Model"},{"location":"econ890/julia/pih/huggett96.html#tips","text":"Writing code is an iterative process . You try something. It gets complicated. You redesign. Writing code is procrastination . You write high level code. When it gets complicated, you just push the complicated bits into functions to be written later. Procrastination is good. Update your tests as you write code. Your tests should always run. Sometimes you need to write \"stubs\" -- functions that \"pretend\" to do something complicated that you have not written yet. Refactor incrementally . Refactoring means restructuring code that already works, but is not optimally structured. Do this in tiny steps and make sure your tests are always running.","title":"Tips"},{"location":"econ890/julia/pih/huggett96.html#writing-the-solution-algorithm","text":"Now we switch to top-down. The solution is simply backward induction: function solve_model ( m :: Model ) sol = initialize_solution (); solve_last_period! ( m , sol ); for t = T : - 1 : 1 if isretired ( m , t ) solve_retire_period! ( m , sol , t ); else solve_work_period! ( m , sol , t ); end end end return sol Note the procrastination. All the difficult stuff is hidden in function calls. Procrastination is good. Note that the code is entirely self-explanatory. There is no need for comments. Next we write the code for each function, starting with solve_last_period . That's actually the same code as for our permanent income model, so we just copy and paste it. Note: The moment you hear \"copy and paste\" you should think: \"I need to package that code so I can reuse it.\" This could (and probably should) be done with the PIH code. But getting this right so it is reasonably general would be quite a bit of work. So we won't do it for this class.","title":"Writing the Solution Algorithm"},{"location":"econ890/julia/pih/making_package.html","text":"Making a package \u00b6 Now that our code is getting more complex, it is time to make it into a package . We start by making module UtilityFunctions into a package, so we can reuse it more easily. Since we plan to put this up on github (for you to download), the package name must be unique (in my github repo, at least). So we will name all of the packages that we create for this class with an 890 suffix. Generic instructions for creating packages are here . It is helpful to have a github account and put your packages there. But you can skip this step for the purposes of this class. Disclaimer: I have not tried to create a package without github info! Generating the package \u00b6 The most common approach is PkgTemplates . It works like this: In your base environment: pkg> add PkgTemplates . This is now always available. Now let's generate a UtilityFunctions890 package. cd to the directory where all of your Econ890 code lives. Make a template. Create the package. Add the source code and tests. Add dependencies. Run tests. Details for my case: julia > econDir = \"/Users/lutz/Documents/julia/Econ890\" ; julia > cd ( econDir ); julia > using PkgTemplates julia > gitIgnore = [ \"*.jl.cov\" , \"*.jl.*.cov\" , \"*.jl.mem\" , \"/deps/deps.jl\" , \"/docs/build\" ]; julia > t = Template (; dir = econDir , plugins = [ Documenter { GitHubActions }, Git (; jl = false , ignore = gitIgnore ), ! CompatHelper , ! AppVeyor , ! TravisCI , ! TagBot ]); julia > t ( \"UtilityFunctions890\" ) [ Info : Running prehooks [ Info : Running hooks Activating environment at `~/Documents/julia/Econ890/UtilityFunctions/Project.toml` Updating registry at `~/.julia/registries/General` Updating registry at `~/.julia/registries/registryLH` Updating git - repo `https://github.com/hendri54/registryLH` No Changes to `~/Documents/julia/Econ890/UtilityFunctions/Project.toml` No Changes to `~/Documents/julia/Econ890/UtilityFunctions/Manifest.toml` Precompiling project ... 1 dependency successfully precompiled in 1 seconds Activating environment at `~/.julia/environments/v1.6/Project.toml` [ Info : Running posthooks [ Info : New package is at / Users / lutz / Documents / julia / Econ890 / UtilityFunctions The package has now been created. Check that you have a new folder UtilityFunctions890 with sub-folders src and test . After creating the package, copy the contents of utility.jl into UtilityFunctions890.jl . Copy the tests into test/runtests.jl . We now need to modify those files a little to reflect the fact that the module UtilityFunctions890 is now a package. In this case, all we need to do is remove the lines # This is one reason why packages work better. include ( \"utility.jl\" ); using . UtilityFunctions in the runtests.jl file. Add dependencies (e.g., Pkg.add(\"Random\") ) until ] test works: julia > Pkg . activate ( \"UtilityFunctions890\" ) Activating environment at `~/Documents/julia/Econ890/UtilityFunctions890/Project.toml` julia > Pkg . add ( \"Random\" ) julia > using UtiltyFunctions890 Now run the tests: pkg> test . And Bob is your uncle.","title":"Making a package"},{"location":"econ890/julia/pih/making_package.html#making-a-package","text":"Now that our code is getting more complex, it is time to make it into a package . We start by making module UtilityFunctions into a package, so we can reuse it more easily. Since we plan to put this up on github (for you to download), the package name must be unique (in my github repo, at least). So we will name all of the packages that we create for this class with an 890 suffix. Generic instructions for creating packages are here . It is helpful to have a github account and put your packages there. But you can skip this step for the purposes of this class. Disclaimer: I have not tried to create a package without github info!","title":"Making a package"},{"location":"econ890/julia/pih/making_package.html#generating-the-package","text":"The most common approach is PkgTemplates . It works like this: In your base environment: pkg> add PkgTemplates . This is now always available. Now let's generate a UtilityFunctions890 package. cd to the directory where all of your Econ890 code lives. Make a template. Create the package. Add the source code and tests. Add dependencies. Run tests. Details for my case: julia > econDir = \"/Users/lutz/Documents/julia/Econ890\" ; julia > cd ( econDir ); julia > using PkgTemplates julia > gitIgnore = [ \"*.jl.cov\" , \"*.jl.*.cov\" , \"*.jl.mem\" , \"/deps/deps.jl\" , \"/docs/build\" ]; julia > t = Template (; dir = econDir , plugins = [ Documenter { GitHubActions }, Git (; jl = false , ignore = gitIgnore ), ! CompatHelper , ! AppVeyor , ! TravisCI , ! TagBot ]); julia > t ( \"UtilityFunctions890\" ) [ Info : Running prehooks [ Info : Running hooks Activating environment at `~/Documents/julia/Econ890/UtilityFunctions/Project.toml` Updating registry at `~/.julia/registries/General` Updating registry at `~/.julia/registries/registryLH` Updating git - repo `https://github.com/hendri54/registryLH` No Changes to `~/Documents/julia/Econ890/UtilityFunctions/Project.toml` No Changes to `~/Documents/julia/Econ890/UtilityFunctions/Manifest.toml` Precompiling project ... 1 dependency successfully precompiled in 1 seconds Activating environment at `~/.julia/environments/v1.6/Project.toml` [ Info : Running posthooks [ Info : New package is at / Users / lutz / Documents / julia / Econ890 / UtilityFunctions The package has now been created. Check that you have a new folder UtilityFunctions890 with sub-folders src and test . After creating the package, copy the contents of utility.jl into UtilityFunctions890.jl . Copy the tests into test/runtests.jl . We now need to modify those files a little to reflect the fact that the module UtilityFunctions890 is now a package. In this case, all we need to do is remove the lines # This is one reason why packages work better. include ( \"utility.jl\" ); using . UtilityFunctions in the runtests.jl file. Add dependencies (e.g., Pkg.add(\"Random\") ) until ] test works: julia > Pkg . activate ( \"UtilityFunctions890\" ) Activating environment at `~/Documents/julia/Econ890/UtilityFunctions890/Project.toml` julia > Pkg . add ( \"Random\" ) julia > using UtiltyFunctions890 Now run the tests: pkg> test . And Bob is your uncle.","title":"Generating the package"},{"location":"econ890/julia/pih/pih1.html","text":"Solving a Permanent Income Model \u00b6 Eventually, we want to solve Huggett (1996), but that's complicated. So we start simpler. Model \u00b6 A household lives for \\(T\\) periods. Preferences are \\(\\sum_{t=1}^T \\beta^t \\frac{c_{t}^{1-\\sigma}}{1-\\sigma}\\) Lifetime income is \\(Y\\) . Lifetime budget constraint: \\(Y=\\sum_{t=1}^T R^{1-t} c_t\\) Solution \u00b6 The consumption growth rate is given by \\(g(c)=(\\beta R)^{1/\\sigma}\\) . Present value of consumption: \\[ Y=\\sum_t R^{1-t} c_t = c_1 \\sum_t [g(c)/R]^{1-t} \\] Recall: \\(\\sum_{t=0}^{T-1} x_t = \\frac{x^T - 1}{x - 1}\\) Therefore: \\[Y=c_{1}\\frac{\\left[g(c)/R\\right]^{T}-1}{g\\left(c\\right)/R-1}\\] Algorithm \u00b6 Inputs: \\(Y, R, T, \\beta, \\sigma\\) . Compute \\(c_1\\) . \\(c_t = c_1 g(c)^{t-1}\\) Excercise: write this! My solution Testing \u00b6 We need a test. This is where using packages comes in handy: it makes writing tests easy. For now, we just wing it and write a test script. We want to test: Euler equation holds. Budget constraint holds. Exercise: write this! Changing the Utility Function \u00b6 In real world applications, you want to explore alternative functional forms etc. Let's try log utility instead. In our simple example, this is easy because log utility is just the special case of \\(\\sigma=1\\) . But let's pretend this were not the case (we cannot try any old utility function because we have baked into our solution that consumption growth is a constant). This simple change requires that we hunt through all of our code to find which lines depend on the functional form for utility. Once we have found all of those, we need to replace each with if logUtility # use the log expression else # use the CRRA expression end And then we have to keep track of the fact that each utility function requires its own set of parameters. Those parameters have to be passed from one function to the next all throughout the code. There has to be a better way!","title":"Solving a Permanent Income Model"},{"location":"econ890/julia/pih/pih1.html#solving-a-permanent-income-model","text":"Eventually, we want to solve Huggett (1996), but that's complicated. So we start simpler.","title":"Solving a Permanent Income Model"},{"location":"econ890/julia/pih/pih1.html#model","text":"A household lives for \\(T\\) periods. Preferences are \\(\\sum_{t=1}^T \\beta^t \\frac{c_{t}^{1-\\sigma}}{1-\\sigma}\\) Lifetime income is \\(Y\\) . Lifetime budget constraint: \\(Y=\\sum_{t=1}^T R^{1-t} c_t\\)","title":"Model"},{"location":"econ890/julia/pih/pih1.html#solution","text":"The consumption growth rate is given by \\(g(c)=(\\beta R)^{1/\\sigma}\\) . Present value of consumption: \\[ Y=\\sum_t R^{1-t} c_t = c_1 \\sum_t [g(c)/R]^{1-t} \\] Recall: \\(\\sum_{t=0}^{T-1} x_t = \\frac{x^T - 1}{x - 1}\\) Therefore: \\[Y=c_{1}\\frac{\\left[g(c)/R\\right]^{T}-1}{g\\left(c\\right)/R-1}\\]","title":"Solution"},{"location":"econ890/julia/pih/pih1.html#algorithm","text":"Inputs: \\(Y, R, T, \\beta, \\sigma\\) . Compute \\(c_1\\) . \\(c_t = c_1 g(c)^{t-1}\\) Excercise: write this! My solution","title":"Algorithm"},{"location":"econ890/julia/pih/pih1.html#testing","text":"We need a test. This is where using packages comes in handy: it makes writing tests easy. For now, we just wing it and write a test script. We want to test: Euler equation holds. Budget constraint holds. Exercise: write this!","title":"Testing"},{"location":"econ890/julia/pih/pih1.html#changing-the-utility-function","text":"In real world applications, you want to explore alternative functional forms etc. Let's try log utility instead. In our simple example, this is easy because log utility is just the special case of \\(\\sigma=1\\) . But let's pretend this were not the case (we cannot try any old utility function because we have baked into our solution that consumption growth is a constant). This simple change requires that we hunt through all of our code to find which lines depend on the functional form for utility. Once we have found all of those, we need to replace each with if logUtility # use the log expression else # use the CRRA expression end And then we have to keep track of the fact that each utility function requires its own set of parameters. Those parameters have to be passed from one function to the next all throughout the code. There has to be a better way!","title":"Changing the Utility Function"},{"location":"econ890/julia/pih/pih2.html","text":"Solving a Permanent Income Model: OOP Approach \u00b6 Our insight so far: hard-wiring functional forms does not work. How can we build a more flexible model? One approach: define a Model object it contains the fixed parameters \\(T\\) , \\(R\\) , \\(Y\\) plus another object that specifies preferences and their parameters Then we can: init the model with the right preferences and parameters just pass the Model around (not the collection of parameters) Factoring out Preferences \u00b6 Utility functions are not model specific (certainly not in this case). It would make sense to factor out all of the code that does utility calculations. Then we can: easily reuse that code in other projects test that code independently of everything else ensure that eacy utility function supports the same interface, so they can be easily swapped in and out. What do we want utility functions to do? compute \\(u(c)\\) and \\(u'(c)\\) it is often also useful to know inverse marginal utility compute the growth rate of \\(c\\) and (related) Euler equation deviations This defines the API that is visible to the outside world and common to all utility functions. Note: If we were a bit more serious, we would think about embedding all of this into a bigger set of utility functions that depend on multiple arguments. Let's start with log utility. Log has no parameters, so we have struct UtilityLog end But for CRRA we have struct UtilityCRRA sigma :: Float64 end Note: We generally would not want to hard-wire that sigma is a Float64 . More generic would be a parametric type : struct UtilityCRRA { T } sigma :: T end But we keep things simple for now. Since we are packaging the code, we will wrap it into a module (which we will later make into a package). Exercise: write code for the utility functions. My solution Exercise: write tests for the utility functions. My solution Making a Model \u00b6 Now we easily build a Model from its parts. struct Model Y :: Float64 R :: Float64 T :: Int beta :: Float64 u :: AbstractUtility end m = Model ( 10.0 , 1.04 , 30 , 0.98 , UtilityLog ()); Note: switching out the utility function is now trivial adding new utility functions is just as trivial the code does not contain any if utilityLog type switches Exercise: Write this code - and don't forget the tests. My solution and the tests I packaged everything in modules because: eventually, this should go into a package (therefore into a module) once we define structs , we cannot repeatedly include the code (invalid redefinition of the struct) the module makes sure that we don't have side-effects. Note: Tracking changes when code lives in module s with Revise.jl can be tricky. Code needs to be included with includet (for tracking), not with include . Even then Revise.jl struggles with nested includet s. Once you have module s, it's always best to use package s.","title":"Solving a Permanent Income Model: OOP Approach"},{"location":"econ890/julia/pih/pih2.html#solving-a-permanent-income-model-oop-approach","text":"Our insight so far: hard-wiring functional forms does not work. How can we build a more flexible model? One approach: define a Model object it contains the fixed parameters \\(T\\) , \\(R\\) , \\(Y\\) plus another object that specifies preferences and their parameters Then we can: init the model with the right preferences and parameters just pass the Model around (not the collection of parameters)","title":"Solving a Permanent Income Model: OOP Approach"},{"location":"econ890/julia/pih/pih2.html#factoring-out-preferences","text":"Utility functions are not model specific (certainly not in this case). It would make sense to factor out all of the code that does utility calculations. Then we can: easily reuse that code in other projects test that code independently of everything else ensure that eacy utility function supports the same interface, so they can be easily swapped in and out. What do we want utility functions to do? compute \\(u(c)\\) and \\(u'(c)\\) it is often also useful to know inverse marginal utility compute the growth rate of \\(c\\) and (related) Euler equation deviations This defines the API that is visible to the outside world and common to all utility functions. Note: If we were a bit more serious, we would think about embedding all of this into a bigger set of utility functions that depend on multiple arguments. Let's start with log utility. Log has no parameters, so we have struct UtilityLog end But for CRRA we have struct UtilityCRRA sigma :: Float64 end Note: We generally would not want to hard-wire that sigma is a Float64 . More generic would be a parametric type : struct UtilityCRRA { T } sigma :: T end But we keep things simple for now. Since we are packaging the code, we will wrap it into a module (which we will later make into a package). Exercise: write code for the utility functions. My solution Exercise: write tests for the utility functions. My solution","title":"Factoring out Preferences"},{"location":"econ890/julia/pih/pih2.html#making-a-model","text":"Now we easily build a Model from its parts. struct Model Y :: Float64 R :: Float64 T :: Int beta :: Float64 u :: AbstractUtility end m = Model ( 10.0 , 1.04 , 30 , 0.98 , UtilityLog ()); Note: switching out the utility function is now trivial adding new utility functions is just as trivial the code does not contain any if utilityLog type switches Exercise: Write this code - and don't forget the tests. My solution and the tests I packaged everything in modules because: eventually, this should go into a package (therefore into a module) once we define structs , we cannot repeatedly include the code (invalid redefinition of the struct) the module makes sure that we don't have side-effects. Note: Tracking changes when code lives in module s with Revise.jl can be tricky. Code needs to be included with includet (for tracking), not with include . Even then Revise.jl struggles with nested includet s. Once you have module s, it's always best to use package s.","title":"Making a Model"},{"location":"econ890/julia/pih/pih3.html","text":"Permanent Income Model 3: Shooting \u00b6 Generalize the model to non-homothetic preferences. Now \\(g(c)\\) depends on \\(c\\) . There is no closed-form solution. Algorithm: Shooting \u00b6 Search over values for \\(c_{T}\\) . For each: Compute \\(c_t\\) from the Euler equation (backwards). Compute the present value of consumption. Check the lifetime budget constraint. Note: Searching over values of \\(c_{1}\\) creates numerical problems in some models. Roughly: small changes in \\(c_{1}\\) can imply large changes in \\(c_{T}\\) . Example: transition path of a standard growth model (between steady states). Higher \\(c_{1}\\) implies lower saving, higher interest rate, higher consumption growth This creates a feedback loop where consumption growth explodes. Interpolation \u00b6 A simple way of finding the optimal \\(c_T\\) : Compute the present value of consumption on a grid of \\(c_T\\) . Interpolate between grid points to find the value that satisfies the budget constraint. Algorithm outline: \u00b6 Initialize the model (unchanged). Set up a grid for \\(c_{T}\\) . For each grid point: Solve for the present value of consumption. Interpolate to find the \\(c_{T}\\) for which the present value of \\(c\\) equals \\(Y\\) . Compute the present value of consumption: Input \\(c_{T}\\) and model. Compute the consumption path \\(c_{t}\\) . Compute the present value. Computing the consumption path: Start with \\(c_{T}\\) . Compute consumption growth. Compute \\(c_{t-1} = c_{t} / g(c)\\) . Iterate backwards. Exercise: write this code - and don't forget the tests Root Finding \u00b6 In my solution , the interpolation is simply hand coded. Usually, one would use a package for this (such as Interpolations.jl ). Interpolation is, of course, inefficient. We need to compute a large number of grid points for \\(c_T\\) . A better solution is to use a numerical optimizer. Solving this model is an example of root finding. We are looking for the solution to \\(f(c_T)=0\\) . There are various libraries that offer algorithms for root finding and for the more common problem of minimizing a function. Using these libraries requires that we install packages . In this case, we will use Roots.jl . See root finding . find_zero finds the root of a function f(x) . This is what we will use. Excercise: write this code. My solution with test","title":"Permanent Income Model 3: Shooting"},{"location":"econ890/julia/pih/pih3.html#permanent-income-model-3-shooting","text":"Generalize the model to non-homothetic preferences. Now \\(g(c)\\) depends on \\(c\\) . There is no closed-form solution.","title":"Permanent Income Model 3: Shooting"},{"location":"econ890/julia/pih/pih3.html#algorithm-shooting","text":"Search over values for \\(c_{T}\\) . For each: Compute \\(c_t\\) from the Euler equation (backwards). Compute the present value of consumption. Check the lifetime budget constraint. Note: Searching over values of \\(c_{1}\\) creates numerical problems in some models. Roughly: small changes in \\(c_{1}\\) can imply large changes in \\(c_{T}\\) . Example: transition path of a standard growth model (between steady states). Higher \\(c_{1}\\) implies lower saving, higher interest rate, higher consumption growth This creates a feedback loop where consumption growth explodes.","title":"Algorithm: Shooting"},{"location":"econ890/julia/pih/pih3.html#interpolation","text":"A simple way of finding the optimal \\(c_T\\) : Compute the present value of consumption on a grid of \\(c_T\\) . Interpolate between grid points to find the value that satisfies the budget constraint.","title":"Interpolation"},{"location":"econ890/julia/pih/pih3.html#algorithm-outline","text":"Initialize the model (unchanged). Set up a grid for \\(c_{T}\\) . For each grid point: Solve for the present value of consumption. Interpolate to find the \\(c_{T}\\) for which the present value of \\(c\\) equals \\(Y\\) . Compute the present value of consumption: Input \\(c_{T}\\) and model. Compute the consumption path \\(c_{t}\\) . Compute the present value. Computing the consumption path: Start with \\(c_{T}\\) . Compute consumption growth. Compute \\(c_{t-1} = c_{t} / g(c)\\) . Iterate backwards. Exercise: write this code - and don't forget the tests","title":"Algorithm outline:"},{"location":"econ890/julia/pih/pih3.html#root-finding","text":"In my solution , the interpolation is simply hand coded. Usually, one would use a package for this (such as Interpolations.jl ). Interpolation is, of course, inefficient. We need to compute a large number of grid points for \\(c_T\\) . A better solution is to use a numerical optimizer. Solving this model is an example of root finding. We are looking for the solution to \\(f(c_T)=0\\) . There are various libraries that offer algorithms for root finding and for the more common problem of minimizing a function. Using these libraries requires that we install packages . In this case, we will use Roots.jl . See root finding . find_zero finds the root of a function f(x) . This is what we will use. Excercise: write this code. My solution with test","title":"Root Finding"},{"location":"econ890/julia/pih/pih4.html","text":"Permanent Income Model 4: Value Function Iteration \u00b6 Now we solve the model by backward induction. This is not efficient in this case, but gets us started on methods for the more general Huggett model. The math \u00b6 Bellman equation: \\(V(k,t)=\\max_{k'} U(w+rk-k') + \\beta V(k',t+1)\\) with first order condition \\(U'(w+rk-k')=\\beta V_{k}(k',t+1)\\) and envelope condition \\(V_{k}(k,t) = r U'(w + rk - k')\\) Value Function Iteration \u00b6 Start at \\(t = T\\) with \\(V(k,T) = U(w+rk)\\) . Set up a grid for \\(k\\) . For each \\(k\\) on the grid: maximize \\(U(w+rk-k') + \\beta V(k',t+1)\\) by searching over \\(k'\\) this gives \\(k'=G(k,t)\\) compute \\(V(k,t) = U(w+rk-G(k,t)) + \\beta V(G(k,t), t+1)\\) Problem: We need to evaluate \\(V(k',t+1)\\) off the grid. Solution: Interpolation (below). This is inefficient it involves a numerical maximization for each \\(k\\) grid point it is much easier (numerically) to find a root than to maximize a function Therefore, we switch to finding roots of the Euler equation instead. Approximate \\(V_{k}(k,t)\\) \u00b6 Start at \\(t=T\\) with \\(V_{k}(k,T)=U'(w+rk-k')\\) . Set up a grid for \\(k\\) . For each \\(k\\) on the grid: Search for the root of \\(U'(w+rk-k')-\\beta V_{k}(k',t+1)\\) Compute the decision rule \\(k' = G(k,t)\\) Compute \\(V_{k}(k,t) = r U'(w + rk - G(k,t))\\) Problem: We have \\(V_{k}\\) on the grid, but for the root finding we need \\(V_{k}\\) off the grid. Solution: Construct a function that approximates \\(V_{k}\\) based on the grid points that we have computed. Problem: \\(V_{k}\\) is highly nonlinear, so it is hard to approximate. Solution: Restate the FOC as \\(w+rk-k'=U'^{-1}(\\beta V_{k}(k',t+1))\\) . Approximate the RHS of this expression. Find the root of the corresponding deviation: \\(k'=G(k,t)\\) . Use this to compute \\(V_{k}(k,t)\\) on the grid. This is a viable algorithm, but we will implement something different. Policy Function Iteration \u00b6 We don't really care about value functions per se ( \\(V\\) or \\(V_{k}\\) ). We care about decision rules \\(k'=G(k,t)\\) . So we approximate them directly. Start at \\(t=T\\) with \\(G(k,T) = 0\\) . Set up a grid for \\(k\\) . For each \\(k\\) on the grid: find the root of the Euler equation \\(U'(w+rk-k') - \\beta R U'(w'+rk'-G(k', t+1))\\) but better (not as non-linear): \\(w+rk-k' - U'^{-1}(\\beta R U'(w'+rk'-G(k', t+1)))\\) this gives \\(k'=G(k,t)\\) on the \\(k\\) grid. Again, we need to interpolate the policy function between grid points. Recall that we already talked about root finding . Let's think about this problem a bit more. The expression \\(w+rk-k' - U'^{-1}(\\beta R U'(w'+rk'-G(k', t+1)))\\) can be thought of as \\(D(k',k)\\) . We are looking for \\(D(k',k) = 0\\) . The solution is \\(G(k', t)\\) . Let's start from the \"inside\" of the problem. Suppose we have \\(D(k', k)\\) on the grid, our first task is to make this a continuous function. This is done with interpolation . One approach that we used before: each time we need to get a value \\(D(k', k)\\) , we call an interpolation function. But this is tedious and inelegant. The better approach is to construct a continuous function that represents \\(D(k', k)\\) . One package that does this is Interpolations.jl . QuantEcon contains a nice description that we will use here. Making a package \u00b6 Before we write the code, we should ensure that UtilityFunctions is nicely reusable as a package. Here are the instructions . Once this is all done, we will set up a separate package for the policy function iteration code. Follow the same directions, but label your package PihVfi890 (permanent income hypothesis model via value function iteration). Note that you can simply reuse the template that you generated for the UtilityFunctions890 package. Go back to the Econ890 directory and just type t(\"PihVfi890\") . You just created a package in 10 seconds. We need to add UtilityFunctions890 as a dependency for our new package. But it's not registered. Solution: pkg> dev ../UtilityFunctions890 . Take a look at Project.toml to see what we just did. This is why packages are so useful. We can now reuse UtilityFunctions890 in all future code that we write. These packages all now live in my github repo . Writing the solution code \u00b6 This looks complicated. So how do we make it tractable? Structured programming and top down design to the rescue. The trick is to simply write out the steps that we want to perform without worrying about how to do each: Solve the last period: \\(G(k', T) = 0\\) . This is trivial. For each \\(t\\) (backwards): Make a capital grid for period \\(t\\) . Find \\(k' = G(k, t)\\) for each grid point. Interpolate \\(G(k, t)\\) to make a continuous function. When all is done: check the solution. That's surprisingly it. It translates fairly directly into code. Now write this out in code and you have solve() in PihVfi890.jl . Next, we fill in details. solve_last_period is basically trivial. solve_one_period just iterates over grid points and then calls ... solve_one_point which checks for corner solutions runs find_zero on \\(D(k', k)\\) Finally, we need to check the solution to make sure it satisfies budget constraint and Euler equation Exercise: write this code. \u00b6 My solution is in the PihVfi890 repo. Don't forget the tests!","title":"Permanent Income Model 4: Value Function Iteration"},{"location":"econ890/julia/pih/pih4.html#permanent-income-model-4-value-function-iteration","text":"Now we solve the model by backward induction. This is not efficient in this case, but gets us started on methods for the more general Huggett model.","title":"Permanent Income Model 4: Value Function Iteration"},{"location":"econ890/julia/pih/pih4.html#the-math","text":"Bellman equation: \\(V(k,t)=\\max_{k'} U(w+rk-k') + \\beta V(k',t+1)\\) with first order condition \\(U'(w+rk-k')=\\beta V_{k}(k',t+1)\\) and envelope condition \\(V_{k}(k,t) = r U'(w + rk - k')\\)","title":"The math"},{"location":"econ890/julia/pih/pih4.html#value-function-iteration","text":"Start at \\(t = T\\) with \\(V(k,T) = U(w+rk)\\) . Set up a grid for \\(k\\) . For each \\(k\\) on the grid: maximize \\(U(w+rk-k') + \\beta V(k',t+1)\\) by searching over \\(k'\\) this gives \\(k'=G(k,t)\\) compute \\(V(k,t) = U(w+rk-G(k,t)) + \\beta V(G(k,t), t+1)\\) Problem: We need to evaluate \\(V(k',t+1)\\) off the grid. Solution: Interpolation (below). This is inefficient it involves a numerical maximization for each \\(k\\) grid point it is much easier (numerically) to find a root than to maximize a function Therefore, we switch to finding roots of the Euler equation instead.","title":"Value Function Iteration"},{"location":"econ890/julia/pih/pih4.html#approximate-v_kkt","text":"Start at \\(t=T\\) with \\(V_{k}(k,T)=U'(w+rk-k')\\) . Set up a grid for \\(k\\) . For each \\(k\\) on the grid: Search for the root of \\(U'(w+rk-k')-\\beta V_{k}(k',t+1)\\) Compute the decision rule \\(k' = G(k,t)\\) Compute \\(V_{k}(k,t) = r U'(w + rk - G(k,t))\\) Problem: We have \\(V_{k}\\) on the grid, but for the root finding we need \\(V_{k}\\) off the grid. Solution: Construct a function that approximates \\(V_{k}\\) based on the grid points that we have computed. Problem: \\(V_{k}\\) is highly nonlinear, so it is hard to approximate. Solution: Restate the FOC as \\(w+rk-k'=U'^{-1}(\\beta V_{k}(k',t+1))\\) . Approximate the RHS of this expression. Find the root of the corresponding deviation: \\(k'=G(k,t)\\) . Use this to compute \\(V_{k}(k,t)\\) on the grid. This is a viable algorithm, but we will implement something different.","title":"Approximate \\(V_{k}(k,t)\\)"},{"location":"econ890/julia/pih/pih4.html#policy-function-iteration","text":"We don't really care about value functions per se ( \\(V\\) or \\(V_{k}\\) ). We care about decision rules \\(k'=G(k,t)\\) . So we approximate them directly. Start at \\(t=T\\) with \\(G(k,T) = 0\\) . Set up a grid for \\(k\\) . For each \\(k\\) on the grid: find the root of the Euler equation \\(U'(w+rk-k') - \\beta R U'(w'+rk'-G(k', t+1))\\) but better (not as non-linear): \\(w+rk-k' - U'^{-1}(\\beta R U'(w'+rk'-G(k', t+1)))\\) this gives \\(k'=G(k,t)\\) on the \\(k\\) grid. Again, we need to interpolate the policy function between grid points. Recall that we already talked about root finding . Let's think about this problem a bit more. The expression \\(w+rk-k' - U'^{-1}(\\beta R U'(w'+rk'-G(k', t+1)))\\) can be thought of as \\(D(k',k)\\) . We are looking for \\(D(k',k) = 0\\) . The solution is \\(G(k', t)\\) . Let's start from the \"inside\" of the problem. Suppose we have \\(D(k', k)\\) on the grid, our first task is to make this a continuous function. This is done with interpolation . One approach that we used before: each time we need to get a value \\(D(k', k)\\) , we call an interpolation function. But this is tedious and inelegant. The better approach is to construct a continuous function that represents \\(D(k', k)\\) . One package that does this is Interpolations.jl . QuantEcon contains a nice description that we will use here.","title":"Policy Function Iteration"},{"location":"econ890/julia/pih/pih4.html#making-a-package","text":"Before we write the code, we should ensure that UtilityFunctions is nicely reusable as a package. Here are the instructions . Once this is all done, we will set up a separate package for the policy function iteration code. Follow the same directions, but label your package PihVfi890 (permanent income hypothesis model via value function iteration). Note that you can simply reuse the template that you generated for the UtilityFunctions890 package. Go back to the Econ890 directory and just type t(\"PihVfi890\") . You just created a package in 10 seconds. We need to add UtilityFunctions890 as a dependency for our new package. But it's not registered. Solution: pkg> dev ../UtilityFunctions890 . Take a look at Project.toml to see what we just did. This is why packages are so useful. We can now reuse UtilityFunctions890 in all future code that we write. These packages all now live in my github repo .","title":"Making a package"},{"location":"econ890/julia/pih/pih4.html#writing-the-solution-code","text":"This looks complicated. So how do we make it tractable? Structured programming and top down design to the rescue. The trick is to simply write out the steps that we want to perform without worrying about how to do each: Solve the last period: \\(G(k', T) = 0\\) . This is trivial. For each \\(t\\) (backwards): Make a capital grid for period \\(t\\) . Find \\(k' = G(k, t)\\) for each grid point. Interpolate \\(G(k, t)\\) to make a continuous function. When all is done: check the solution. That's surprisingly it. It translates fairly directly into code. Now write this out in code and you have solve() in PihVfi890.jl . Next, we fill in details. solve_last_period is basically trivial. solve_one_period just iterates over grid points and then calls ... solve_one_point which checks for corner solutions runs find_zero on \\(D(k', k)\\) Finally, we need to check the solution to make sure it satisfies budget constraint and Euler equation","title":"Writing the solution code"},{"location":"econ890/julia/pih/pih4.html#exercise-write-this-code","text":"My solution is in the PihVfi890 repo. Don't forget the tests!","title":"Exercise: write this code."},{"location":"econ890/julia/pih/root_finding.html","text":"Root Finding \u00b6 Root finding means finding the zero of a function, i.e., find \\(x^*\\) such that \\(f(x^*) = 0\\) . For this type of problem, we use code packaged into reusable libraries, called \"packages\". See the Section on Packages . In this case, we will use Roots.jl . Before we can use Roots , we need to add it as a dependency to the current environment : julia > cd ( \"/Users/lutz/Documents/data/web/professional/docs/econ890/julia/\" ) ( @v1 . 5 ) pkg > activate . Activating new environment at `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` We have now activated the environment described by Project.toml in this directory. To get the Pkg commands to work, type ] and the pkg> prompt appears. Backspace backs out of the Pkg mode in the REPL. To see which packages are already contained in the enviroment: ( julia ) pkg > st Status `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` ( empty project ) This makes sense; we have not added any packages yet. But keep in mind that everything we activated before (including all packages in your v1.5 environment are still available). Let's add Roots : ( julia ) pkg > add Roots Updating registry at `~/.julia/registries/General` ######################################################################## 100.0% Updating registry at `~/.julia/registries/registryLH` Updating git - repo `https://github.com/hendri54/registryLH` Resolving package versions ... Updating `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` [ f2b01f46 ] + Roots v1 . 0.8 Updating `~/Documents/data/web/professional/docs/econ890/julia/Manifest.toml` [ f2b01f46 ] + Roots v1 . 0.8 [ de0858da ] + Printf [ 4 ec0a83e ] + Unicode ( julia ) pkg > st Status `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` [ f2b01f46 ] Roots v1 . 0.8 Now using Roots works. Roots is a registered package, so it can be installed with pkg> add Roots . The package manager looks up where to find the files for Roots in the General Registry and downloads them. The code for Roots now resides in a subdirectory of .julia/packages . Each version of Roots gets its own subdirectory. So you can have several versions installed at the same time. But: Only one version of a package can be loaded at any given time. This can lead to interesting problems... Note that all of the dependencies of Roots were also installed automatically (in this case, Printf and Unicode ). Now we can use all functions that were exported by Roots.jl . For example: help?> find_zero search: find_zero find_zeros find_zero! find_zero(fs, x0, M, [N::AbstractBracketing]; kwargs...) Interface to one of several methods for find zeros of a univariate function. [...] julia> f(x) = exp(x) - x^4; julia> find_zero(f, (8, 9), Bisection()) 8.6131694564414 Closures \u00b6 We encounter a common problem: find_zero expects a one-argument function f(x) . But the function that we use takes 2 arguments: a model and \\(c_T\\) . This type of problem is solved using a closure . A closure is a function that \"captures\" some of the variables in the calling namespace. Example: julia > function foo () x = 1 ; g ( y ) = x + y ; @show g ( 2 ) x = 2 ; @show g ( 2 ) end foo ( generic function with 1 method ) julia > foo () g ( 2 ) = 3 g ( 2 ) = 4 Note that g has \"captured\" the variable x from foo . g behaves as if there were an implicit second argument. Anonymous functions \u00b6 When closures are used, they often remain unnamed. Example: julia > findfirst ( x -> x > 2 , 1 : 10 ) 3 # This is the same as julia > f ( x ) = x > 2 ; julia > findfirst ( f , 1 : 10 ) 3 But note: julia > [ x -> x ^ 2 for x in ( 1 , 2 , 3 )] 3 - element Array { var \"#9#11\" , 1 } : #9 (generic function with 1 method) #9 (generic function with 1 method) #9 (generic function with 1 method)","title":"Root Finding"},{"location":"econ890/julia/pih/root_finding.html#root-finding","text":"Root finding means finding the zero of a function, i.e., find \\(x^*\\) such that \\(f(x^*) = 0\\) . For this type of problem, we use code packaged into reusable libraries, called \"packages\". See the Section on Packages . In this case, we will use Roots.jl . Before we can use Roots , we need to add it as a dependency to the current environment : julia > cd ( \"/Users/lutz/Documents/data/web/professional/docs/econ890/julia/\" ) ( @v1 . 5 ) pkg > activate . Activating new environment at `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` We have now activated the environment described by Project.toml in this directory. To get the Pkg commands to work, type ] and the pkg> prompt appears. Backspace backs out of the Pkg mode in the REPL. To see which packages are already contained in the enviroment: ( julia ) pkg > st Status `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` ( empty project ) This makes sense; we have not added any packages yet. But keep in mind that everything we activated before (including all packages in your v1.5 environment are still available). Let's add Roots : ( julia ) pkg > add Roots Updating registry at `~/.julia/registries/General` ######################################################################## 100.0% Updating registry at `~/.julia/registries/registryLH` Updating git - repo `https://github.com/hendri54/registryLH` Resolving package versions ... Updating `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` [ f2b01f46 ] + Roots v1 . 0.8 Updating `~/Documents/data/web/professional/docs/econ890/julia/Manifest.toml` [ f2b01f46 ] + Roots v1 . 0.8 [ de0858da ] + Printf [ 4 ec0a83e ] + Unicode ( julia ) pkg > st Status `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` [ f2b01f46 ] Roots v1 . 0.8 Now using Roots works. Roots is a registered package, so it can be installed with pkg> add Roots . The package manager looks up where to find the files for Roots in the General Registry and downloads them. The code for Roots now resides in a subdirectory of .julia/packages . Each version of Roots gets its own subdirectory. So you can have several versions installed at the same time. But: Only one version of a package can be loaded at any given time. This can lead to interesting problems... Note that all of the dependencies of Roots were also installed automatically (in this case, Printf and Unicode ). Now we can use all functions that were exported by Roots.jl . For example: help?> find_zero search: find_zero find_zeros find_zero! find_zero(fs, x0, M, [N::AbstractBracketing]; kwargs...) Interface to one of several methods for find zeros of a univariate function. [...] julia> f(x) = exp(x) - x^4; julia> find_zero(f, (8, 9), Bisection()) 8.6131694564414","title":"Root Finding"},{"location":"econ890/julia/pih/root_finding.html#closures","text":"We encounter a common problem: find_zero expects a one-argument function f(x) . But the function that we use takes 2 arguments: a model and \\(c_T\\) . This type of problem is solved using a closure . A closure is a function that \"captures\" some of the variables in the calling namespace. Example: julia > function foo () x = 1 ; g ( y ) = x + y ; @show g ( 2 ) x = 2 ; @show g ( 2 ) end foo ( generic function with 1 method ) julia > foo () g ( 2 ) = 3 g ( 2 ) = 4 Note that g has \"captured\" the variable x from foo . g behaves as if there were an implicit second argument.","title":"Closures"},{"location":"econ890/julia/pih/root_finding.html#anonymous-functions","text":"When closures are used, they often remain unnamed. Example: julia > findfirst ( x -> x > 2 , 1 : 10 ) 3 # This is the same as julia > f ( x ) = x > 2 ; julia > findfirst ( f , 1 : 10 ) 3 But note: julia > [ x -> x ^ 2 for x in ( 1 , 2 , 3 )] 3 - element Array { var \"#9#11\" , 1 } : #9 (generic function with 1 method) #9 (generic function with 1 method) #9 (generic function with 1 method)","title":"Anonymous functions"},{"location":"econ920/syllabus920.html","text":"Econ920 - Macro Student Workshop \u00b6 Fall 2021 - Lutz Hendricks - UNC Class meets: Tuesdays, 11am, Gardner 7. Schedule: See the sakai site. Description \u00b6 A workshop where Ph.D. students present their research and receive feedback through class discussion. Organization \u00b6 Students sign up for presentations. Each student presents at least one paper per semester. Early stage research is perfectly fine. It is useful to get feedback early on. There will typically one presentation per class meeting. However, if time permits, we will set aside one or two sessions for shorter presentations of early stage project ideas . These can be very useful for framing your project and for weeding out ideas that are not promising before you spend a lot of time on them. Presenters make their slides available (also papers, if feasible) at least several days before the presentation. Everyone is expected to participate with constructive comments . This is a team effort. Students are required to attend all presentations. Students are expected to read papers before class (or peruse the slides, if there is no paper). Spend some time thinking about the paper. This will make the workshop far more productive. Objectives \u00b6 Receive feedback on your research. Learn presentation skills. Take your presentations seriously. You only get good feedback if you present well. Time management is key. Many presentations spend too much time on the Introduction and therefore don't get through the material. Learn to participate in (conference) presentations. Making constructive comments. Useful Links \u00b6 Presentation tips Other notes for graduate students","title":"Econ920"},{"location":"econ920/syllabus920.html#econ920-macro-student-workshop","text":"Fall 2021 - Lutz Hendricks - UNC Class meets: Tuesdays, 11am, Gardner 7. Schedule: See the sakai site.","title":"Econ920 - Macro Student Workshop"},{"location":"econ920/syllabus920.html#description","text":"A workshop where Ph.D. students present their research and receive feedback through class discussion.","title":"Description"},{"location":"econ920/syllabus920.html#organization","text":"Students sign up for presentations. Each student presents at least one paper per semester. Early stage research is perfectly fine. It is useful to get feedback early on. There will typically one presentation per class meeting. However, if time permits, we will set aside one or two sessions for shorter presentations of early stage project ideas . These can be very useful for framing your project and for weeding out ideas that are not promising before you spend a lot of time on them. Presenters make their slides available (also papers, if feasible) at least several days before the presentation. Everyone is expected to participate with constructive comments . This is a team effort. Students are required to attend all presentations. Students are expected to read papers before class (or peruse the slides, if there is no paper). Spend some time thinking about the paper. This will make the workshop far more productive.","title":"Organization"},{"location":"econ920/syllabus920.html#objectives","text":"Receive feedback on your research. Learn presentation skills. Take your presentations seriously. You only get good feedback if you present well. Time management is key. Many presentations spend too much time on the Introduction and therefore don't get through the material. Learn to participate in (conference) presentations. Making constructive comments.","title":"Objectives"},{"location":"econ920/syllabus920.html#useful-links","text":"Presentation tips Other notes for graduate students","title":"Useful Links"},{"location":"graduate/computational_econ.html","text":"References: Computational Methods \u00b6 Text Books for Macroeconomists \u00b6 Heer, Burkhard, and Alfred Maussner. \"Dynamic General Equilibrium Modelling Springer Berlin.\" Heidelberg, New York (2008).","title":"References: Computational Methods #"},{"location":"graduate/computational_econ.html#references-computational-methods","text":"","title":"References: Computational Methods"},{"location":"graduate/computational_econ.html#text-books-for-macroeconomists","text":"Heer, Burkhard, and Alfred Maussner. \"Dynamic General Equilibrium Modelling Springer Berlin.\" Heidelberg, New York (2008).","title":"Text Books for Macroeconomists"},{"location":"graduate/discussion_forums.html","text":"{{../markdown_header.txt}} Economics Discussion Forums \u00b6 EconSpark * seems focuses on job market, but there is a \"general questions\" section Forums that seem overrun by spam: * Debate.org","title":"Discussion forums"},{"location":"graduate/discussion_forums.html#economics-discussion-forums","text":"EconSpark * seems focuses on job market, but there is a \"general questions\" section Forums that seem overrun by spam: * Debate.org","title":"Economics Discussion Forums"},{"location":"graduate/dissertation_tips.html","text":"Dissertation Tips \u00b6 Finding a topic \u00b6 Work top down \u00b6 When you start out, you just don't know which questions are interesting, which have been answered, etc. So you start broadly. Pick something that interests you and start reading. Let's use cross-country income gaps as an example. Rich countries are 25 times richer than poor countries. Why? Start reading. Take notes on what you read. Organize your notes, so you understand the \"tree of questions\" in that literature. In our example, part of the tree may look like this: How important are capital, human capital, and productivity? Within human capital: how that this be measured? Why does it differ across countries? Within the measurement question: there is a Mincerian approach and a production function approach. Questions there: how can we measure inputs to human capital production? How can we estimate a production function? The point is to get from vague, broad questions to specific questions that one could potentially study. Advisors \u00b6 Even a well posed question does not help you if you cannot find an advisor. Therefore, you need to focus on areas where someone on the faculty has expertise. At the very start of your search, you should visit the websites of faculty members in your field of interest and read some of their recent papers. This will give you an idea of the range of topics that you can get support for. It will also give you feel for the techniques that each faculty member uses (e.g., theory, econometrics, computational modeling). The best approach is to not look for a topic. \u00b6 Just sit down and try to understand how the literature answers a question of interest. Yes: a question ! Good project ideas end with a question mark. Be suspicious of ideas like \"we want to explore ...\" Be very suspcious about ideas like \"what happens when feature x is added to a model?\" You need a question. Anyway, at some point you'll get the idea of what others think about the question of interest (or even of what interesting questions in a given area may be). Then simply ask: \" Do I believe what I have read? Is it convincing? \" Forget the fact that you are looking for a project. Just ask whether you believe what you have read. You will typically find that there are many shaky issues in the proposed answers. That's where an idea is born. If you find something that is really unconvincing, it is an opportunity to do better. Example : You decide to study the question: \"How much does human capital differ across countries?\" The literature basically has two types of answers. Mincer equations: Regress log wages on schooling for U.S. workers. Assume that workers with given schooling have the same human capital in all countries. Estimate a schooling production function. Estimate schooling inputs for a set of countries. Calculate human capital from the production function. The Mincer approach is not credible because it must assume that workers with given schooling have the same human capital everywhere. The production function approach turns out to be very tricky. It is extremely hard to measure schooling inputs (parental time, school inputs, child study time, child abilities, peer effects, etc.) and outputs (adult wages?). The functional form of the school production function is unknown. This leads to two project ideas : Try to improve the estimation of human capital production functions. Look for better data (existing studies did not use individual data - this actually would be a good project which has not been done at the time I am writing this). Try to measure human capital without estimating a production function. How can this be done? If one could observe the productivity of workers from different countries, that would work. This leads to the idea: estimate the productivity of workers from country x as the wages earned by U.S. immigrants from that country (Hendricks 2002 AER). Of course, in most cases it will simply be too hard to do better. Then you don't believe that the existing findings are bullet proof, but they are still the best answers available. It is useful to keep these kinds of situations in the back of your mind. Perhaps you'll see something later that allows you to follow through with your idea after all. Example : The migration literature argues about immigrant quality and earnings of immigrants relative to natives. But it's very hard to figure out what's really going on in all the data because we don't have longitudinal observations. So there is a clear potential for improvement, but it's not feasible because the data don't exist. Write that down. Later on you find out about the German Socioeconomic Panel and the fact that it oversamples guestworkers. Perhaps one could use that data to address the open issues? (This is actually a project idea worth pursuing, not just a ficticious example. In fact, recently a number of papers using longitudinal immigrant data have come out in top journals.) Use common sense . A fair number of good ideas are obvious with hindsight. Example: A large literature has studied the causes of cross-country income gaps. Many hypotheses were investigated: human capital, organization capital, trade, etc. But common sense tells us that institutions are important. The obvious evidence comes from divided countries (East and West Germany) and from the former Soviet Block. Strangely, it took a very long time for this idea to be explored in economic research. One more suggestion: Work on a topic that at least one local faculty member knows in detail . Otherwise, it will be hard to convince your committee members to spend a lot of time on your project. And the comments you will receive may be far off the mark. Make a serious effort to demolish your ideas. \u00b6 What happens once you have found a candidate topic: Try to convince yourself that the idea is no good . This is important. Before you sink any time into an idea, make sure it is worth it. Most ideas are not worth anything. There are many reasons. Perhaps the idea is too marginal. But more commonly it is outright flawed. Make a list of objections against your idea. Be sure you know how to respond to them. Talk to people and ask them for objections. Do this early . Do not wait until you have a model or (worse) a paper draft. One objection could destroy the entire effort you put into the project. Such as: \"X has done that already in a 1955 paper\" or \"This does not make sense because of XYZ.\" Be sure to try simple examples first. They sometimes reveal fundamental flaws in an idea or question. Example: You want to argue that schooling accounts for large cross-country income gaps. You think about a model in which human capital depends on schooling according to h(s) = h(0) * g(s). A back of the envelope calculations that this cannot work. To generate income gaps of, say, a factor 10, you would need h(12)/h(2)=10 (U.S. versus Uganda). Then the return to schooling would have to be enormous. A similar advice applies to the implementation. You may have a good question, but not a good way of answering it. Don't forget common sense . A lot of papers go through sophisticated analysis of a model that just doesn't make common sense. Motivation, Ideas, and Lack Thereof \u00b6 A common problem with dissertation topics is lack of motivation or lack of an idea. I often see papers that extend existing work in minor ways without any good reason why that should be done. Often, these are extensions of field papers. Usually, these turn out to be a waste of time. Relaxing an assumption does not make a paper . You need to convince people that it matters to attack a question in a more general way. A paper needs an idea . It is easy to find good questions. It is hard to find good ideas. Do not waste time on a project until you have convinced yourself that the idea is worthwhile. A question is something broad like: \"How important are productivity shocks for business cycles?\" \"Why does education differ across countries?\" An idea is a specific approach to answering a question. Such as: Kydland & Prescott for the business cycle question. Before you start working on the details, you should be able to explain in non-technical terms why your idea has merit. If you can't do that, chances are your idea is not important. Depth \u00b6 Writing a good paper requires that you really understand the literature. You should read a lot and think a lot. See my comments on specialization. When you start reading about a subject, you will generate lots of ideas. Most of these are no good, but you won't be able to see this until you really understand the literature. Defer the Details \u00b6 I see a lot of students with half-baked ideas and fully worked out models. This is a waste of time. In most cases, don't write down a model until you can precisely state: What is the question? Why is it important? What is the approach? Why does the approach make sense? What is the potential punchline? To borrow from Lee Ohanian: How does your paper change the way I think about the world? How does it fit into the literature? This, by the way, makes a good template for an Introduction. You cannot know what ingredients your model needs to have, until you can answer these questions. To Plan or Not to Plan? \u00b6 Some people ask: \"what is your research agenda?\" Ideally one could answer: \"I want to understand this big picture question and here are the steps that will get me there ... At the end I should have the following papers ...\" If that works, great! It usually doesn't (take a look at Parente and Prescott Barriers to Riches for a great example where it did work). There are at least two reasons: Until you have actually done a step in the plan, you typically have no idea what will come out (especially if the work has any empirical content). But what comes next depends critically on what you found before. It is hard to come up with a good idea/question that can actually be done. It is darn hard to come up with a whole sequence of such ideas at a time. Therefore, be realistic and take project ideas one at a time. Think of each dissertation chapter as one publishable paper. Don't try to write a monolithic dissertation where one chapter leads cleanly to the next. It's perfectly fine if your chapters address different questions. Specialize! \u00b6 At any cost, avoid working on several unrelated problems. To be successful, you must specialize. Each time you work on a new topic, you incur the large fixed cost of really, deeply understanding the literature. It is therefore essential to zero in on one or two areas and then stick to those for several years. If you do not follow this advice, you will encounter two problems: Your papers will lack depth. They may look superficially interesting, but experts will view your papers as missing the point. When you try to publish your work, you will have to convince referees that you should be taken seriously. They need to know that you have published in the same area before. Aim to associate your name with a topic. If you work in many different areas, nobody will know who you are. But if you persistently work in one area, people will hear your name and immediately think: \"he/she works on X.\" This is how your work is taken seriously and how to get impact. Disclaimer: I am sure there are reasonable people who vehemently disagree with my views on this. Theory vs. Empirical Work \u00b6 Theory is glamorous and in many respects just more interesting and more fun to do than data work. If you doubt that, start reading the documentation for the PSID. Data work involves a lot of tedious steps and a lot of time during which essentially nothing is learned (except about the twisted minds of those who publish data sets). If you doubt that, start reading the documentation for the PSID. And yet, you should consider doing empirical work. For one simple reason: It may get you a job. There are loads of theorists coming out of top departments every year. The best of them get jobs. The others often have a hard time because the market for pure theory is not that large. Having an empirical project or at least a serious empirical part in your dissertation immensely increases the range of jobs you can apply for. There is unfortunately a big barrier standing between graduate students and data: Empirical work is hardly ever taught. The first time around, the startup investment required for using a data set is very large. If you doubt that, start reading the documentation for the PSID. Which is why many grad students never touch any data. But this obstacle can be overcome through persistence. Communicating with your committee members (CMs) \u00b6 Remember: your CMs don't think about your project all the time. They forget details between meetings. Therefore: Stay in touch regularly. Too many students show up with a completed paper that was written without any input from the CMs. They are then surprised when the CMs think that major revisions are needed. Have a short summary document ready. In particular, have a document with the model equations. Prepare for each meeting. Summarize your progress and the issues to be discussed in a short document. Documents should not be written in prose. Prose is a waste of time for the writer and for the reader. Use an outline format. Respond to comments. Do not just ignore them. Again, a short reply document is useful. Writing \u00b6 Early on, write out a plan for the paper It should address the items in the intro. Be clear about what results you may get and what the contribution would be. Until you can clearly state the potential contribution of the project, don't spend any time on it. Models are presented in a standard format: Describe demographics, preferences, endowments, technologies, market arrangements. State each agent's problem. Define an equilibrium. Only when all of this is done are you allowed to analyze the properties of the model. See also notes on writing . To Ph.D. or not to Ph.D.? \u00b6 Finally, a word for those who are considering whether or not to apply for a Ph.D. program: If you are not sure you want a Ph.D., do something else. The Ph.D. program is structured with a single outcome in mind: to place graduating students as faculty in Research I universities. The material learned is useful for only one purpose: for publishing research in academic journals. It is not useful for consulting, for working in businesses or the government (other than the Fed), or even for teaching. Therefore, if you are not sure you want to do academic research for the rest of your life, do not apply for Ph.D. programs in economics. An MA or an MBA always has a higher payoff and will save you years of frustration.","title":"Dissertation Tips #"},{"location":"graduate/dissertation_tips.html#dissertation-tips","text":"","title":"Dissertation Tips"},{"location":"graduate/dissertation_tips.html#finding-a-topic","text":"","title":"Finding a topic"},{"location":"graduate/dissertation_tips.html#work-top-down","text":"When you start out, you just don't know which questions are interesting, which have been answered, etc. So you start broadly. Pick something that interests you and start reading. Let's use cross-country income gaps as an example. Rich countries are 25 times richer than poor countries. Why? Start reading. Take notes on what you read. Organize your notes, so you understand the \"tree of questions\" in that literature. In our example, part of the tree may look like this: How important are capital, human capital, and productivity? Within human capital: how that this be measured? Why does it differ across countries? Within the measurement question: there is a Mincerian approach and a production function approach. Questions there: how can we measure inputs to human capital production? How can we estimate a production function? The point is to get from vague, broad questions to specific questions that one could potentially study.","title":"Work top down"},{"location":"graduate/dissertation_tips.html#advisors","text":"Even a well posed question does not help you if you cannot find an advisor. Therefore, you need to focus on areas where someone on the faculty has expertise. At the very start of your search, you should visit the websites of faculty members in your field of interest and read some of their recent papers. This will give you an idea of the range of topics that you can get support for. It will also give you feel for the techniques that each faculty member uses (e.g., theory, econometrics, computational modeling).","title":"Advisors"},{"location":"graduate/dissertation_tips.html#the-best-approach-is-to-not-look-for-a-topic","text":"Just sit down and try to understand how the literature answers a question of interest. Yes: a question ! Good project ideas end with a question mark. Be suspicious of ideas like \"we want to explore ...\" Be very suspcious about ideas like \"what happens when feature x is added to a model?\" You need a question. Anyway, at some point you'll get the idea of what others think about the question of interest (or even of what interesting questions in a given area may be). Then simply ask: \" Do I believe what I have read? Is it convincing? \" Forget the fact that you are looking for a project. Just ask whether you believe what you have read. You will typically find that there are many shaky issues in the proposed answers. That's where an idea is born. If you find something that is really unconvincing, it is an opportunity to do better. Example : You decide to study the question: \"How much does human capital differ across countries?\" The literature basically has two types of answers. Mincer equations: Regress log wages on schooling for U.S. workers. Assume that workers with given schooling have the same human capital in all countries. Estimate a schooling production function. Estimate schooling inputs for a set of countries. Calculate human capital from the production function. The Mincer approach is not credible because it must assume that workers with given schooling have the same human capital everywhere. The production function approach turns out to be very tricky. It is extremely hard to measure schooling inputs (parental time, school inputs, child study time, child abilities, peer effects, etc.) and outputs (adult wages?). The functional form of the school production function is unknown. This leads to two project ideas : Try to improve the estimation of human capital production functions. Look for better data (existing studies did not use individual data - this actually would be a good project which has not been done at the time I am writing this). Try to measure human capital without estimating a production function. How can this be done? If one could observe the productivity of workers from different countries, that would work. This leads to the idea: estimate the productivity of workers from country x as the wages earned by U.S. immigrants from that country (Hendricks 2002 AER). Of course, in most cases it will simply be too hard to do better. Then you don't believe that the existing findings are bullet proof, but they are still the best answers available. It is useful to keep these kinds of situations in the back of your mind. Perhaps you'll see something later that allows you to follow through with your idea after all. Example : The migration literature argues about immigrant quality and earnings of immigrants relative to natives. But it's very hard to figure out what's really going on in all the data because we don't have longitudinal observations. So there is a clear potential for improvement, but it's not feasible because the data don't exist. Write that down. Later on you find out about the German Socioeconomic Panel and the fact that it oversamples guestworkers. Perhaps one could use that data to address the open issues? (This is actually a project idea worth pursuing, not just a ficticious example. In fact, recently a number of papers using longitudinal immigrant data have come out in top journals.) Use common sense . A fair number of good ideas are obvious with hindsight. Example: A large literature has studied the causes of cross-country income gaps. Many hypotheses were investigated: human capital, organization capital, trade, etc. But common sense tells us that institutions are important. The obvious evidence comes from divided countries (East and West Germany) and from the former Soviet Block. Strangely, it took a very long time for this idea to be explored in economic research. One more suggestion: Work on a topic that at least one local faculty member knows in detail . Otherwise, it will be hard to convince your committee members to spend a lot of time on your project. And the comments you will receive may be far off the mark.","title":"The best approach is to not look for a topic."},{"location":"graduate/dissertation_tips.html#make-a-serious-effort-to-demolish-your-ideas","text":"What happens once you have found a candidate topic: Try to convince yourself that the idea is no good . This is important. Before you sink any time into an idea, make sure it is worth it. Most ideas are not worth anything. There are many reasons. Perhaps the idea is too marginal. But more commonly it is outright flawed. Make a list of objections against your idea. Be sure you know how to respond to them. Talk to people and ask them for objections. Do this early . Do not wait until you have a model or (worse) a paper draft. One objection could destroy the entire effort you put into the project. Such as: \"X has done that already in a 1955 paper\" or \"This does not make sense because of XYZ.\" Be sure to try simple examples first. They sometimes reveal fundamental flaws in an idea or question. Example: You want to argue that schooling accounts for large cross-country income gaps. You think about a model in which human capital depends on schooling according to h(s) = h(0) * g(s). A back of the envelope calculations that this cannot work. To generate income gaps of, say, a factor 10, you would need h(12)/h(2)=10 (U.S. versus Uganda). Then the return to schooling would have to be enormous. A similar advice applies to the implementation. You may have a good question, but not a good way of answering it. Don't forget common sense . A lot of papers go through sophisticated analysis of a model that just doesn't make common sense.","title":"Make a serious effort to demolish your ideas."},{"location":"graduate/dissertation_tips.html#motivation-ideas-and-lack-thereof","text":"A common problem with dissertation topics is lack of motivation or lack of an idea. I often see papers that extend existing work in minor ways without any good reason why that should be done. Often, these are extensions of field papers. Usually, these turn out to be a waste of time. Relaxing an assumption does not make a paper . You need to convince people that it matters to attack a question in a more general way. A paper needs an idea . It is easy to find good questions. It is hard to find good ideas. Do not waste time on a project until you have convinced yourself that the idea is worthwhile. A question is something broad like: \"How important are productivity shocks for business cycles?\" \"Why does education differ across countries?\" An idea is a specific approach to answering a question. Such as: Kydland & Prescott for the business cycle question. Before you start working on the details, you should be able to explain in non-technical terms why your idea has merit. If you can't do that, chances are your idea is not important.","title":"Motivation, Ideas, and Lack Thereof"},{"location":"graduate/dissertation_tips.html#depth","text":"Writing a good paper requires that you really understand the literature. You should read a lot and think a lot. See my comments on specialization. When you start reading about a subject, you will generate lots of ideas. Most of these are no good, but you won't be able to see this until you really understand the literature.","title":"Depth"},{"location":"graduate/dissertation_tips.html#defer-the-details","text":"I see a lot of students with half-baked ideas and fully worked out models. This is a waste of time. In most cases, don't write down a model until you can precisely state: What is the question? Why is it important? What is the approach? Why does the approach make sense? What is the potential punchline? To borrow from Lee Ohanian: How does your paper change the way I think about the world? How does it fit into the literature? This, by the way, makes a good template for an Introduction. You cannot know what ingredients your model needs to have, until you can answer these questions.","title":"Defer the Details"},{"location":"graduate/dissertation_tips.html#to-plan-or-not-to-plan","text":"Some people ask: \"what is your research agenda?\" Ideally one could answer: \"I want to understand this big picture question and here are the steps that will get me there ... At the end I should have the following papers ...\" If that works, great! It usually doesn't (take a look at Parente and Prescott Barriers to Riches for a great example where it did work). There are at least two reasons: Until you have actually done a step in the plan, you typically have no idea what will come out (especially if the work has any empirical content). But what comes next depends critically on what you found before. It is hard to come up with a good idea/question that can actually be done. It is darn hard to come up with a whole sequence of such ideas at a time. Therefore, be realistic and take project ideas one at a time. Think of each dissertation chapter as one publishable paper. Don't try to write a monolithic dissertation where one chapter leads cleanly to the next. It's perfectly fine if your chapters address different questions.","title":"To Plan or Not to Plan?"},{"location":"graduate/dissertation_tips.html#specialize","text":"At any cost, avoid working on several unrelated problems. To be successful, you must specialize. Each time you work on a new topic, you incur the large fixed cost of really, deeply understanding the literature. It is therefore essential to zero in on one or two areas and then stick to those for several years. If you do not follow this advice, you will encounter two problems: Your papers will lack depth. They may look superficially interesting, but experts will view your papers as missing the point. When you try to publish your work, you will have to convince referees that you should be taken seriously. They need to know that you have published in the same area before. Aim to associate your name with a topic. If you work in many different areas, nobody will know who you are. But if you persistently work in one area, people will hear your name and immediately think: \"he/she works on X.\" This is how your work is taken seriously and how to get impact. Disclaimer: I am sure there are reasonable people who vehemently disagree with my views on this.","title":"Specialize!"},{"location":"graduate/dissertation_tips.html#theory-vs-empirical-work","text":"Theory is glamorous and in many respects just more interesting and more fun to do than data work. If you doubt that, start reading the documentation for the PSID. Data work involves a lot of tedious steps and a lot of time during which essentially nothing is learned (except about the twisted minds of those who publish data sets). If you doubt that, start reading the documentation for the PSID. And yet, you should consider doing empirical work. For one simple reason: It may get you a job. There are loads of theorists coming out of top departments every year. The best of them get jobs. The others often have a hard time because the market for pure theory is not that large. Having an empirical project or at least a serious empirical part in your dissertation immensely increases the range of jobs you can apply for. There is unfortunately a big barrier standing between graduate students and data: Empirical work is hardly ever taught. The first time around, the startup investment required for using a data set is very large. If you doubt that, start reading the documentation for the PSID. Which is why many grad students never touch any data. But this obstacle can be overcome through persistence.","title":"Theory vs. Empirical Work"},{"location":"graduate/dissertation_tips.html#communicating-with-your-committee-members-cms","text":"Remember: your CMs don't think about your project all the time. They forget details between meetings. Therefore: Stay in touch regularly. Too many students show up with a completed paper that was written without any input from the CMs. They are then surprised when the CMs think that major revisions are needed. Have a short summary document ready. In particular, have a document with the model equations. Prepare for each meeting. Summarize your progress and the issues to be discussed in a short document. Documents should not be written in prose. Prose is a waste of time for the writer and for the reader. Use an outline format. Respond to comments. Do not just ignore them. Again, a short reply document is useful.","title":"Communicating with your committee members (CMs)"},{"location":"graduate/dissertation_tips.html#writing","text":"Early on, write out a plan for the paper It should address the items in the intro. Be clear about what results you may get and what the contribution would be. Until you can clearly state the potential contribution of the project, don't spend any time on it. Models are presented in a standard format: Describe demographics, preferences, endowments, technologies, market arrangements. State each agent's problem. Define an equilibrium. Only when all of this is done are you allowed to analyze the properties of the model. See also notes on writing .","title":"Writing"},{"location":"graduate/dissertation_tips.html#to-phd-or-not-to-phd","text":"Finally, a word for those who are considering whether or not to apply for a Ph.D. program: If you are not sure you want a Ph.D., do something else. The Ph.D. program is structured with a single outcome in mind: to place graduating students as faculty in Research I universities. The material learned is useful for only one purpose: for publishing research in academic journals. It is not useful for consulting, for working in businesses or the government (other than the Fed), or even for teaching. Therefore, if you are not sure you want to do academic research for the rest of your life, do not apply for Ph.D. programs in economics. An MA or an MBA always has a higher payoff and will save you years of frustration.","title":"To Ph.D. or not to Ph.D.?"},{"location":"graduate/field_papers.html","text":"{{../markdown_header.txt}} Field Papers in Macro/International \u00b6 A field paper should contain at least a critical literature review. Critical means: the review should identify potential avenues for future research. In many cases, students will have identified a potential topic by the time they start their field paper. Then it makes sense to keep the literature review short and focus on the initial steps of the proposed research. Each student should get his/her topic approved by a faculty member at the start. While field papers are eventually read by 2 faculty members, the \"field paper advisor\" will have an important say in the outcome. For 2016, the due date is September 9. FAQ \u00b6 You do not need an abstract.","title":"Field papers"},{"location":"graduate/field_papers.html#field-papers-in-macrointernational","text":"A field paper should contain at least a critical literature review. Critical means: the review should identify potential avenues for future research. In many cases, students will have identified a potential topic by the time they start their field paper. Then it makes sense to keep the literature review short and focus on the initial steps of the proposed research. Each student should get his/her topic approved by a faculty member at the start. While field papers are eventually read by 2 faculty members, the \"field paper advisor\" will have an important say in the outcome. For 2016, the due date is September 9.","title":"Field Papers in Macro/International"},{"location":"graduate/field_papers.html#faq","text":"You do not need an abstract.","title":"FAQ"},{"location":"graduate/graduate.html","text":"Graduate Teaching Notes \u00b6 Computational issues \u00b6 Spring 2016 Econ821 course on wealth distribution and computational methods (using Matlab). Matlab and Programming Using killdevil at UNC Notes on data sources Tips for using IPUMS data Dissertation tips \u00b6 Tips for dissertations, especially on finding topics Tips for writing Tips for presenting a paper Other \u00b6 Tips for first year PhD Students Notes on field papers in macro/international Exam tips","title":"Graduate notes"},{"location":"graduate/graduate.html#graduate-teaching-notes","text":"","title":"Graduate Teaching Notes"},{"location":"graduate/graduate.html#computational-issues","text":"Spring 2016 Econ821 course on wealth distribution and computational methods (using Matlab). Matlab and Programming Using killdevil at UNC Notes on data sources Tips for using IPUMS data","title":"Computational issues"},{"location":"graduate/graduate.html#dissertation-tips","text":"Tips for dissertations, especially on finding topics Tips for writing Tips for presenting a paper","title":"Dissertation tips"},{"location":"graduate/graduate.html#other","text":"Tips for first year PhD Students Notes on field papers in macro/international Exam tips","title":"Other"},{"location":"graduate/killdevil.html","text":"{{../markdown_header.txt}} Using HPCs at UNC \u00b6 Crashing jobs \u00b6 When jobs crash without explanation: * check whether over disc quota. Quota is 52GB in 2020. * the reason may be errors writing to files. This terminates a process without any info on the reason in the log. * Matlab ignores file writing errors. It just keeps running. The crash only occurs when file reads fails. Uploading Files \u00b6 Set up login via ssh keys. Then use rsync to upload and download files. Submitting Jobs \u00b6 Longleaf uses slurm Changing software versions \u00b6 module avail julia lists available versions. module add julia/1.4.1 adds a module temporarily. But need to module save to make it permanent. module rm removes a module module list lists currently installed ones. Matlab Issues \u00b6 It is easiest to replicate the local directory structure on killdevil . Then running files on the cluster just requires a change in the base directory that all other directories hang off. Write your code so that the data are placed in the right folder (different on unix cluster vs local machine). Write a matlab function that does the computations and can be called from the command line. Command syntax: bsub -n 8 -R \"span[hosts=1]\" matlab -nodisplay -nosplash -r \"run_batch_so1('fminsearch',1,1,7)\" -logfile set7.out -n 8 : requests 8 cores - the max matlab can handle run_batch_so1 is my command file in this example. Kure jobs crash regularly. It is important to make sure the optimization algorithm can hot-start (resume after a crash using a saved history). Saving files: Matlab cannot save large / complex files. It crashes. Only save the minimum optimization history needed to hot-start. When using parallel algorithms, make sure different instances do not try to read / write the same file at the same time. A simple semaphore approach is easily implemented (each instance locks the file it wants to access by writing a file, e.g. \"lock07_param.mat\" indicates that instance 7 has locked the file param.mat).","title":"Killdevil"},{"location":"graduate/killdevil.html#using-hpcs-at-unc","text":"","title":"Using HPCs at UNC"},{"location":"graduate/killdevil.html#crashing-jobs","text":"When jobs crash without explanation: * check whether over disc quota. Quota is 52GB in 2020. * the reason may be errors writing to files. This terminates a process without any info on the reason in the log. * Matlab ignores file writing errors. It just keeps running. The crash only occurs when file reads fails.","title":"Crashing jobs"},{"location":"graduate/killdevil.html#uploading-files","text":"Set up login via ssh keys. Then use rsync to upload and download files.","title":"Uploading Files"},{"location":"graduate/killdevil.html#submitting-jobs","text":"Longleaf uses slurm","title":"Submitting Jobs"},{"location":"graduate/killdevil.html#changing-software-versions","text":"module avail julia lists available versions. module add julia/1.4.1 adds a module temporarily. But need to module save to make it permanent. module rm removes a module module list lists currently installed ones.","title":"Changing software versions"},{"location":"graduate/killdevil.html#matlab-issues","text":"It is easiest to replicate the local directory structure on killdevil . Then running files on the cluster just requires a change in the base directory that all other directories hang off. Write your code so that the data are placed in the right folder (different on unix cluster vs local machine). Write a matlab function that does the computations and can be called from the command line. Command syntax: bsub -n 8 -R \"span[hosts=1]\" matlab -nodisplay -nosplash -r \"run_batch_so1('fminsearch',1,1,7)\" -logfile set7.out -n 8 : requests 8 cores - the max matlab can handle run_batch_so1 is my command file in this example. Kure jobs crash regularly. It is important to make sure the optimization algorithm can hot-start (resume after a crash using a saved history). Saving files: Matlab cannot save large / complex files. It crashes. Only save the minimum optimization history needed to hot-start. When using parallel algorithms, make sure different instances do not try to read / write the same file at the same time. A simple semaphore approach is easily implemented (each instance locks the file it wants to access by writing a file, e.g. \"lock07_param.mat\" indicates that instance 7 has locked the file param.mat).","title":"Matlab Issues"},{"location":"graduate/presentation_tips.html","text":"{{../markdown_header.txt}} Tips for Presenting a Paper \u00b6 Intro \u00b6 Clearly state: what is the question? (this should be one of your first slides) how is it approached? why is the approach reasonable? what are the findings? how does the paper change the way I think about economics? (due to Lee Ohanian). After the intro, people must have the paper's main message firmly in their minds. Slides \u00b6 Don't put too much on a slide. The Pat Kehoe test is useful: drop the slide on the floor; can you still read everything? Every slides must have a point. It must state its point clearly. You should have no more than 30 slides for a 90 minute presentation, unless there is very little on each slide.","title":"Presentation tips"},{"location":"graduate/presentation_tips.html#tips-for-presenting-a-paper","text":"","title":"Tips for Presenting a Paper"},{"location":"graduate/presentation_tips.html#intro","text":"Clearly state: what is the question? (this should be one of your first slides) how is it approached? why is the approach reasonable? what are the findings? how does the paper change the way I think about economics? (due to Lee Ohanian). After the intro, people must have the paper's main message firmly in their minds.","title":"Intro"},{"location":"graduate/presentation_tips.html#slides","text":"Don't put too much on a slide. The Pat Kehoe test is useful: drop the slide on the floor; can you still read everything? Every slides must have a point. It must state its point clearly. You should have no more than 30 slides for a 90 minute presentation, unless there is very little on each slide.","title":"Slides"},{"location":"graduate/writing_tips.html","text":"{{../markdown_header.txt}} Tips for Writing a Paper \u00b6 For some exceptionally well written papers, take a look at the work of Richard Rogerson. Structure of the presentation \u00b6 Introduction \u00b6 Your introduction should answer the following questions (due to Lee Ohanian): What is the question to be answered? Why is it important? (Often obvious) How is it approached? Why is the approach reasonable? What is the main result? How does the paper change the way I think about economics? What is the contribution? What is new relative to the literature? Literature review \u00b6 The literature review's goal is not to write a survey of the related literature. Instead, it clarifies your contribution relative to previous work. Presenting models \u00b6 Separate the presentation of what you do from the discussion of why you do it. Brief comments mixed in with the model presentation are ok. Long discussions make it hard to follow what you actually do. Separate the presentation of the model from the derivation of its implications. It is very confusing to read a paper that mixes assumptions with results. First present the model. Define equilibrium. Then derive properties of the equilibrium. There is a standard structure for presenting a model : Demographics Endowments Preferences Technologies Market arrangements Only once these have been stated is it acceptable to talk about equilibrium properties or agents' problems. Next, describe the agents' problems, and define an equilibrium. The process of writing \u00b6 Nice wording comes last \u00b6 First decide on what you want to write. Just write that down. Focus on structure. Ignore wording and formatting. Only when everything is in place does it make sense to worry about construcing nice sentences. When you write a section, ask yourself: what is the message of this section? And then write the answer to that question as the section's intro sentence. Do not mix levels of abstraction (a rule borrowed from programming). When you discuss high level arguments (e.g. in the Introduction), do not mix in details. Think of your document as a nested list or an outline. There should be a place (the Intro) where the reader can get the entire story (minus detail) on about one page. Then think of each section as elaborating the details of the overall argument. Ideally, the reader should be able to read the level 2 sections (skipping the level 3s) and get the entire argument again, just with a bit more detail. The level 3 sections then provide even more detail. Each such section should by itself make a self-contained point. PS: I wish there was a technology for actually writing papers as nested, collapsible lists. Why are we still writing (and formatting) documents as if they were printed and read on paper? Tips and tricks \u00b6 A little trick: When you are unsure about notation, define latex commands for the mathematical symbols. Example: \\newcommand{\\capShare}{\\alpha} . Then y = A k^\\capShare . Avoid literals in your text. Let your code write a latex preamble with statments like \\newcommand{\\meanWage}{7.53} . Then in the text: \"the mean wage in the sample is $\\meanWage\". That way, you don't have to manually update the numbers in the text. It's more robust. Tables \u00b6 Don't write tables by hand. Let your code write them. It's faster and it avoids mistakes. It is fairly easy to write basic Latex tables using code. I have Matlab code for this purpose in my github repo. Links \u00b6 Tips on Writing Economics Papers by R. Carter Hill (a collection of links) A Guide to Writing in Economics by P. Dudenhefer. Written for undergraduate writing, but also useful for PhD students. Writing Tips For Economics Research Papers by P. Nikilov.","title":"Writing tips"},{"location":"graduate/writing_tips.html#tips-for-writing-a-paper","text":"For some exceptionally well written papers, take a look at the work of Richard Rogerson.","title":"Tips for Writing a Paper"},{"location":"graduate/writing_tips.html#structure-of-the-presentation","text":"","title":"Structure of the presentation"},{"location":"graduate/writing_tips.html#introduction","text":"Your introduction should answer the following questions (due to Lee Ohanian): What is the question to be answered? Why is it important? (Often obvious) How is it approached? Why is the approach reasonable? What is the main result? How does the paper change the way I think about economics? What is the contribution? What is new relative to the literature?","title":"Introduction"},{"location":"graduate/writing_tips.html#literature-review","text":"The literature review's goal is not to write a survey of the related literature. Instead, it clarifies your contribution relative to previous work.","title":"Literature review"},{"location":"graduate/writing_tips.html#presenting-models","text":"Separate the presentation of what you do from the discussion of why you do it. Brief comments mixed in with the model presentation are ok. Long discussions make it hard to follow what you actually do. Separate the presentation of the model from the derivation of its implications. It is very confusing to read a paper that mixes assumptions with results. First present the model. Define equilibrium. Then derive properties of the equilibrium. There is a standard structure for presenting a model : Demographics Endowments Preferences Technologies Market arrangements Only once these have been stated is it acceptable to talk about equilibrium properties or agents' problems. Next, describe the agents' problems, and define an equilibrium.","title":"Presenting models"},{"location":"graduate/writing_tips.html#the-process-of-writing","text":"","title":"The process of writing"},{"location":"graduate/writing_tips.html#nice-wording-comes-last","text":"First decide on what you want to write. Just write that down. Focus on structure. Ignore wording and formatting. Only when everything is in place does it make sense to worry about construcing nice sentences. When you write a section, ask yourself: what is the message of this section? And then write the answer to that question as the section's intro sentence. Do not mix levels of abstraction (a rule borrowed from programming). When you discuss high level arguments (e.g. in the Introduction), do not mix in details. Think of your document as a nested list or an outline. There should be a place (the Intro) where the reader can get the entire story (minus detail) on about one page. Then think of each section as elaborating the details of the overall argument. Ideally, the reader should be able to read the level 2 sections (skipping the level 3s) and get the entire argument again, just with a bit more detail. The level 3 sections then provide even more detail. Each such section should by itself make a self-contained point. PS: I wish there was a technology for actually writing papers as nested, collapsible lists. Why are we still writing (and formatting) documents as if they were printed and read on paper?","title":"Nice wording comes last"},{"location":"graduate/writing_tips.html#tips-and-tricks","text":"A little trick: When you are unsure about notation, define latex commands for the mathematical symbols. Example: \\newcommand{\\capShare}{\\alpha} . Then y = A k^\\capShare . Avoid literals in your text. Let your code write a latex preamble with statments like \\newcommand{\\meanWage}{7.53} . Then in the text: \"the mean wage in the sample is $\\meanWage\". That way, you don't have to manually update the numbers in the text. It's more robust.","title":"Tips and tricks"},{"location":"graduate/writing_tips.html#tables","text":"Don't write tables by hand. Let your code write them. It's faster and it avoids mistakes. It is fairly easy to write basic Latex tables using code. I have Matlab code for this purpose in my github repo.","title":"Tables"},{"location":"graduate/writing_tips.html#links","text":"Tips on Writing Economics Papers by R. Carter Hill (a collection of links) A Guide to Writing in Economics by P. Dudenhefer. Written for undergraduate writing, but also useful for PhD students. Writing Tips For Economics Research Papers by P. Nikilov.","title":"Links"},{"location":"julia_notes/arrays.html","text":"Arrays \u00b6 EllipsisNotation.jl implements .. which stands for \"an arbitrary number of dimensions.\" Example: A[1:2, .., 3:4] . SplitApplyCombine.jl converts nested containers into flattened ones and vice versa. Also performs grouping operations. Tensorcast.jl handles matrix and vector operations such as: changing index order: @cast A[j, i] := B[i,j] functions over selected indices: @cast A[j,i] := B[i,j] + C[i] going from Matrix to Vector of Vector: @cast A[j][i] := B[i,j]","title":"Arrays"},{"location":"julia_notes/arrays.html#arrays","text":"EllipsisNotation.jl implements .. which stands for \"an arbitrary number of dimensions.\" Example: A[1:2, .., 3:4] . SplitApplyCombine.jl converts nested containers into flattened ones and vice versa. Also performs grouping operations. Tensorcast.jl handles matrix and vector operations such as: changing index order: @cast A[j, i] := B[i,j] functions over selected indices: @cast A[j,i] := B[i,j] + C[i] going from Matrix to Vector of Vector: @cast A[j][i] := B[i,j]","title":"Arrays"},{"location":"julia_notes/clusters.html","text":"Remote Clusters \u00b6 See also: The Ultimate Guide to Distributed Computing with a MWE. Preparation \u00b6 Get an account on the cluster, such as UNC's longleaf . Generate an ssh key , which allows you to log on without entering passwords. Try this out by logging into the cluster via ssh . At the terminal, enter ssh user@longleaf.unc.edu . Installing Julia on a Cluster \u00b6 This is for cases where one does not want to use the version that is installed for everyone (usually because it lags behind the current version). The command line installation instructions for linux produce a directory of the format julia-1.6.1 with a binary of bin/julia . All it then takes is to replace the generic julia -e with ~/julia-1.6.1/bin/julia -e in the command files called from slurm . Getting started with a test script \u00b6 How to get your code to run on a typical Linux cluster? Get started by writing a simple test script (Test3.jl) so we can test running from the command line. Make sure you can run the test script locally with julia \u201c/full/path/to/Test3.jl\u201d Now copy Test3.jl to a directory on the cluster and repeat the same. Once: make Julia available on the cluster with module add julia or module add julia/1.5.3 if you want a specific version. Then run julia \"/full/path/to/Test3.jl\" Now we know that things run on the cluster and it's time to submit a batch file: sbatch -p general -N 1 -J \"test_job\" -t 3-00 --mem 16384 -n 1 --mail-type=end --mail-user=lhendri@email.unc.edu -o \"test1.out\" --wrap=\"julia /full/path/to/Test3.jl\" Slurm \u00b6 Submitting jobs \u00b6 The usual way of submitting jobs consists of writing an sbatch file and then submitting it using the sbatch command. Steps: Copy your code and all of its dependencies to the cluster (see below). This is not needed when all dependencies are registered. Write a Julia script that contains the startup code for the project and then runs the actual computation (call this batch.jl ). Write a batch file that submits julia batch.jl as a job to the cluster's job scheduler. For UNC's longleaf cluster, this would be slurm. So you need to write job.sl that will be submitted using sbatch job.sl . Each line in the sbatch file looks like #SBATCH -o value . Options (indicated by -o) are: * -t 03-00 : time in days-hours * -N 1 : number of nodes * --mem 24576 : memory in megabytes (per cpu) Status of running jobs: \u00b6 squeue -u squeue --job XXXX sacct --format=\"JobID,JobName%30,State,ExitCode\" (best typed using KeyboardMaestro) Examining memory and cpu usage \u00b6 Yale guide After jobs completed: - seff jobid - sacct with MaxRSS switch shows memory usage. Errors \u00b6 From time to time, github asks for user credentials when trying to download private repos, even if those have been downloaded many times before. Then precompile the package from the REPL on the cluster, entering the credentials by hand. They will then be stored for some time again. The Julia script \u00b6 Submitting a job is (almost) equivalent to julia batch.jl from the terminal. Note: cd() does not work in these command files. To include a file, provide a full path. If you only use registered packages, life is easy. Your code would simply say: using Pkg # This needs to be done only once, but it does not hurt Pkg.add(MyPackage) # Make sure all required packages are downloaded Pkg.instantiate() MyPackage.run() If the code for MyPackage has been copied to the remote, then julia --project=\"/path/to/MyPackage\" --startup-file=no batch.jl activates MyPackage and runs batch.jl . The --project option is equivalent to Pkg.activate. Julia looks for batch.jl in the MyPackage directory. Disabling the startup-file prevents surprises where the startup-file changes the directory before looking for batch.jl. ~ is not expanded when relative paths are used. If MyPackage contains is unregistered or contains unregistered dependencies, things get more difficult. Now batch.jl must: Activate the package's environment. develop all unregistered dependencies. This replaces the invalid paths to directories on the local machine (e.g. /Users/lutz/julia/...) with the corresponding paths on the cluster (e.g. /nas/longleaf/...). Note: I verified that one cannot replace homedir() with ~ in Manifest.toml. using MyPackage MyPackage.run() Developing MyPackage in a blank folder does not work (for reasons I do not understand). It results in errors indicating that dependencies of MyPackage could not be found. This approach requires you to keep track of all unregistered dependencies and where they are located on the remote machine. My way of doing this is contained in PackageTools.jl in the shared repo (this is not a package b/c its very purpose is to facilitate loading of unregistered packages). But the easier way is to create a private registry and register all dependencies. File Transfer \u00b6 A reliable command line transfer option is rsync (on mac / linux). The command would be something like rsync -atuzv \"/someDirectory/sourceDir/\" \"username@longleaf.unc.edu:someDirectorySourceDir\" Notes: The source dir should end in \u201c/\u201d; the target dir should not. Exluding .git speeds up the transfer. --delete ensures that no old files remain on the server. This will use ssh for authentication if it is set up. An alternative is to use git . To transfer an individual file: run( scp $filename hostname:/path/to/newfile.txt')`.","title":"Clusters"},{"location":"julia_notes/clusters.html#remote-clusters","text":"See also: The Ultimate Guide to Distributed Computing with a MWE.","title":"Remote Clusters"},{"location":"julia_notes/clusters.html#preparation","text":"Get an account on the cluster, such as UNC's longleaf . Generate an ssh key , which allows you to log on without entering passwords. Try this out by logging into the cluster via ssh . At the terminal, enter ssh user@longleaf.unc.edu .","title":"Preparation"},{"location":"julia_notes/clusters.html#installing-julia-on-a-cluster","text":"This is for cases where one does not want to use the version that is installed for everyone (usually because it lags behind the current version). The command line installation instructions for linux produce a directory of the format julia-1.6.1 with a binary of bin/julia . All it then takes is to replace the generic julia -e with ~/julia-1.6.1/bin/julia -e in the command files called from slurm .","title":"Installing Julia on a Cluster"},{"location":"julia_notes/clusters.html#getting-started-with-a-test-script","text":"How to get your code to run on a typical Linux cluster? Get started by writing a simple test script (Test3.jl) so we can test running from the command line. Make sure you can run the test script locally with julia \u201c/full/path/to/Test3.jl\u201d Now copy Test3.jl to a directory on the cluster and repeat the same. Once: make Julia available on the cluster with module add julia or module add julia/1.5.3 if you want a specific version. Then run julia \"/full/path/to/Test3.jl\" Now we know that things run on the cluster and it's time to submit a batch file: sbatch -p general -N 1 -J \"test_job\" -t 3-00 --mem 16384 -n 1 --mail-type=end --mail-user=lhendri@email.unc.edu -o \"test1.out\" --wrap=\"julia /full/path/to/Test3.jl\"","title":"Getting started with a test script"},{"location":"julia_notes/clusters.html#slurm","text":"","title":"Slurm"},{"location":"julia_notes/clusters.html#submitting-jobs","text":"The usual way of submitting jobs consists of writing an sbatch file and then submitting it using the sbatch command. Steps: Copy your code and all of its dependencies to the cluster (see below). This is not needed when all dependencies are registered. Write a Julia script that contains the startup code for the project and then runs the actual computation (call this batch.jl ). Write a batch file that submits julia batch.jl as a job to the cluster's job scheduler. For UNC's longleaf cluster, this would be slurm. So you need to write job.sl that will be submitted using sbatch job.sl . Each line in the sbatch file looks like #SBATCH -o value . Options (indicated by -o) are: * -t 03-00 : time in days-hours * -N 1 : number of nodes * --mem 24576 : memory in megabytes (per cpu)","title":"Submitting jobs"},{"location":"julia_notes/clusters.html#status-of-running-jobs","text":"squeue -u squeue --job XXXX sacct --format=\"JobID,JobName%30,State,ExitCode\" (best typed using KeyboardMaestro)","title":"Status of running jobs:"},{"location":"julia_notes/clusters.html#examining-memory-and-cpu-usage","text":"Yale guide After jobs completed: - seff jobid - sacct with MaxRSS switch shows memory usage.","title":"Examining memory and cpu usage"},{"location":"julia_notes/clusters.html#errors","text":"From time to time, github asks for user credentials when trying to download private repos, even if those have been downloaded many times before. Then precompile the package from the REPL on the cluster, entering the credentials by hand. They will then be stored for some time again.","title":"Errors"},{"location":"julia_notes/clusters.html#the-julia-script","text":"Submitting a job is (almost) equivalent to julia batch.jl from the terminal. Note: cd() does not work in these command files. To include a file, provide a full path. If you only use registered packages, life is easy. Your code would simply say: using Pkg # This needs to be done only once, but it does not hurt Pkg.add(MyPackage) # Make sure all required packages are downloaded Pkg.instantiate() MyPackage.run() If the code for MyPackage has been copied to the remote, then julia --project=\"/path/to/MyPackage\" --startup-file=no batch.jl activates MyPackage and runs batch.jl . The --project option is equivalent to Pkg.activate. Julia looks for batch.jl in the MyPackage directory. Disabling the startup-file prevents surprises where the startup-file changes the directory before looking for batch.jl. ~ is not expanded when relative paths are used. If MyPackage contains is unregistered or contains unregistered dependencies, things get more difficult. Now batch.jl must: Activate the package's environment. develop all unregistered dependencies. This replaces the invalid paths to directories on the local machine (e.g. /Users/lutz/julia/...) with the corresponding paths on the cluster (e.g. /nas/longleaf/...). Note: I verified that one cannot replace homedir() with ~ in Manifest.toml. using MyPackage MyPackage.run() Developing MyPackage in a blank folder does not work (for reasons I do not understand). It results in errors indicating that dependencies of MyPackage could not be found. This approach requires you to keep track of all unregistered dependencies and where they are located on the remote machine. My way of doing this is contained in PackageTools.jl in the shared repo (this is not a package b/c its very purpose is to facilitate loading of unregistered packages). But the easier way is to create a private registry and register all dependencies.","title":"The Julia script"},{"location":"julia_notes/clusters.html#file-transfer","text":"A reliable command line transfer option is rsync (on mac / linux). The command would be something like rsync -atuzv \"/someDirectory/sourceDir/\" \"username@longleaf.unc.edu:someDirectorySourceDir\" Notes: The source dir should end in \u201c/\u201d; the target dir should not. Exluding .git speeds up the transfer. --delete ensures that no old files remain on the server. This will use ssh for authentication if it is set up. An alternative is to use git . To transfer an individual file: run( scp $filename hostname:/path/to/newfile.txt')`.","title":"File Transfer"},{"location":"julia_notes/data_handling.html","text":"Data Handling \u00b6 Useful packages: DataSkimmer.jl produces a summary of tabular data (e.g. DataFrames ), including histogram.","title":"Data Handling"},{"location":"julia_notes/data_handling.html#data-handling","text":"Useful packages: DataSkimmer.jl produces a summary of tabular data (e.g. DataFrames ), including histogram.","title":"Data Handling"},{"location":"julia_notes/debugging.html","text":"Debugging \u00b6 Discourse thread on debugging A useful tutorial The Upshot \u00b6 This is a point of contention in the Julia ecosystem. Many users think the lack of a \"good\" debugger is the main drawback that prevents them from using Julia. One common answer is: Yeah, debugging is kind of lousy at this point. Just write your code so you don't need a debugger much. This is pretty much what I do and I find that I don't miss the debugger much at all. Roughly, I work as follows. Where possible, I break code into lots of small functions. This is probably anyway a good idea (see Martin's famous \"Clean Code\" book). Then I write tests for the small functions. When I develop custom types, I write test setup functions that make instances of the types that can be used for testing. The test functions are placed into self-contained files that can be include d from the REPL. When something goes wrong, it is easy to inspect it there. See testing . When something goes wrong in the integrated code that was not found during tests, I start to sprinkle @assert s into the code. If the code is not performance sensitive (95% of what I write), the @assert s are never removed, even when the bug is fixed. This gets me closer to the source of the error. In the vast majority of the cases, this process identifies errors without ever using a debugger. If this fails, Infiltrator.jl and Exfiltrator.jl are helpful. They are a bit like Matlab s keyboard statements, but less powerful. The code essentially stops at a breakpoint. The user can inspect the state of the system, but cannot move around the call stack. But that's usually OK because the steps taken before invoking the debugger have gotten me close to the origin of the problem. The Options \u00b6 Julia offers several debugger options that work in very different ways. The main trade-off is compile time versus run time . Debuggers that run interpreted code, such as Debugger.jl, compile reasonably fast but run very slowly (about 10 times slower than compiled code). Debuggers that compile debugging features into the code run at near native speed but are either slow to compile (MagneticReadHead) or offer limited features (Infiltrator). Common options are: Debugger.jl: It interprets all code and can therefore offer a complete feature set. But it is very slow for larger projects. Options are available that make Debugger faster, but less powerful. The VS Code plugin gives an IDE experience. MagneticReadHead.jl: It compiles debugging features into all code and therefore runs at near native speed. But compile times are often extremely long. Infiltrator.jl: It compiles all code, adding only user specified breakpoints (@infiltrate). Compile times and run times are good, but the user can only inspect the local state when a break point is reached. It is not possible to move around the call stack. Exfiltrator.jl: Simply exports all local variables at the point of call to Main. The idea is that the entire local environment can be inspected at really no runtime or compilation cost. Simple and effective, but one cannot manipulate objects in the context of the calling module. There are other options that I don't know much about, such as Juno's debugger. Stacktraces \u00b6 Stacktraces can be long. InteractiveErrors.jl can make them easier to navigate.","title":"Debugging"},{"location":"julia_notes/debugging.html#debugging","text":"Discourse thread on debugging A useful tutorial","title":"Debugging"},{"location":"julia_notes/debugging.html#the-upshot","text":"This is a point of contention in the Julia ecosystem. Many users think the lack of a \"good\" debugger is the main drawback that prevents them from using Julia. One common answer is: Yeah, debugging is kind of lousy at this point. Just write your code so you don't need a debugger much. This is pretty much what I do and I find that I don't miss the debugger much at all. Roughly, I work as follows. Where possible, I break code into lots of small functions. This is probably anyway a good idea (see Martin's famous \"Clean Code\" book). Then I write tests for the small functions. When I develop custom types, I write test setup functions that make instances of the types that can be used for testing. The test functions are placed into self-contained files that can be include d from the REPL. When something goes wrong, it is easy to inspect it there. See testing . When something goes wrong in the integrated code that was not found during tests, I start to sprinkle @assert s into the code. If the code is not performance sensitive (95% of what I write), the @assert s are never removed, even when the bug is fixed. This gets me closer to the source of the error. In the vast majority of the cases, this process identifies errors without ever using a debugger. If this fails, Infiltrator.jl and Exfiltrator.jl are helpful. They are a bit like Matlab s keyboard statements, but less powerful. The code essentially stops at a breakpoint. The user can inspect the state of the system, but cannot move around the call stack. But that's usually OK because the steps taken before invoking the debugger have gotten me close to the origin of the problem.","title":"The Upshot"},{"location":"julia_notes/debugging.html#the-options","text":"Julia offers several debugger options that work in very different ways. The main trade-off is compile time versus run time . Debuggers that run interpreted code, such as Debugger.jl, compile reasonably fast but run very slowly (about 10 times slower than compiled code). Debuggers that compile debugging features into the code run at near native speed but are either slow to compile (MagneticReadHead) or offer limited features (Infiltrator). Common options are: Debugger.jl: It interprets all code and can therefore offer a complete feature set. But it is very slow for larger projects. Options are available that make Debugger faster, but less powerful. The VS Code plugin gives an IDE experience. MagneticReadHead.jl: It compiles debugging features into all code and therefore runs at near native speed. But compile times are often extremely long. Infiltrator.jl: It compiles all code, adding only user specified breakpoints (@infiltrate). Compile times and run times are good, but the user can only inspect the local state when a break point is reached. It is not possible to move around the call stack. Exfiltrator.jl: Simply exports all local variables at the point of call to Main. The idea is that the entire local environment can be inspected at really no runtime or compilation cost. Simple and effective, but one cannot manipulate objects in the context of the calling module. There are other options that I don't know much about, such as Juno's debugger.","title":"The Options"},{"location":"julia_notes/debugging.html#stacktraces","text":"Stacktraces can be long. InteractiveErrors.jl can make them easier to navigate.","title":"Stacktraces"},{"location":"julia_notes/documentation.html","text":"Documentation \u00b6 DocStringExtensions.jl makes it easier to write docs. In particular, function signatures are automatically created in docstrings. Literate.jl is useful for generating examples. A useful guide to writing documentation (pointed out by Tim Holy on Discourse). Useful for making tutorials: Discourse thread 2021 Documenter.jl \u00b6 Documenter.jl is the most commonly used package to write documentation. Documentation specific dependencies are in ./docs/Project.toml . In my case, this contains FilesLH for deploying the docs. Then ./docs/make.jl needs to be called when the docs environment is active. Easiest: add Pkg.activate(\"./docs\") at the start of make.jl and Pkg.activate(\".\") at the end. It is then not necessary to have Documenter.jl as a dependency of the package. Deploying (1.5) \u00b6 The standard approach is TravisCI. Since I have private repos and a private package registry, I prefer \u201cmanual\u201d hosting on my own website. I run the docs/make.jl documenation build script as usual, but replace deploydocs with FilesLH.deploy_docs . This simply rsyncs the static html files generated by Documenter.jl to my personal website. See also Deploy Documenter docs locally .","title":"Documentation"},{"location":"julia_notes/documentation.html#documentation","text":"DocStringExtensions.jl makes it easier to write docs. In particular, function signatures are automatically created in docstrings. Literate.jl is useful for generating examples. A useful guide to writing documentation (pointed out by Tim Holy on Discourse). Useful for making tutorials: Discourse thread 2021","title":"Documentation"},{"location":"julia_notes/documentation.html#documenterjl","text":"Documenter.jl is the most commonly used package to write documentation. Documentation specific dependencies are in ./docs/Project.toml . In my case, this contains FilesLH for deploying the docs. Then ./docs/make.jl needs to be called when the docs environment is active. Easiest: add Pkg.activate(\"./docs\") at the start of make.jl and Pkg.activate(\".\") at the end. It is then not necessary to have Documenter.jl as a dependency of the package.","title":"Documenter.jl"},{"location":"julia_notes/documentation.html#deploying-15","text":"The standard approach is TravisCI. Since I have private repos and a private package registry, I prefer \u201cmanual\u201d hosting on my own website. I run the docs/make.jl documenation build script as usual, but replace deploydocs with FilesLH.deploy_docs . This simply rsyncs the static html files generated by Documenter.jl to my personal website. See also Deploy Documenter docs locally .","title":"Deploying (1.5)"},{"location":"julia_notes/functions.html","text":"Functions and Methods \u00b6 Default arguments \u00b6 Given a function that accepts keyword arguments: function foo1 ( x ; a = 1 , b = 2 , c = 3 , d = 4 ) @show a , b , c , d end Setting default arguments can be done with a NamedTuple : default_args = ( : b => 22 , : d => 44 ); foo1 ( 1 ; default_args ... , b = 33 ) # Result: (a, b, c, d) = (1, 22, 3, 44) # But this loses the non-default value of `b`: foo1 ( 1 ; b = 33 , default_args ... ) One can set default arguments inside the function as a NamedTuple and merge: function foo (; kwargs ... ) # Note that `x = 17` works as well as `:x => 17` defaults = ( x = 17 , ); args = merge ( defaults , kwargs ); println ( args [ : x ]) # Or call another function `bar(; args...)` end The next obvious step would be to define foo_defaults() = (x = 17, ) .","title":"Functions"},{"location":"julia_notes/functions.html#functions-and-methods","text":"","title":"Functions and Methods"},{"location":"julia_notes/functions.html#default-arguments","text":"Given a function that accepts keyword arguments: function foo1 ( x ; a = 1 , b = 2 , c = 3 , d = 4 ) @show a , b , c , d end Setting default arguments can be done with a NamedTuple : default_args = ( : b => 22 , : d => 44 ); foo1 ( 1 ; default_args ... , b = 33 ) # Result: (a, b, c, d) = (1, 22, 3, 44) # But this loses the non-default value of `b`: foo1 ( 1 ; b = 33 , default_args ... ) One can set default arguments inside the function as a NamedTuple and merge: function foo (; kwargs ... ) # Note that `x = 17` works as well as `:x => 17` defaults = ( x = 17 , ); args = merge ( defaults , kwargs ); println ( args [ : x ]) # Or call another function `bar(; args...)` end The next obvious step would be to define foo_defaults() = (x = 17, ) .","title":"Default arguments"},{"location":"julia_notes/git.html","text":"Notes on git \u00b6","title":"Git"},{"location":"julia_notes/git.html#notes-on-git","text":"","title":"Notes on git"},{"location":"julia_notes/installation.html","text":"Installation \u00b6 My Setup \u00b6 My current setup is Julia 1.5 run from the terminal and Visual Studio Code as editor (augmented with BBEdit to overcome VsCode's shortcomings in multi-file search and replace). My startup file loads the packages OhMyREPL and the. Revise comes after packages from the standard libraries, so it does not track changes to those. It appears that the default editor is determined by the system wide file association. No need to set the JULIA_EDITOR environment variable. Updating to a new version \u00b6 After starting the new version, basic packages need to be added so the startup code can be run (e.g., OhMyREPL ). In my case these are: ]add OhMyREPL Revise The bash profile needs to be updated to point to the new version. Alternatively, create a symlink for the new version with rm /usr/local/bin/julia ln -s /Applications/Julia-1.5.app/Contents/Resources/julia/bin/julia /usr/local/bin/julia The Jill bash script automates this process. Perhaps even better, though requiring python is jill.py . A simple jill install stable is all it takes. There is no need to copy installed packages to the new version's subdirectory. They are downloaded again as needed. Customizing the REPL \u00b6 On MacOS, meta-X means Esc-X. There does not seem to be a way of binding Alt-x. Customizing key bindings is somewhat tricky. One has to edit startup.jl to define a function that modifies the key map. I have not been able to assign Ctrl-H and similar. Perhaps iterm intercepts them, but they always arrive as control sequences. Invisible lines in stacktraces (1.6): This happens for various colorschemes. In iTerm , set the minimum contrast slider to make those lines visible. VS Code \u00b6 Set the Julia executable path to /usr/local/bin/julia (the symlink created above). A bash script that links an external terminal REPL to the Julia VSCode extension. Troubleshooting \u00b6 When problems with package operations occur, it often helps to reinstall the main registry: pkg> registry rm General Julia will automatically redownload the general registry when needed. Clearing out the package cache may also help.","title":"Installation"},{"location":"julia_notes/installation.html#installation","text":"","title":"Installation"},{"location":"julia_notes/installation.html#my-setup","text":"My current setup is Julia 1.5 run from the terminal and Visual Studio Code as editor (augmented with BBEdit to overcome VsCode's shortcomings in multi-file search and replace). My startup file loads the packages OhMyREPL and the. Revise comes after packages from the standard libraries, so it does not track changes to those. It appears that the default editor is determined by the system wide file association. No need to set the JULIA_EDITOR environment variable.","title":"My Setup"},{"location":"julia_notes/installation.html#updating-to-a-new-version","text":"After starting the new version, basic packages need to be added so the startup code can be run (e.g., OhMyREPL ). In my case these are: ]add OhMyREPL Revise The bash profile needs to be updated to point to the new version. Alternatively, create a symlink for the new version with rm /usr/local/bin/julia ln -s /Applications/Julia-1.5.app/Contents/Resources/julia/bin/julia /usr/local/bin/julia The Jill bash script automates this process. Perhaps even better, though requiring python is jill.py . A simple jill install stable is all it takes. There is no need to copy installed packages to the new version's subdirectory. They are downloaded again as needed.","title":"Updating to a new version"},{"location":"julia_notes/installation.html#customizing-the-repl","text":"On MacOS, meta-X means Esc-X. There does not seem to be a way of binding Alt-x. Customizing key bindings is somewhat tricky. One has to edit startup.jl to define a function that modifies the key map. I have not been able to assign Ctrl-H and similar. Perhaps iterm intercepts them, but they always arrive as control sequences. Invisible lines in stacktraces (1.6): This happens for various colorschemes. In iTerm , set the minimum contrast slider to make those lines visible.","title":"Customizing the REPL"},{"location":"julia_notes/installation.html#vs-code","text":"Set the Julia executable path to /usr/local/bin/julia (the symlink created above). A bash script that links an external terminal REPL to the Julia VSCode extension.","title":"VS Code"},{"location":"julia_notes/installation.html#troubleshooting","text":"When problems with package operations occur, it often helps to reinstall the main registry: pkg> registry rm General Julia will automatically redownload the general registry when needed. Clearing out the package cache may also help.","title":"Troubleshooting"},{"location":"julia_notes/intro.html","text":"Notes on the Julia Language \u00b6 This document collects what I have learned about the Julia language. Its main purpose is to document tips and tricks that are not covered in the official documentation. Much of what is collected here is really just that: collected from other sources, which I try to cite where appropriate. Some of the material is a synthesis of material taken from various Discourse threads. In these cases, I may not always recall where I learned something. Apologies to Discourse contributors who I should perhaps have cited, but whose contributions I failed to recall. I will be happy to add citations if omissions are pointed out to me. Note: Earlier notes in pdf format Useful References and Tutorials \u00b6 QuantEcon : Lectures and code in Julia and Python. Courses using Julia: Julia in the classroom Jesus Fernandez-Villaverde : Course notes on scientific computing. Books: Statistics with Julia Introduction to Quantitative Macroeconomics Using Julia","title":"Introduction"},{"location":"julia_notes/intro.html#notes-on-the-julia-language","text":"This document collects what I have learned about the Julia language. Its main purpose is to document tips and tricks that are not covered in the official documentation. Much of what is collected here is really just that: collected from other sources, which I try to cite where appropriate. Some of the material is a synthesis of material taken from various Discourse threads. In these cases, I may not always recall where I learned something. Apologies to Discourse contributors who I should perhaps have cited, but whose contributions I failed to recall. I will be happy to add citations if omissions are pointed out to me. Note: Earlier notes in pdf format","title":"Notes on the Julia Language"},{"location":"julia_notes/intro.html#useful-references-and-tutorials","text":"QuantEcon : Lectures and code in Julia and Python. Courses using Julia: Julia in the classroom Jesus Fernandez-Villaverde : Course notes on scientific computing. Books: Statistics with Julia Introduction to Quantitative Macroeconomics Using Julia","title":"Useful References and Tutorials"},{"location":"julia_notes/jupyter.html","text":"Jupyter \u00b6 Jupyter creates or runs notebooks that combine code, output, and text. using IJulia jupyterlab () # or notebook () An IDE for editing notebooks is JupyterLab . On my machine, connecting to the kernel is flaky.","title":"Jupyter"},{"location":"julia_notes/jupyter.html#jupyter","text":"Jupyter creates or runs notebooks that combine code, output, and text. using IJulia jupyterlab () # or notebook () An IDE for editing notebooks is JupyterLab . On my machine, connecting to the kernel is flaky.","title":"Jupyter"},{"location":"julia_notes/miscellaneous.html","text":"Miscellaneous \u00b6 Good advice on miscellaneous topics: Julia Antipatterns Artifacts (1.6) \u00b6 A useful guide: Artifacts for Dummies Dates (1.6) \u00b6 Working with time durations seems to require converting the durations to millisecond integers first: d1 = DateTime ( 2021 , 9 , 10 , 9 ); d2 = d1 + Minute ( 3 ) + Second ( 5 ); dSeconds = Dates . value ( d2 - d1 ) / 1000 ; Going back to time units requires rounding because Minute(dSeconds) throws an InexactError . dMinutes = Minute ( round ( dSeconds / 60 )); There is no formatted display of durations, only of dates: Dates . format ( d1 , \"HH:MM\" ); Enum (1.6) \u00b6 @enum Fruit apple = 1 orange = 2 kiwi = 3 The type is Fruit (concrete). So dispatch on the instances does not work. The alternative: Defint an abstract type with concrete subtypes Apple <: AbstractFruit . Benefits of enum : Array{Fruit} is more efficient than Array{AbstractFruit} . Benefits of types: Static dispatch. Can be extended. Hashing \u00b6 For new DataType s, it is necessary to defined hash , == , and isequal . hash is needed for containers such as Dict s (it is used for haskey ). The way this is done can be based on AutoHashEquals.jl : mutable struct Foo a :: Int b end Base . hash ( a :: Foo , h :: UInt ) = hash ( a . b , hash ( a . a , hash ( : Foo , h ))) Interpolation (1.6) \u00b6 Interpolations.jl \u00b6 An example from QuantEcon . One limitation: multi-dimensional interpolation only works with unform grids. The inputs must be ranges. The default for extrapolation is to throw an error. Example: xV = 1 : 10 ; yV = 5 : 10 ; zM = xV .+ yV ' .+ xV .* yV ' ; itp = CubicInterpolation (( xV , yV ), zM ); itp ( 1.5 , 5.9 ) The same (?) interpolation can be constructed the long way round: itp2 = interpolate ( zM , BSpline ( Cubic ( Line ( OnGrid ())))); sitp = scale ( itp2 , xV , yV ); One difference is that bounds works on sitp but not on itp . Latex Output (1.6) \u00b6 Latexify.jl renders various expressions as Latex equations. This is useful for automatically making expressions for functional forms. Also generates Latex tables from DataFrames and Arrays . Logging (1.6) \u00b6 @debug can be used to generate self-test code that is only run while developing the code. Example: # test1.jl a = 1 ; b = [ 1 , 2 , 3 ]; @debug begin bSum = sum ( b ); \"\"\" Debug message $bsum \"\"\" end @debug \"Debug with args:\" a , b To run this with the @debug statements enabled, issue (in the shell): export JULIA_DEBUG = all julia \"test1.jl\" But this generates lots of debug messages that sit in Base . To avoid this, export JULIA_DEBUG=MyPkg . Enabling logging levels temporarily: lg = ConsoleLogger ( stderr , Logging . Debug ); with_logger ( lg ) do foo (); end Or: lg = ConsoleLogger ( stderr , Logging . Debug ); old_logger = global_logger ( lg ); foo (); global_logger ( old_logger ); Random numbers (1.5) \u00b6 Generating reproducible random numbers across Julia versions can be done with StableRNGs.jl . This also seems to generate the same random numbers across operating systems (in my case MacOS and Linux). Traits \u00b6 An interesting implementation is WhereTraits.jl which permits, for example, dispatch on functions that return Bool .","title":"Miscellaneous"},{"location":"julia_notes/miscellaneous.html#miscellaneous","text":"Good advice on miscellaneous topics: Julia Antipatterns","title":"Miscellaneous"},{"location":"julia_notes/miscellaneous.html#artifacts-16","text":"A useful guide: Artifacts for Dummies","title":"Artifacts (1.6)"},{"location":"julia_notes/miscellaneous.html#dates-16","text":"Working with time durations seems to require converting the durations to millisecond integers first: d1 = DateTime ( 2021 , 9 , 10 , 9 ); d2 = d1 + Minute ( 3 ) + Second ( 5 ); dSeconds = Dates . value ( d2 - d1 ) / 1000 ; Going back to time units requires rounding because Minute(dSeconds) throws an InexactError . dMinutes = Minute ( round ( dSeconds / 60 )); There is no formatted display of durations, only of dates: Dates . format ( d1 , \"HH:MM\" );","title":"Dates (1.6)"},{"location":"julia_notes/miscellaneous.html#enum-16","text":"@enum Fruit apple = 1 orange = 2 kiwi = 3 The type is Fruit (concrete). So dispatch on the instances does not work. The alternative: Defint an abstract type with concrete subtypes Apple <: AbstractFruit . Benefits of enum : Array{Fruit} is more efficient than Array{AbstractFruit} . Benefits of types: Static dispatch. Can be extended.","title":"Enum (1.6)"},{"location":"julia_notes/miscellaneous.html#hashing","text":"For new DataType s, it is necessary to defined hash , == , and isequal . hash is needed for containers such as Dict s (it is used for haskey ). The way this is done can be based on AutoHashEquals.jl : mutable struct Foo a :: Int b end Base . hash ( a :: Foo , h :: UInt ) = hash ( a . b , hash ( a . a , hash ( : Foo , h )))","title":"Hashing"},{"location":"julia_notes/miscellaneous.html#interpolation-16","text":"","title":"Interpolation (1.6)"},{"location":"julia_notes/miscellaneous.html#interpolationsjl","text":"An example from QuantEcon . One limitation: multi-dimensional interpolation only works with unform grids. The inputs must be ranges. The default for extrapolation is to throw an error. Example: xV = 1 : 10 ; yV = 5 : 10 ; zM = xV .+ yV ' .+ xV .* yV ' ; itp = CubicInterpolation (( xV , yV ), zM ); itp ( 1.5 , 5.9 ) The same (?) interpolation can be constructed the long way round: itp2 = interpolate ( zM , BSpline ( Cubic ( Line ( OnGrid ())))); sitp = scale ( itp2 , xV , yV ); One difference is that bounds works on sitp but not on itp .","title":"Interpolations.jl"},{"location":"julia_notes/miscellaneous.html#latex-output-16","text":"Latexify.jl renders various expressions as Latex equations. This is useful for automatically making expressions for functional forms. Also generates Latex tables from DataFrames and Arrays .","title":"Latex Output (1.6)"},{"location":"julia_notes/miscellaneous.html#logging-16","text":"@debug can be used to generate self-test code that is only run while developing the code. Example: # test1.jl a = 1 ; b = [ 1 , 2 , 3 ]; @debug begin bSum = sum ( b ); \"\"\" Debug message $bsum \"\"\" end @debug \"Debug with args:\" a , b To run this with the @debug statements enabled, issue (in the shell): export JULIA_DEBUG = all julia \"test1.jl\" But this generates lots of debug messages that sit in Base . To avoid this, export JULIA_DEBUG=MyPkg . Enabling logging levels temporarily: lg = ConsoleLogger ( stderr , Logging . Debug ); with_logger ( lg ) do foo (); end Or: lg = ConsoleLogger ( stderr , Logging . Debug ); old_logger = global_logger ( lg ); foo (); global_logger ( old_logger );","title":"Logging (1.6)"},{"location":"julia_notes/miscellaneous.html#random-numbers-15","text":"Generating reproducible random numbers across Julia versions can be done with StableRNGs.jl . This also seems to generate the same random numbers across operating systems (in my case MacOS and Linux).","title":"Random numbers (1.5)"},{"location":"julia_notes/miscellaneous.html#traits","text":"An interesting implementation is WhereTraits.jl which permits, for example, dispatch on functions that return Bool .","title":"Traits"},{"location":"julia_notes/optimization.html","text":"Numerical Optimization \u00b6 NLopt (1.2) \u00b6 Objective function requires gradient as input, even if it is not used. If gradient is not provided, NLopt returns FORCED_STOP without error message. When objective function errors, return value is STOPVAL_REACHED and fVal=0.0. One way of diagnosing such errors: print the guess to stdout at the start of each iteration. Then the objective function can be run again from the REPL with the guesses that cause the crash. An alternative (suggested by Kristoffer Carlsson): wrap the entire objective function in try/catch. Report the error in the catch and then rethrow it. Noisy objectives \u00b6 Useful discourse threads: here SPSA : according to the author: specifically made for simulation type problems basic idea seems to approximate derivatives, but instead of perturbing each parameter one-by-one (expensive), all are perturbed in the same step. extremely easy to implement can vary the distribution of step sizes (main algorithm uses step sizes 1 or 2 times a c( k ) ). COBYLA implemented in NLopt COBYLA uses a linear approximation of the function Subplex implemented in NLopt Sbplx similar to Nelder-Mead, but claims to be more robust Bayesian optimization Global algorithms \u00b6 QuadDIRECT combines ideas of DIRECT with local search points from local search are used to form boxes for the global search NODAL global optimization algorithms that can run in parallel possibly abandoned Controlled Random Search \u00b6 implemented as NLopt CRS starts from a random population of points (default size 10(n+1) ) user can control the size of the initial population, but there are no warm starts. then evolves these using heuristic rules. Described as \"randomized Nelder-Mead\". MLSL \u00b6 implemented as NLopt MLSL basic idea: multistart a local solver, avoiding resolving points that are close to each other TikTak \u00b6 Arnoud, Antoine, Fatih Guvenen, and Tatjana Kleineberg. 2019. \u201cBenchmarking Global Optimizers.\u201d Working Paper 26340. National Bureau of Economic Research. https://doi.org/10.3386/w26340. A multistart algorithm that generates new starting points as convex combinations of the current best point and Sobol points. BlackBoxOptim \u00b6 implements SPSA currently little documentation (2020-May) There is an example of distributed parallel optimization. Not clear whether multi-threaded works as well. Not clear whether / how optimization history can be saved. Surrogate Optimization \u00b6 Basic idea: Sample a small number of points. Evaluate the objective. Fit a surrogate function to those points. Optimize this function, which is cheap to evaluate, using an algorithm that explores the global parameter space downweights points that are far from points where the true objective has been evaluated Add the optimum of the surrogate to the list of evaluated points (using the true function value). Update the surrogate model based on the new point. Repeat. Packages: Surrogates.jl : a variety of algorithms and sampling methods. SurrogateModelOptim.jl Drawback: There is no good way of running the surrogate optimization in parallel (unlike Matlab).","title":"Optimization"},{"location":"julia_notes/optimization.html#numerical-optimization","text":"","title":"Numerical Optimization"},{"location":"julia_notes/optimization.html#nlopt-12","text":"Objective function requires gradient as input, even if it is not used. If gradient is not provided, NLopt returns FORCED_STOP without error message. When objective function errors, return value is STOPVAL_REACHED and fVal=0.0. One way of diagnosing such errors: print the guess to stdout at the start of each iteration. Then the objective function can be run again from the REPL with the guesses that cause the crash. An alternative (suggested by Kristoffer Carlsson): wrap the entire objective function in try/catch. Report the error in the catch and then rethrow it.","title":"NLopt (1.2)"},{"location":"julia_notes/optimization.html#noisy-objectives","text":"Useful discourse threads: here SPSA : according to the author: specifically made for simulation type problems basic idea seems to approximate derivatives, but instead of perturbing each parameter one-by-one (expensive), all are perturbed in the same step. extremely easy to implement can vary the distribution of step sizes (main algorithm uses step sizes 1 or 2 times a c( k ) ). COBYLA implemented in NLopt COBYLA uses a linear approximation of the function Subplex implemented in NLopt Sbplx similar to Nelder-Mead, but claims to be more robust Bayesian optimization","title":"Noisy objectives"},{"location":"julia_notes/optimization.html#global-algorithms","text":"QuadDIRECT combines ideas of DIRECT with local search points from local search are used to form boxes for the global search NODAL global optimization algorithms that can run in parallel possibly abandoned","title":"Global algorithms"},{"location":"julia_notes/optimization.html#controlled-random-search","text":"implemented as NLopt CRS starts from a random population of points (default size 10(n+1) ) user can control the size of the initial population, but there are no warm starts. then evolves these using heuristic rules. Described as \"randomized Nelder-Mead\".","title":"Controlled Random Search"},{"location":"julia_notes/optimization.html#mlsl","text":"implemented as NLopt MLSL basic idea: multistart a local solver, avoiding resolving points that are close to each other","title":"MLSL"},{"location":"julia_notes/optimization.html#tiktak","text":"Arnoud, Antoine, Fatih Guvenen, and Tatjana Kleineberg. 2019. \u201cBenchmarking Global Optimizers.\u201d Working Paper 26340. National Bureau of Economic Research. https://doi.org/10.3386/w26340. A multistart algorithm that generates new starting points as convex combinations of the current best point and Sobol points.","title":"TikTak"},{"location":"julia_notes/optimization.html#blackboxoptim","text":"implements SPSA currently little documentation (2020-May) There is an example of distributed parallel optimization. Not clear whether multi-threaded works as well. Not clear whether / how optimization history can be saved.","title":"BlackBoxOptim"},{"location":"julia_notes/optimization.html#surrogate-optimization","text":"Basic idea: Sample a small number of points. Evaluate the objective. Fit a surrogate function to those points. Optimize this function, which is cheap to evaluate, using an algorithm that explores the global parameter space downweights points that are far from points where the true objective has been evaluated Add the optimum of the surrogate to the list of evaluated points (using the true function value). Update the surrogate model based on the new point. Repeat. Packages: Surrogates.jl : a variety of algorithms and sampling methods. SurrogateModelOptim.jl Drawback: There is no good way of running the surrogate optimization in parallel (unlike Matlab).","title":"Surrogate Optimization"},{"location":"julia_notes/packages.html","text":"Packages \u00b6 Why Packages? \u00b6 The alternative to creating a package is to create an environment with a bunch of jl files that contain a module . Reasons why packages are better: Revise.jl has an easier time tracking code changes. Pkg.test works. Code is easier to reuse with just a simple Pkg.add and Pkg.develop and using MyPkg . No need for includet statements. If the module is used in multiple modules in the same environment, one has to make sure that each module uses the same version of MyPkg . One has to avoid multiple includet(\"MyPkg.jl\") which would create multiple instances of MyPkg . Creating packages \u00b6 Create the package locally. If using PkgTemplates.jl , this automatically initializes the github repo and sets it as the origin ( git remote add origin <url> ). Write some code. Push to github. PkgTemplates.jl \u00b6 The typical flow would be: using PkgTemplates gitIgnore = [ \"*.jl.cov\" , \"*.jl.*.cov\" , \"*.jl.mem\" , \"/deps/deps.jl\" , \"/docs/build\" ]; t = Template (; dir = joinpath ( homedir (), \"Documents\" , \"julia\" ), plugins = [ Documenter { GitHubActions }, Git (; jl = false , ignore = gitIgnore ), ! CompatHelper , ! AppVeyor , ! TravisCI , ! TagBot ]); t ( \"MyPkg\" ); Note that dir points to the parent directory of the new packages to be created. Even if one does not want to deploy documentation, the Documenter plugin is needed to create the barebones file structure. PkgSkeleton.jl (1.5) \u00b6 The easiest way for creating a package is PkgSkeleton.jl. You need to set your github info (user.name etc) using git config --global user.name YourName This must be done inside a git directory. Then generate generates the directory structure and the required files (Project.toml etc). Example: PkgSkeleton.generate(\"dir1/MyPackage\") Details: I first create the repo on github and clone it to the local dir. Then I use, from the parent dir: PkgSkeleton.generate(\"MyPackage\", skip_existing_dir = false) This way everything is linked to github from the start. Github and packages \u00b6 The basic steps (after creating the package locally): Create the package on github. git branch -M main git push -u origin main Or import the package repo into Github Desktop. Compatibility \u00b6 Enabling CompatHelper workflows is very helpful. Simply update CompatHelper.yml in the repo's .github/workflows directory and enable local actions in the github repo settings. The rest is automatic. CompatHelper creates one PR each time a dependency experiences a breaking version bump. Rather than merging these on github, it is easier to manually edit Project.toml locally, test, commit, and then close the PRs. For updating compat entries, PkgCompatUI is useful. It shows available versions for all packages and indicates which ones have breaking updates. Pkg Errors \u00b6 Occasionally, Pkg complains that a package is not registered. ]registry up tends to solve that issue. If that fails, one can alway remove the registry with ]registry remove General . It will be automatically installed again the next time it's needed.","title":"Packages"},{"location":"julia_notes/packages.html#packages","text":"","title":"Packages"},{"location":"julia_notes/packages.html#why-packages","text":"The alternative to creating a package is to create an environment with a bunch of jl files that contain a module . Reasons why packages are better: Revise.jl has an easier time tracking code changes. Pkg.test works. Code is easier to reuse with just a simple Pkg.add and Pkg.develop and using MyPkg . No need for includet statements. If the module is used in multiple modules in the same environment, one has to make sure that each module uses the same version of MyPkg . One has to avoid multiple includet(\"MyPkg.jl\") which would create multiple instances of MyPkg .","title":"Why Packages?"},{"location":"julia_notes/packages.html#creating-packages","text":"Create the package locally. If using PkgTemplates.jl , this automatically initializes the github repo and sets it as the origin ( git remote add origin <url> ). Write some code. Push to github.","title":"Creating packages"},{"location":"julia_notes/packages.html#pkgtemplatesjl","text":"The typical flow would be: using PkgTemplates gitIgnore = [ \"*.jl.cov\" , \"*.jl.*.cov\" , \"*.jl.mem\" , \"/deps/deps.jl\" , \"/docs/build\" ]; t = Template (; dir = joinpath ( homedir (), \"Documents\" , \"julia\" ), plugins = [ Documenter { GitHubActions }, Git (; jl = false , ignore = gitIgnore ), ! CompatHelper , ! AppVeyor , ! TravisCI , ! TagBot ]); t ( \"MyPkg\" ); Note that dir points to the parent directory of the new packages to be created. Even if one does not want to deploy documentation, the Documenter plugin is needed to create the barebones file structure.","title":"PkgTemplates.jl"},{"location":"julia_notes/packages.html#pkgskeletonjl-15","text":"The easiest way for creating a package is PkgSkeleton.jl. You need to set your github info (user.name etc) using git config --global user.name YourName This must be done inside a git directory. Then generate generates the directory structure and the required files (Project.toml etc). Example: PkgSkeleton.generate(\"dir1/MyPackage\") Details: I first create the repo on github and clone it to the local dir. Then I use, from the parent dir: PkgSkeleton.generate(\"MyPackage\", skip_existing_dir = false) This way everything is linked to github from the start.","title":"PkgSkeleton.jl (1.5)"},{"location":"julia_notes/packages.html#github-and-packages","text":"The basic steps (after creating the package locally): Create the package on github. git branch -M main git push -u origin main Or import the package repo into Github Desktop.","title":"Github and packages"},{"location":"julia_notes/packages.html#compatibility","text":"Enabling CompatHelper workflows is very helpful. Simply update CompatHelper.yml in the repo's .github/workflows directory and enable local actions in the github repo settings. The rest is automatic. CompatHelper creates one PR each time a dependency experiences a breaking version bump. Rather than merging these on github, it is easier to manually edit Project.toml locally, test, commit, and then close the PRs. For updating compat entries, PkgCompatUI is useful. It shows available versions for all packages and indicates which ones have breaking updates.","title":"Compatibility"},{"location":"julia_notes/packages.html#pkg-errors","text":"Occasionally, Pkg complains that a package is not registered. ]registry up tends to solve that issue. If that fails, one can alway remove the registry with ]registry remove General . It will be automatically installed again the next time it's needed.","title":"Pkg Errors"},{"location":"julia_notes/parallel.html","text":"Parallel Computing \u00b6 Polyester.jl offers a customizable version of Threads.@threads . For example, one can set the minum \"batch size\" (no of loop iterations) per thread. This can be much faster than @threads when iterations are fast.","title":"Parallel Computing"},{"location":"julia_notes/parallel.html#parallel-computing","text":"Polyester.jl offers a customizable version of Threads.@threads . For example, one can set the minum \"batch size\" (no of loop iterations) per thread. This can be much faster than @threads when iterations are fast.","title":"Parallel Computing"},{"location":"julia_notes/performance.html","text":"Performance \u00b6 Profiling (1.5) \u00b6 A blog post on profiling and benchmarking. If the profiler shows that an assignment (e.g. setindex! ) takes a lot of time, it may indicate dynamic dispatch on the RHS of the assignment. I find it most efficient to have a global profiling environment that Pkg.add s Profile, BenchmarkTools, StatProfilerHTML . To use it: using MyPackage Pkg.activate(\"path/to/profiling\") using BenchmarkTools, Profile, StatProfilerHTML Pkg.activate(\".\") include(\"profiling_code.jl\") # for this package The output generated by the built-in profiler is hard to read. Fortunately, there are packages that improve readability or graph the results. ProfileView does compile now (1.3), taking a surprisingly long time. Personally, I find the presentation of StatProfilerHTML more convenient, though. StatProfilerHTML \u00b6 It provides a flame graph with clickable links that show which lines in a function take up most time. Need to locate index.html and open it by hand in the browser after running statprofilehtml() . But can click on path link in terminal as well. PProf.jl \u00b6 requires Graphviz. On MacOS, install using brew install graphviz. But it has TONS of dependencies and did not install on my system. Then PProf cannot be used. TimerOutputs.jl \u00b6 can be used to time selected lines of code produces a nicely formatted table that is much easier to digest than profiler output. Loops (1.5) \u00b6 LoopVectorization.jl can give massive speed improvements for for loops. An example . Manual dispatch (1.5) \u00b6 It is beneficial to manually dispatch at runtime when a variable could potentially take on many types (as far as the compiler knows) but we know that only a few of those are possible. This is done automatically for small unions (known as union splitting). But for parametric types, the compiler has to look up methods in the method table at runtime because they could be extended. The package ManualDispatch.jl has a @unionsplit macro for this purpose. But AFAIK one may just as well write out an explicit if else . This would look weird: if x isa A foo(x); elseif x isa B foo(x); end but it seems to work. See the discussion on discourse . GPU computing (1.5) \u00b6 Tutorials - Nextjournal 2019 - Cuda.jl tutorial","title":"Performance"},{"location":"julia_notes/performance.html#performance","text":"","title":"Performance"},{"location":"julia_notes/performance.html#profiling-15","text":"A blog post on profiling and benchmarking. If the profiler shows that an assignment (e.g. setindex! ) takes a lot of time, it may indicate dynamic dispatch on the RHS of the assignment. I find it most efficient to have a global profiling environment that Pkg.add s Profile, BenchmarkTools, StatProfilerHTML . To use it: using MyPackage Pkg.activate(\"path/to/profiling\") using BenchmarkTools, Profile, StatProfilerHTML Pkg.activate(\".\") include(\"profiling_code.jl\") # for this package The output generated by the built-in profiler is hard to read. Fortunately, there are packages that improve readability or graph the results. ProfileView does compile now (1.3), taking a surprisingly long time. Personally, I find the presentation of StatProfilerHTML more convenient, though.","title":"Profiling (1.5)"},{"location":"julia_notes/performance.html#statprofilerhtml","text":"It provides a flame graph with clickable links that show which lines in a function take up most time. Need to locate index.html and open it by hand in the browser after running statprofilehtml() . But can click on path link in terminal as well.","title":"StatProfilerHTML"},{"location":"julia_notes/performance.html#pprofjl","text":"requires Graphviz. On MacOS, install using brew install graphviz. But it has TONS of dependencies and did not install on my system. Then PProf cannot be used.","title":"PProf.jl"},{"location":"julia_notes/performance.html#timeroutputsjl","text":"can be used to time selected lines of code produces a nicely formatted table that is much easier to digest than profiler output.","title":"TimerOutputs.jl"},{"location":"julia_notes/performance.html#loops-15","text":"LoopVectorization.jl can give massive speed improvements for for loops. An example .","title":"Loops (1.5)"},{"location":"julia_notes/performance.html#manual-dispatch-15","text":"It is beneficial to manually dispatch at runtime when a variable could potentially take on many types (as far as the compiler knows) but we know that only a few of those are possible. This is done automatically for small unions (known as union splitting). But for parametric types, the compiler has to look up methods in the method table at runtime because they could be extended. The package ManualDispatch.jl has a @unionsplit macro for this purpose. But AFAIK one may just as well write out an explicit if else . This would look weird: if x isa A foo(x); elseif x isa B foo(x); end but it seems to work. See the discussion on discourse .","title":"Manual dispatch (1.5)"},{"location":"julia_notes/performance.html#gpu-computing-15","text":"Tutorials - Nextjournal 2019 - Cuda.jl tutorial","title":"GPU computing (1.5)"},{"location":"julia_notes/plotting.html","text":"Plotting \u00b6 Plots.jl \u00b6 Visually, PlotlyJS produces the most appealing plots (for me). But it does not install on my system (1.5). When a plotting related library is not found (as in \u201cerror compiling display\u201d), try ]build Plots . Defaults are set with the defaults command. Axis labels \u00b6 bar tends to have too small default margins for axis labels to show (at least in subplots). Try using Plots.PlotMeasures Colors \u00b6 Saturation is given by a number between 0 and 1 as in color = (:blue, 0.2) . Legends \u00b6 The label is set when each series is plotted. If labels are set when the plot is created (before the series are plotted), the entries are ignored. Bar graphs \u00b6 Switch off lines around bars with linealpha = 0 . Default arguments \u00b6 Make a Dict with default arguments for each plot type, such as: bar_defaults () = Dict ([ : leg => : bottom , : linecolor => : black ]); Make a function for each plot type, such as: function bar_graph ( groupLabelV , dataV ; kwargs ... ) args = merge ( bar_defaults (), kwargs ); p = bar ( groupLabelV , dataV ; args ... ); return p end Now any default arguments can be overridden and bar_graph is called exactly as bar would be. Makie.jl \u00b6 Subplots \u00b6 It helps to write plotting functions that take a Figure as an input: # Make a stand-alone figure. Could be omitted. function myplot ( x , y ; kwargs ... ) fig = Figure (); myplot! ( f , x , y ; kwargs ... ) return fig end # Plot into existing Figure. function myplot! ( fig :: Figure , x , y ; pos = ( 1 , 1 ), kwargs ... ) ax = fig [ pos ... ] = Axis ( fig ; xlabel = \"x\" ); myplot! ( ax , x , y ; kwargs ... ); return ax end # Plot into existing Axis function myplot! ( ax :: Axis , x , y ; kwargs ... ) lines! ( ax , x , y ; kwargs ... ); end # Now we can make a stand-alone figure with fig = Figure (); myplot! ( fig , x , y ); # Or we can make a subplot with fig = Figure (); myplot! ( fig , x , y ; pos = ( 2 , 1 )); Limitations: The kwargs cannot be used to create the axis. Looping over axes \u00b6 One way of creating a figure with subplots is: fig = Figure (); nr = 2 ; nc = 3 ; for ir = 1 : nr , ic = 1 : nc ax = fig [ ir , ic ] = Axis ( fig ); end This fixes the layout. Now we can iterate over the subplots with ind2sub ( j , sz ) = Tuple ( CartesianIndices ( sz )[ j ]); for j = 1 : ( nr * nc ) fig [ ind2sub ( j , ( nr , nc )) ... ] end The roundabout way is necessary because Figure does not support linear or cartesian indexing. Grouped bar graphs \u00b6 Building up a grouped bar graph by plotting each series one at a time does not work. The first series bar is too wide (it covers the width of the entire group of bars). One could set it by hand, but it is not clear how. axislegend does not work for grouped bar graphs (lacking labels). Keyword arguments \u00b6 Makie ignores invalid keyword arguments. This makes it possible to \"flatten\" keyword arguments; i.e., one can provide that Axis arguments in the same list as the series arguments. For example, this works: lines ( x , y ; xlabel = \"x\" ); But lines! ( ax , x , y ; xlabel = \"x\" ); ignores the xlabel . nothing works with keyword arguments such as title . ylims appears to be ignored. Need to use ylims!(ax, lims) . Unspecified bounds are set to nothing (not Inf ). Themes \u00b6 update_theme!(thm, Lines = (linewidth = 4,)) creates a new \"section\" thm.Lines that applies to lines. update_theme!(thm, Lines = (linestyle = :dash,)) merges the new information into the existing Lines section. It does not replace previous content. Text sizes are determined by separate attributes for all elements; e.g., xticklabelsize . Setting line colors from the theme's colormap : thm = theme_dark (); update_theme! ( thm ; colormap = ColorSchemes . leonardo ); function make_figure () fig = Figure (); ax = fig [ 1 , 1 ] = Axis ( fig ); for j = 1 : 4 ; lines! ( ax , 1 : 10 , ( 1 : 10 ) .^ ( 1 / j ); color = fill ( j , 10 ), colorrange = ( 1 , 4 )); end return fig end fig = with_theme ( make_figure , thm ); Errors in theme settings cause merge! errors when plotting that bear no obvious relationship to themes. Saving data with plots \u00b6 VegaLite does this natively. with Plots.jl one can use hdf5plot_write to write an entire plot, including the data, to an hdf5 file. This means that each plot has to be generated twice; once with whatever backend is used to generate PDF files; and then again with hdf5. In particular, one cannot first plot with another backend and then save the resulting plot object to hdf5. The approach is then to first save the plot to hdf5, then load it and save it with another backend. Note: In my current (v.1.3) installation, hdf5plot_write generates a bunch or warnings followed by a crash due to world age problems.","title":"Plotting"},{"location":"julia_notes/plotting.html#plotting","text":"","title":"Plotting"},{"location":"julia_notes/plotting.html#plotsjl","text":"Visually, PlotlyJS produces the most appealing plots (for me). But it does not install on my system (1.5). When a plotting related library is not found (as in \u201cerror compiling display\u201d), try ]build Plots . Defaults are set with the defaults command.","title":"Plots.jl"},{"location":"julia_notes/plotting.html#axis-labels","text":"bar tends to have too small default margins for axis labels to show (at least in subplots). Try using Plots.PlotMeasures","title":"Axis labels"},{"location":"julia_notes/plotting.html#colors","text":"Saturation is given by a number between 0 and 1 as in color = (:blue, 0.2) .","title":"Colors"},{"location":"julia_notes/plotting.html#legends","text":"The label is set when each series is plotted. If labels are set when the plot is created (before the series are plotted), the entries are ignored.","title":"Legends"},{"location":"julia_notes/plotting.html#bar-graphs","text":"Switch off lines around bars with linealpha = 0 .","title":"Bar graphs"},{"location":"julia_notes/plotting.html#default-arguments","text":"Make a Dict with default arguments for each plot type, such as: bar_defaults () = Dict ([ : leg => : bottom , : linecolor => : black ]); Make a function for each plot type, such as: function bar_graph ( groupLabelV , dataV ; kwargs ... ) args = merge ( bar_defaults (), kwargs ); p = bar ( groupLabelV , dataV ; args ... ); return p end Now any default arguments can be overridden and bar_graph is called exactly as bar would be.","title":"Default arguments"},{"location":"julia_notes/plotting.html#makiejl","text":"","title":"Makie.jl"},{"location":"julia_notes/plotting.html#subplots","text":"It helps to write plotting functions that take a Figure as an input: # Make a stand-alone figure. Could be omitted. function myplot ( x , y ; kwargs ... ) fig = Figure (); myplot! ( f , x , y ; kwargs ... ) return fig end # Plot into existing Figure. function myplot! ( fig :: Figure , x , y ; pos = ( 1 , 1 ), kwargs ... ) ax = fig [ pos ... ] = Axis ( fig ; xlabel = \"x\" ); myplot! ( ax , x , y ; kwargs ... ); return ax end # Plot into existing Axis function myplot! ( ax :: Axis , x , y ; kwargs ... ) lines! ( ax , x , y ; kwargs ... ); end # Now we can make a stand-alone figure with fig = Figure (); myplot! ( fig , x , y ); # Or we can make a subplot with fig = Figure (); myplot! ( fig , x , y ; pos = ( 2 , 1 )); Limitations: The kwargs cannot be used to create the axis.","title":"Subplots"},{"location":"julia_notes/plotting.html#looping-over-axes","text":"One way of creating a figure with subplots is: fig = Figure (); nr = 2 ; nc = 3 ; for ir = 1 : nr , ic = 1 : nc ax = fig [ ir , ic ] = Axis ( fig ); end This fixes the layout. Now we can iterate over the subplots with ind2sub ( j , sz ) = Tuple ( CartesianIndices ( sz )[ j ]); for j = 1 : ( nr * nc ) fig [ ind2sub ( j , ( nr , nc )) ... ] end The roundabout way is necessary because Figure does not support linear or cartesian indexing.","title":"Looping over axes"},{"location":"julia_notes/plotting.html#grouped-bar-graphs","text":"Building up a grouped bar graph by plotting each series one at a time does not work. The first series bar is too wide (it covers the width of the entire group of bars). One could set it by hand, but it is not clear how. axislegend does not work for grouped bar graphs (lacking labels).","title":"Grouped bar graphs"},{"location":"julia_notes/plotting.html#keyword-arguments","text":"Makie ignores invalid keyword arguments. This makes it possible to \"flatten\" keyword arguments; i.e., one can provide that Axis arguments in the same list as the series arguments. For example, this works: lines ( x , y ; xlabel = \"x\" ); But lines! ( ax , x , y ; xlabel = \"x\" ); ignores the xlabel . nothing works with keyword arguments such as title . ylims appears to be ignored. Need to use ylims!(ax, lims) . Unspecified bounds are set to nothing (not Inf ).","title":"Keyword arguments"},{"location":"julia_notes/plotting.html#themes","text":"update_theme!(thm, Lines = (linewidth = 4,)) creates a new \"section\" thm.Lines that applies to lines. update_theme!(thm, Lines = (linestyle = :dash,)) merges the new information into the existing Lines section. It does not replace previous content. Text sizes are determined by separate attributes for all elements; e.g., xticklabelsize . Setting line colors from the theme's colormap : thm = theme_dark (); update_theme! ( thm ; colormap = ColorSchemes . leonardo ); function make_figure () fig = Figure (); ax = fig [ 1 , 1 ] = Axis ( fig ); for j = 1 : 4 ; lines! ( ax , 1 : 10 , ( 1 : 10 ) .^ ( 1 / j ); color = fill ( j , 10 ), colorrange = ( 1 , 4 )); end return fig end fig = with_theme ( make_figure , thm ); Errors in theme settings cause merge! errors when plotting that bear no obvious relationship to themes.","title":"Themes"},{"location":"julia_notes/plotting.html#saving-data-with-plots","text":"VegaLite does this natively. with Plots.jl one can use hdf5plot_write to write an entire plot, including the data, to an hdf5 file. This means that each plot has to be generated twice; once with whatever backend is used to generate PDF files; and then again with hdf5. In particular, one cannot first plot with another backend and then save the resulting plot object to hdf5. The approach is then to first save the plot to hdf5, then load it and save it with another backend. Note: In my current (v.1.3) installation, hdf5plot_write generates a bunch or warnings followed by a crash due to world age problems.","title":"Saving data with plots"},{"location":"julia_notes/regressions.html","text":"Regressions \u00b6 RegressionTables.jl produces formatted regression tables. GLM (1.5) \u00b6 GLM.jl is the package to run regressions. GLM really expects the data to be provided as a DataFrame , but one can run m = fit(LinearModel, X, y); Then the intercept needs to be explicitly provided as a column of X . Methods: coef(m) returns values of coefficients stderror(m) returns coefficient std errors confint(m) produces confidence intervals by (regressor, lower/upper). But these are wrong in the current version of GLM (and the method no longer appears in the documentation). predict(m) gives predicted values for original X values It is currently not possible to compute confidence intervals for predicted values. There are open issues for this. To save just the regression results (without the data, which could be a lot of memory), use coeftable(mdl). This produces a StatsBase.CoefTable. Alternative, use RegressionTable from EconometricsLH. Categorical regressors return names such as Symbol(\u201cschool: 3\u201d). A useful introduction is in the Cookbook .","title":"Regressions"},{"location":"julia_notes/regressions.html#regressions","text":"RegressionTables.jl produces formatted regression tables.","title":"Regressions"},{"location":"julia_notes/regressions.html#glm-15","text":"GLM.jl is the package to run regressions. GLM really expects the data to be provided as a DataFrame , but one can run m = fit(LinearModel, X, y); Then the intercept needs to be explicitly provided as a column of X . Methods: coef(m) returns values of coefficients stderror(m) returns coefficient std errors confint(m) produces confidence intervals by (regressor, lower/upper). But these are wrong in the current version of GLM (and the method no longer appears in the documentation). predict(m) gives predicted values for original X values It is currently not possible to compute confidence intervals for predicted values. There are open issues for this. To save just the regression results (without the data, which could be a lot of memory), use coeftable(mdl). This produces a StatsBase.CoefTable. Alternative, use RegressionTable from EconometricsLH. Categorical regressors return names such as Symbol(\u201cschool: 3\u201d). A useful introduction is in the Cookbook .","title":"GLM (1.5)"},{"location":"julia_notes/testing.html","text":"Testing \u00b6 Structuring tests \u00b6 The goal is to be able to run subsets of tests and to encapsulate the code of each test. My current approach: Place each testset inside a function. Call these functions from within other testsets. One can now include each file and run the tests independently. The function provide some isolation (similar to using modules). # runtests.jl @testset \"All\" begin include ( \"test_one.jl\" ); end # test_one.jl using Test function test_one () @testset \"A\" begin @test 1 == 1 end end @testset \"One\" begin test_one (); end Now Pkg.test() runs everything, but include(\"test/test_one.jl\") only runs the subset. SafeTests.jl goes further by wrapping tests in modules. Test helpers can be put into a separate file and conditionally included, as in (taken from MPVerify.jl): @isdefined ( TestHelpers ) || include ( \"../TestHelpers.jl\" ) This checks whether the module TestHelpers exists. But one may not need a module for the helpers. Module approach: \u00b6 Place each group of tests into a module, so the tests are independent of each other and can be run independently. SafeTestsets.jl has a similar idea, but I find it cleaner to explicitly write out the modules. Though modules have the benefit that they can include setup code that is used repeatedly in different tests. runtests.jl simply contains a list of include statements; one for each test module. Those are wrapped in a @testset for nice display and to ensure that errors don't stop the tests. Each test module also contains a @testset. When runtests is run, it displays a single success summary. But when there are errors, they are nicely broken down by testset. To run tests selectively, simply include the file that contains the @testset at the REPL. Test specific dependencies \u00b6 Test dependencies now need to be added to the Project.toml file in ./test : pkg> activate ./test pkg> add MyPkg pkg> activate . All dependencies used in tests now have to be manually added. They do not \"carry over\" from the main package. Developing test set dependencies seems to cause problems (\"error: cannot merge projects\"). They need to be added. Important note : For now (1.5) test dependencies are still considered \"beta\" and buggy. Do not use. Instead, use the 1.0 method of extras in Project.toml . Useful packages \u00b6 Aqua.jl checks for method ambiguities, invalid exports, stale dependencies, and more. TestSetExtensions.jl mainly provides nicer display of test progress and failures UnitTestDesign generates combinations of arguments that are passed to tests the goal is to generate coverage without having to run all parameter combinations Travis CI (1.2) \u00b6 Travis can automatically test all branches uploaded to github. Need to customize travis.yml to only build for the current Julia version. Building with unregistered dependencies is tricky. Probably ok if the dependencies are added (so they point to a github url), but not if they are developed. Miscellaneous \u00b6 Errors in the code to be tested (but not caught by @test) cause the entire test run to crash. Preventing this requires all tests to be enclosed in a @testset. A sequence of @testset does not do the trick. An error in one prevents all others from being run. Nested @testsets produce nested error reports (nice). @test statements can be placed inside functions. To preserve result reporting, the function should contain a @testset and return its result.","title":"Testing"},{"location":"julia_notes/testing.html#testing","text":"","title":"Testing"},{"location":"julia_notes/testing.html#structuring-tests","text":"The goal is to be able to run subsets of tests and to encapsulate the code of each test. My current approach: Place each testset inside a function. Call these functions from within other testsets. One can now include each file and run the tests independently. The function provide some isolation (similar to using modules). # runtests.jl @testset \"All\" begin include ( \"test_one.jl\" ); end # test_one.jl using Test function test_one () @testset \"A\" begin @test 1 == 1 end end @testset \"One\" begin test_one (); end Now Pkg.test() runs everything, but include(\"test/test_one.jl\") only runs the subset. SafeTests.jl goes further by wrapping tests in modules. Test helpers can be put into a separate file and conditionally included, as in (taken from MPVerify.jl): @isdefined ( TestHelpers ) || include ( \"../TestHelpers.jl\" ) This checks whether the module TestHelpers exists. But one may not need a module for the helpers.","title":"Structuring tests"},{"location":"julia_notes/testing.html#module-approach","text":"Place each group of tests into a module, so the tests are independent of each other and can be run independently. SafeTestsets.jl has a similar idea, but I find it cleaner to explicitly write out the modules. Though modules have the benefit that they can include setup code that is used repeatedly in different tests. runtests.jl simply contains a list of include statements; one for each test module. Those are wrapped in a @testset for nice display and to ensure that errors don't stop the tests. Each test module also contains a @testset. When runtests is run, it displays a single success summary. But when there are errors, they are nicely broken down by testset. To run tests selectively, simply include the file that contains the @testset at the REPL.","title":"Module approach:"},{"location":"julia_notes/testing.html#test-specific-dependencies","text":"Test dependencies now need to be added to the Project.toml file in ./test : pkg> activate ./test pkg> add MyPkg pkg> activate . All dependencies used in tests now have to be manually added. They do not \"carry over\" from the main package. Developing test set dependencies seems to cause problems (\"error: cannot merge projects\"). They need to be added. Important note : For now (1.5) test dependencies are still considered \"beta\" and buggy. Do not use. Instead, use the 1.0 method of extras in Project.toml .","title":"Test specific dependencies"},{"location":"julia_notes/testing.html#useful-packages","text":"Aqua.jl checks for method ambiguities, invalid exports, stale dependencies, and more. TestSetExtensions.jl mainly provides nicer display of test progress and failures UnitTestDesign generates combinations of arguments that are passed to tests the goal is to generate coverage without having to run all parameter combinations","title":"Useful packages"},{"location":"julia_notes/testing.html#travis-ci-12","text":"Travis can automatically test all branches uploaded to github. Need to customize travis.yml to only build for the current Julia version. Building with unregistered dependencies is tricky. Probably ok if the dependencies are added (so they point to a github url), but not if they are developed.","title":"Travis CI (1.2)"},{"location":"julia_notes/testing.html#miscellaneous","text":"Errors in the code to be tested (but not caught by @test) cause the entire test run to crash. Preventing this requires all tests to be enclosed in a @testset. A sequence of @testset does not do the trick. An error in one prevents all others from being run. Nested @testsets produce nested error reports (nice). @test statements can be placed inside functions. To preserve result reporting, the function should contain a @testset and return its result.","title":"Miscellaneous"},{"location":"julia_notes/types.html","text":"Types \u00b6 Parametric types without the type parameter are NOT DataTypes; they are UnionAll. Example: struct Foo{T} end; isa(Foo, DataType) == false; I find it easiest to write model specific code NOT using parametric types. Instead, I define type aliases for the types used in custom types (e.g., Double=Float64 ). Then I hardwire the use of Double everywhere. This removes two problems: Possible type instability as the compiler tries to figure out the types of the custom type fields. It becomes possible to call constructors with, say, integers of all kinds without raising method errors. Broadcasting (1.6) \u00b6 For an object that behaves like a scalar, such as struct Foo x :: Int end it is enough to define Base.broadcastable(f :: Foo) = Ref(f) . Constructors (1.5) \u00b6 Constructing objects with many fields: Define an inner constructor that leaves the object (partially) uninitialized. It is legal to have new(x) even if the object contains additional fields. LazyInitializedFields.jl ensures that accessing uninitialized fields gives errors. Parameters.jl is useful for objects with default values. Constructor must then provide all arguments that do not have defaults. Note that @with_kw automatically defines show(). Use @with_kw_noshow to avoid this. Base.@kwdef now does much of the same. Inheritance (1.5) \u00b6 There is no inheritance in Julia. Abstract types have no fields and concrete types have no subtypes. There are various discussions about how to implement types that share common fields. For simple cases, it is probably best to just repeat the fields in all types. One good piece of advice: ensure that methods are generally defined on the abstract type, so that all concrete types have the same interface (kind of the point of having an abstract type). Macro for common fields \u00b6 A macro that lets users define a set of common fields for a set of structs: macro def ( name , definition ) return quote macro $ ( esc ( name ))() esc ( $ ( Expr ( : quote , definition ))) end end end @def commonfields begin #Data X #Feature vectors y #Labels (-1,1) nSamples :: Int64 # Number of data points nFeatures :: Int64 # Number of features end struct Foo @commonfields z end But this does not work with default values. Another option using @eval . A more robust implementation is Mixers.jl . @mix is intended to create parametric types. But @mix C1{} [...] works as well and creates a plain vanilla type. However, the @pour macro is then simpler: julia > @pour c1 begin x :: Int y :: Float64 end @c1 ( macro with 1 method ) julia > struct Foo @c1 z :: String end julia > Foo ( 1 , 2.0 , \"abc\" ) Foo ( 1 , 2.0 , \"abc\" ) Common fields with default values \u00b6 mutable struct Foo x y z Foo () = new (); end # Need at least one positional argument. Otherwise stack overflow. function Foo ( z :: Integer ; kwargs ... ) f = Foo (); set_common_fields! ( f ); set_kw_args! ( f ; kwargs ... ); f . z = z ; return f end function set_common_fields! ( f :: Foo ) f . x = 1 ; f . y = 2 ; end function set_kw_args! ( f :: Foo ; kwargs ... ) for kw in kwargs setfield! ( f , kw [ 1 ], kw [ 2 ]) end end julia > Foo ( 3 ) Foo ( 1 , 2 , 3 ) Common fields in sub-struct \u00b6 An alternative is to store common fields in a sub-struct. Passing methods through to these fields can be automated using @forward in Lazy.jl . using Lazy struct Foo x end @forward Foo . x ( Base . show , Base . isempty ) The tricky part is to modify these fields. One possible solution: Base.@kwdef mutable struct FooCommon x = 1 y = 2 end Base.@kwdef mutable struct Foo fc :: FooCommon z = 3 zz = 4 end # Again: need at least one positional argument to avoid stack overflow. function Foo(z; kwargs...) f = Foo(fc = FooCommon()); set_kwargs!(f; kwargs...); return f end function set_kwargs!(f :: Foo; kwargs...) for kw in kwargs set_field!(f, kw[1], kw[2]); end end # Note the changed function name. Cannot overload `setfield!`. function set_field!(f :: Foo, fName :: Symbol, fValue) if hasproperty(f, fName) setfield!(f, fName, fValue); else setfield!(f.fc, fName, fValue); end end User Defined Types (1.5) \u00b6 LazyInitializedFields.jl is a nice way of handling partially initialized struct fields. Properties and fields \u00b6 getfield is a \"built-in\" function that always points to a struct field directly. Example: struct A x :: Dict { Symbol , Int } y :: Int end a = A ( Dict ([ : a => 1 ]), 2 ); getfield ( a , : x ) isa Dict { Symbol , Int } getproperty is generically the same as getfield . But note that propertynames(A) spits out additional hidden properties, not just :x, :y . Users can overload getproperty to point to something more useful than the direct fields of the struct : Base . getproperty ( a :: A , n :: Symbol ) = getfield ( a , : x )[ n ]; Then also overload propertynames so that functions that rely on the public properties of A work.","title":"Types"},{"location":"julia_notes/types.html#types","text":"Parametric types without the type parameter are NOT DataTypes; they are UnionAll. Example: struct Foo{T} end; isa(Foo, DataType) == false; I find it easiest to write model specific code NOT using parametric types. Instead, I define type aliases for the types used in custom types (e.g., Double=Float64 ). Then I hardwire the use of Double everywhere. This removes two problems: Possible type instability as the compiler tries to figure out the types of the custom type fields. It becomes possible to call constructors with, say, integers of all kinds without raising method errors.","title":"Types"},{"location":"julia_notes/types.html#broadcasting-16","text":"For an object that behaves like a scalar, such as struct Foo x :: Int end it is enough to define Base.broadcastable(f :: Foo) = Ref(f) .","title":"Broadcasting (1.6)"},{"location":"julia_notes/types.html#constructors-15","text":"Constructing objects with many fields: Define an inner constructor that leaves the object (partially) uninitialized. It is legal to have new(x) even if the object contains additional fields. LazyInitializedFields.jl ensures that accessing uninitialized fields gives errors. Parameters.jl is useful for objects with default values. Constructor must then provide all arguments that do not have defaults. Note that @with_kw automatically defines show(). Use @with_kw_noshow to avoid this. Base.@kwdef now does much of the same.","title":"Constructors (1.5)"},{"location":"julia_notes/types.html#inheritance-15","text":"There is no inheritance in Julia. Abstract types have no fields and concrete types have no subtypes. There are various discussions about how to implement types that share common fields. For simple cases, it is probably best to just repeat the fields in all types. One good piece of advice: ensure that methods are generally defined on the abstract type, so that all concrete types have the same interface (kind of the point of having an abstract type).","title":"Inheritance (1.5)"},{"location":"julia_notes/types.html#macro-for-common-fields","text":"A macro that lets users define a set of common fields for a set of structs: macro def ( name , definition ) return quote macro $ ( esc ( name ))() esc ( $ ( Expr ( : quote , definition ))) end end end @def commonfields begin #Data X #Feature vectors y #Labels (-1,1) nSamples :: Int64 # Number of data points nFeatures :: Int64 # Number of features end struct Foo @commonfields z end But this does not work with default values. Another option using @eval . A more robust implementation is Mixers.jl . @mix is intended to create parametric types. But @mix C1{} [...] works as well and creates a plain vanilla type. However, the @pour macro is then simpler: julia > @pour c1 begin x :: Int y :: Float64 end @c1 ( macro with 1 method ) julia > struct Foo @c1 z :: String end julia > Foo ( 1 , 2.0 , \"abc\" ) Foo ( 1 , 2.0 , \"abc\" )","title":"Macro for common fields"},{"location":"julia_notes/types.html#common-fields-with-default-values","text":"mutable struct Foo x y z Foo () = new (); end # Need at least one positional argument. Otherwise stack overflow. function Foo ( z :: Integer ; kwargs ... ) f = Foo (); set_common_fields! ( f ); set_kw_args! ( f ; kwargs ... ); f . z = z ; return f end function set_common_fields! ( f :: Foo ) f . x = 1 ; f . y = 2 ; end function set_kw_args! ( f :: Foo ; kwargs ... ) for kw in kwargs setfield! ( f , kw [ 1 ], kw [ 2 ]) end end julia > Foo ( 3 ) Foo ( 1 , 2 , 3 )","title":"Common fields with default values"},{"location":"julia_notes/types.html#common-fields-in-sub-struct","text":"An alternative is to store common fields in a sub-struct. Passing methods through to these fields can be automated using @forward in Lazy.jl . using Lazy struct Foo x end @forward Foo . x ( Base . show , Base . isempty ) The tricky part is to modify these fields. One possible solution: Base.@kwdef mutable struct FooCommon x = 1 y = 2 end Base.@kwdef mutable struct Foo fc :: FooCommon z = 3 zz = 4 end # Again: need at least one positional argument to avoid stack overflow. function Foo(z; kwargs...) f = Foo(fc = FooCommon()); set_kwargs!(f; kwargs...); return f end function set_kwargs!(f :: Foo; kwargs...) for kw in kwargs set_field!(f, kw[1], kw[2]); end end # Note the changed function name. Cannot overload `setfield!`. function set_field!(f :: Foo, fName :: Symbol, fValue) if hasproperty(f, fName) setfield!(f, fName, fValue); else setfield!(f.fc, fName, fValue); end end","title":"Common fields in sub-struct"},{"location":"julia_notes/types.html#user-defined-types-15","text":"LazyInitializedFields.jl is a nice way of handling partially initialized struct fields.","title":"User Defined Types (1.5)"},{"location":"julia_notes/types.html#properties-and-fields","text":"getfield is a \"built-in\" function that always points to a struct field directly. Example: struct A x :: Dict { Symbol , Int } y :: Int end a = A ( Dict ([ : a => 1 ]), 2 ); getfield ( a , : x ) isa Dict { Symbol , Int } getproperty is generically the same as getfield . But note that propertynames(A) spits out additional hidden properties, not just :x, :y . Users can overload getproperty to point to something more useful than the direct fields of the struct : Base . getproperty ( a :: A , n :: Symbol ) = getfield ( a , : x )[ n ]; Then also overload propertynames so that functions that rely on the public properties of A work.","title":"Properties and fields"},{"location":"julia_notes/workflow.html","text":"Workflow \u00b6 It is often useful to try something in a temporary environment. Pkg.activate(temp = true) or pkg> activate --temp both generate a temporary environment in /tmp and activate it. Here, one can add dependencies and then simply forget the environment once done. The folder will be automatically cleaned up after some time, I believe. Revise.jl \u00b6 Revise is essential for a smooth workflow. One limitation: include ing files in a model that is tracked with includet does not work (1.6). Example: # Foo.jl module Foo include ( \"foo2.jl\" ) end # foo2.jl foo () = println ( \"This is foo\" ) # REPL includet ( \"Foo.jl\" ) produces a MethodError that is hard to make sense of. Once code gets complicated enough that files include other files, it is best to make a package.","title":"Workflow"},{"location":"julia_notes/workflow.html#workflow","text":"It is often useful to try something in a temporary environment. Pkg.activate(temp = true) or pkg> activate --temp both generate a temporary environment in /tmp and activate it. Here, one can add dependencies and then simply forget the environment once done. The folder will be automatically cleaned up after some time, I believe.","title":"Workflow"},{"location":"julia_notes/workflow.html#revisejl","text":"Revise is essential for a smooth workflow. One limitation: include ing files in a model that is tracked with includet does not work (1.6). Example: # Foo.jl module Foo include ( \"foo2.jl\" ) end # foo2.jl foo () = println ( \"This is foo\" ) # REPL includet ( \"Foo.jl\" ) produces a MethodError that is hard to make sense of. Once code gets complicated enough that files include other files, it is best to make a package.","title":"Revise.jl"},{"location":"teaching/current_issues.html","text":"Topics in the Current Policy Debate \u00b6 Trade Restrictions: China \u00b6 Economist topic page: trade barriers Winners and losers in a China-America trade war (Economist, Jan 2017) What might a trade war between America and China look like? (Economist, Feb 2017) Taxes \u00b6 Border Adjustments, Tariffs, VAT, and the Corporate Income Tax , Jan 2017 discusses the implications of corporate tax reforms, including the Trump proposal Useful sources for undergraduate research \u00b6 Journal of Economic Perspectives Brookings Institution , which also has topics pages NY Fed: Liberty Street Economics , Economic Policy Review MN Fed: Quarterly Review SF Fed: Economic Letter Google scholar is useful for finding articles.","title":"Topics in the Current Policy Debate #"},{"location":"teaching/current_issues.html#topics-in-the-current-policy-debate","text":"","title":"Topics in the Current Policy Debate"},{"location":"teaching/current_issues.html#trade-restrictions-china","text":"Economist topic page: trade barriers Winners and losers in a China-America trade war (Economist, Jan 2017) What might a trade war between America and China look like? (Economist, Feb 2017)","title":"Trade Restrictions: China"},{"location":"teaching/current_issues.html#taxes","text":"Border Adjustments, Tariffs, VAT, and the Corporate Income Tax , Jan 2017 discusses the implications of corporate tax reforms, including the Trump proposal","title":"Taxes"},{"location":"teaching/current_issues.html#useful-sources-for-undergraduate-research","text":"Journal of Economic Perspectives Brookings Institution , which also has topics pages NY Fed: Liberty Street Economics , Economic Policy Review MN Fed: Quarterly Review SF Fed: Economic Letter Google scholar is useful for finding articles.","title":"Useful sources for undergraduate research"},{"location":"teaching/exam_tips.html","text":"Tips for Exams \u00b6 Slow down \u00b6 Most exam answers are quite short. The trick is to approach the question correctly from the start. Algebra errors are quite costly. They can be avoided by slowing down, writing carefully, and checking your algebra from time to time. Read the question carefully. I often grade answers that clearly overlooked a piece of information that was given in the question. Don't panic \u00b6 Don't panic when an answer does not come together. Move on to the next question and come back to the one that bugs you later. Explain your answers \u00b6 Just giving me a graph and letting me figure out the answer does not work. When you draw a graph, explain why you think the curves slope up or down, etc. If you make a mistake, at least I can give you partial credit. Writing \u00b6 Make room. A lot of answers are very crowded. Then you find that you have to fit something else in and soon you have a mess on the page, where I don't even know in what order I am supposed to read things. If I can't read it, I can't grade it.","title":"Tips for Exams #"},{"location":"teaching/exam_tips.html#tips-for-exams","text":"","title":"Tips for Exams"},{"location":"teaching/exam_tips.html#slow-down","text":"Most exam answers are quite short. The trick is to approach the question correctly from the start. Algebra errors are quite costly. They can be avoided by slowing down, writing carefully, and checking your algebra from time to time. Read the question carefully. I often grade answers that clearly overlooked a piece of information that was given in the question.","title":"Slow down"},{"location":"teaching/exam_tips.html#dont-panic","text":"Don't panic when an answer does not come together. Move on to the next question and come back to the one that bugs you later.","title":"Don't panic"},{"location":"teaching/exam_tips.html#explain-your-answers","text":"Just giving me a graph and letting me figure out the answer does not work. When you draw a graph, explain why you think the curves slope up or down, etc. If you make a mistake, at least I can give you partial credit.","title":"Explain your answers"},{"location":"teaching/exam_tips.html#writing","text":"Make room. A lot of answers are very crowded. Then you find that you have to fit something else in and soon you have a mess on the page, where I don't even know in what order I am supposed to read things. If I can't read it, I can't grade it.","title":"Writing"},{"location":"teaching/honors_thesis_topics.html","text":"Some Ideas for Honors Thesis Projects \u00b6 This page contains a collection of ideas that may be useful starting points for honors theses. Disclaimer : I haven't thought about these ideas carefully, so they may not be good ideas. Or they may have been done (note the date next to each idea). Or they may not be doable. Or boring, or fundamentally mistaken, or any of the other things that tend to derail research projects. Don't take the ideas as given. Use them to get started thinking about a set of questions. A good thesis topic explores cause and effect (e.g., minimum wages affect unemployment) with some clever identification strategy (e.g., instrumental variables). Most of the topics I am listing here don't fit that pattern. They are really just data descriptions. The reason is that I work with structural models. For the questions that I study, getting answers with data only is usually not possible. College \u00b6 College qualities over time \u00b6 Are college qualities highly persistent over time? Do colleges move around in the quality distribution? Which colleges move up and why? Is there a mechanism that \"rewards\" better colleges and forces \"worse\" colleges to exit? Drawbacks: this is descriptive. College Stratification \u00b6 Hoxby (2009) shows that colleges became more stratified in the 1960s. Her data end in 2006. They are also not publicly available. Moreover, Hoxby's data show that initially highly selective colleges became more selective over time and vice versa. A different, but related, question is: did colleges become more homogeneous? How did the CDF of college \"qualities\" change over time? What happened more recently? Possible data sources: IPEDS (since about 1985) and HERI freshmen surveys. Drawback: this is descriptive. Cross-country Income Differences \u00b6 Occupational downgrading of immigrants (2020) \u00b6 Idea: If immigrants from poor countries have less human capital (given schooling), they should be employed in jobs that require less human capital. Those are jobs held by natives with lower schooling. Quantify this: Construct average native schooling by [occupation, industry]. For each source/host pair: compute the average gap between immigrant and native schooling in [occ, ind] cells. This is a measure of occupational downgrading. To what extent is the wage gap between immigrants and similar natives explained by this? Jones (2014) has strong claims about downgrading. How do those hold up? The task content of immigrant jobs (2020) \u00b6 Todd Schoellman may have done this. Inequality \u00b6 Hsieh/Klenow for Immigrants \u00b6 Hsieh et al 2019 show that women and black men were underrepresented in certain occupations in the 1960s. Over time, the gaps diminished, suggesting that the allocation of talent improved. Is there evidence for a similar convergence among immigrants? Drawback: this is really just a replication of Hsieh et al for a different population group. Sources of earnings \"shocks\" (2021) \u00b6 Administrative data show that earnings \"shocks\" are asymmetric (frequent small positive and rare large negative shocks). What observable events are associated with earnings shocks? What fraction of the \"shocks\" are due to employer changes including layoffs occupation changes big changes in hours worked family events (e.g., having children) The goal is to inform how one could model earnings shocks (in structural models). There is a recent paper (for which I cannot find a reference) that does something related using administrative data from a Nordic country. Drawbacks: may be hard to do with publicly available data descriptive How predictable are lifetime earnings? (2020) \u00b6 It is fairly easy to get a lower bound on predictability. Take a panel dataset. Use half to fit a statistical model. Use the other half to perform out of sample prediction. Specification search is a problem. Uncertainty about aggregate shocks (basically uncertainty about the relationship between individual characteristics and earnings) are not measured. But the same is true in structural models. Skill premium variation across U.S. states / cities \u00b6 Dispersion supposedly has decreased. Could one explore empirically possible explanations? This is very open ended without a clear hypothesis or method. Giannone, Elisa. n.d. \u201cSkill-Biased Technical Change and Regional Convergence\u201d","title":"Some Ideas for Honors Thesis Projects #"},{"location":"teaching/honors_thesis_topics.html#some-ideas-for-honors-thesis-projects","text":"This page contains a collection of ideas that may be useful starting points for honors theses. Disclaimer : I haven't thought about these ideas carefully, so they may not be good ideas. Or they may have been done (note the date next to each idea). Or they may not be doable. Or boring, or fundamentally mistaken, or any of the other things that tend to derail research projects. Don't take the ideas as given. Use them to get started thinking about a set of questions. A good thesis topic explores cause and effect (e.g., minimum wages affect unemployment) with some clever identification strategy (e.g., instrumental variables). Most of the topics I am listing here don't fit that pattern. They are really just data descriptions. The reason is that I work with structural models. For the questions that I study, getting answers with data only is usually not possible.","title":"Some Ideas for Honors Thesis Projects"},{"location":"teaching/honors_thesis_topics.html#college","text":"","title":"College"},{"location":"teaching/honors_thesis_topics.html#college-qualities-over-time","text":"Are college qualities highly persistent over time? Do colleges move around in the quality distribution? Which colleges move up and why? Is there a mechanism that \"rewards\" better colleges and forces \"worse\" colleges to exit? Drawbacks: this is descriptive.","title":"College qualities over time"},{"location":"teaching/honors_thesis_topics.html#college-stratification","text":"Hoxby (2009) shows that colleges became more stratified in the 1960s. Her data end in 2006. They are also not publicly available. Moreover, Hoxby's data show that initially highly selective colleges became more selective over time and vice versa. A different, but related, question is: did colleges become more homogeneous? How did the CDF of college \"qualities\" change over time? What happened more recently? Possible data sources: IPEDS (since about 1985) and HERI freshmen surveys. Drawback: this is descriptive.","title":"College Stratification"},{"location":"teaching/honors_thesis_topics.html#cross-country-income-differences","text":"","title":"Cross-country Income Differences"},{"location":"teaching/honors_thesis_topics.html#occupational-downgrading-of-immigrants-2020","text":"Idea: If immigrants from poor countries have less human capital (given schooling), they should be employed in jobs that require less human capital. Those are jobs held by natives with lower schooling. Quantify this: Construct average native schooling by [occupation, industry]. For each source/host pair: compute the average gap between immigrant and native schooling in [occ, ind] cells. This is a measure of occupational downgrading. To what extent is the wage gap between immigrants and similar natives explained by this? Jones (2014) has strong claims about downgrading. How do those hold up?","title":"Occupational downgrading of immigrants (2020)"},{"location":"teaching/honors_thesis_topics.html#the-task-content-of-immigrant-jobs-2020","text":"Todd Schoellman may have done this.","title":"The task content of immigrant jobs (2020)"},{"location":"teaching/honors_thesis_topics.html#inequality","text":"","title":"Inequality"},{"location":"teaching/honors_thesis_topics.html#hsiehklenow-for-immigrants","text":"Hsieh et al 2019 show that women and black men were underrepresented in certain occupations in the 1960s. Over time, the gaps diminished, suggesting that the allocation of talent improved. Is there evidence for a similar convergence among immigrants? Drawback: this is really just a replication of Hsieh et al for a different population group.","title":"Hsieh/Klenow for Immigrants"},{"location":"teaching/honors_thesis_topics.html#sources-of-earnings-shocks-2021","text":"Administrative data show that earnings \"shocks\" are asymmetric (frequent small positive and rare large negative shocks). What observable events are associated with earnings shocks? What fraction of the \"shocks\" are due to employer changes including layoffs occupation changes big changes in hours worked family events (e.g., having children) The goal is to inform how one could model earnings shocks (in structural models). There is a recent paper (for which I cannot find a reference) that does something related using administrative data from a Nordic country. Drawbacks: may be hard to do with publicly available data descriptive","title":"Sources of earnings \"shocks\" (2021)"},{"location":"teaching/honors_thesis_topics.html#how-predictable-are-lifetime-earnings-2020","text":"It is fairly easy to get a lower bound on predictability. Take a panel dataset. Use half to fit a statistical model. Use the other half to perform out of sample prediction. Specification search is a problem. Uncertainty about aggregate shocks (basically uncertainty about the relationship between individual characteristics and earnings) are not measured. But the same is true in structural models.","title":"How predictable are lifetime earnings? (2020)"},{"location":"teaching/honors_thesis_topics.html#skill-premium-variation-across-us-states-cities","text":"Dispersion supposedly has decreased. Could one explore empirically possible explanations? This is very open ended without a clear hypothesis or method. Giannone, Elisa. n.d. \u201cSkill-Biased Technical Change and Regional Convergence\u201d","title":"Skill premium variation across U.S. states / cities"},{"location":"teaching/teaching.html","text":"Undergraduate Teaching \u00b6 Potential topics for honors theses How can undergraduates get involved in research? Current issues in the policy arena Exam tips","title":"Teaching notes"},{"location":"teaching/teaching.html#undergraduate-teaching","text":"Potential topics for honors theses How can undergraduates get involved in research? Current issues in the policy arena Exam tips","title":"Undergraduate Teaching"},{"location":"teaching/undergrad_research.html","text":"How can undergraduates get involved in research? \u00b6 The main organized path for undergraduate research in economics is the senior honors thesis . Aside from the honors thesis, students need to approach faculty members directly and inquire whether they can work on one of the faculty members' projects. This works best if the faculty member already knows the student. For help with this process, please contact the undergraduate research liasion (the economics front office will know who this is at any given time). Also see the notes provided by OUR Summer research fellowships \u00b6 Mayo Summer Research Fellowship for macro SURF Summer University Research Fellowships Guest Summer Research Fellowship for micro. These are announced in late fall, with applications due in March. An additional option is the University work-study program.","title":"How can undergraduates get involved in research?"},{"location":"teaching/undergrad_research.html#how-can-undergraduates-get-involved-in-research","text":"The main organized path for undergraduate research in economics is the senior honors thesis . Aside from the honors thesis, students need to approach faculty members directly and inquire whether they can work on one of the faculty members' projects. This works best if the faculty member already knows the student. For help with this process, please contact the undergraduate research liasion (the economics front office will know who this is at any given time). Also see the notes provided by OUR","title":"How can undergraduates get involved in research?"},{"location":"teaching/undergrad_research.html#summer-research-fellowships","text":"Mayo Summer Research Fellowship for macro SURF Summer University Research Fellowships Guest Summer Research Fellowship for micro. These are announced in late fall, with applications due in March. An additional option is the University work-study program.","title":"Summer research fellowships"},{"location":"thoughts/duplication.html","text":"Thoughts on How Economists Can Avoid Reinventing the Wheel \u00b6 The Problem \u00b6 In writing research papers, economists solve the same problems over and over again. Code Examples Drawing joint Normal random variables with fixed standard deviations (e.g. agents' endowments). Coding common production functions (nested CES). Data Examples Constructing individual histories of earnings / schooling using NLSY / PSID data. Consistently constructing measures of schooling / earnings across year in CPS / Census / ACS data. The list is endless. The Solution \u00b6 Consider what other disciplines do. People who work on numerical math have access to a set of trusted code libraries (BLAS, NLopt, ...). There is a mechanism through which users can contribute to code ( github ) or discuss it (e.g., stackexchange ). Consider the development of the Julia language . All the code libraries live on github . The major packages are moderated by groups who take responsibility for the code's correctness. All code comes with automated tests. The result: Much of the time when users ask questions on how to solve a problem in Julia , someone will simply point to an existing library. Economics needs a similar setup for code and for data. Instead of creating the same variables over and over again from each of the major datasets, there should be a place where the construction of such variables can be discussed and where code for constructing variables can be posted (and trusted). The Organizational Problem \u00b6 Why does this not happen?[^QuantEconFn] Because there is no payoff for individuals to run such an effort. Can this problem be solved? As a small first step, I have started to post reusable code I wrote at github . [^QuantEconFn]: A partial exception is QuantEcon , which is organized by Sargent and Stacchurski. But it is not an open repository.","title":"Avoid reinventing the wheel"},{"location":"thoughts/duplication.html#thoughts-on-how-economists-can-avoid-reinventing-the-wheel","text":"","title":"Thoughts on How Economists Can Avoid Reinventing the Wheel"},{"location":"thoughts/duplication.html#the-problem","text":"In writing research papers, economists solve the same problems over and over again. Code Examples Drawing joint Normal random variables with fixed standard deviations (e.g. agents' endowments). Coding common production functions (nested CES). Data Examples Constructing individual histories of earnings / schooling using NLSY / PSID data. Consistently constructing measures of schooling / earnings across year in CPS / Census / ACS data. The list is endless.","title":"The Problem"},{"location":"thoughts/duplication.html#the-solution","text":"Consider what other disciplines do. People who work on numerical math have access to a set of trusted code libraries (BLAS, NLopt, ...). There is a mechanism through which users can contribute to code ( github ) or discuss it (e.g., stackexchange ). Consider the development of the Julia language . All the code libraries live on github . The major packages are moderated by groups who take responsibility for the code's correctness. All code comes with automated tests. The result: Much of the time when users ask questions on how to solve a problem in Julia , someone will simply point to an existing library. Economics needs a similar setup for code and for data. Instead of creating the same variables over and over again from each of the major datasets, there should be a place where the construction of such variables can be discussed and where code for constructing variables can be posted (and trusted).","title":"The Solution"},{"location":"thoughts/duplication.html#the-organizational-problem","text":"Why does this not happen?[^QuantEconFn] Because there is no payoff for individuals to run such an effort. Can this problem be solved? As a small first step, I have started to post reusable code I wrote at github . [^QuantEconFn]: A partial exception is QuantEcon , which is organized by Sargent and Stacchurski. But it is not an open repository.","title":"The Organizational Problem"},{"location":"thoughts/forums.html","text":"Economics Discussion Forums \u00b6 2020-Aug-9 Wouldn't it be nice if there were a place where economists can pose questions and get help from other economists? Wouldn't that be very helpful for undergraduate and graduate students who are trying to learn economics? But also for researchers who look for data sources, references, methods, ...? For software, online forums of this kind are commonplace. Even experience programmers consult them all the time. For learning new languages, they are essential. Economics needs its own discussion forum. For this to work, the forum must require registration. Posts cannot be anonymous. The discussion must be moderated. Otherwise, we end up with another facebook or twitter. Here are the forums that I know about: EconSpark organized by the AEA registration required, moderated volume is currently quite low Econ StackExchange currently listed as \"beta\" registration required, moderated focused on Q&A, not discussion there is reasonable volume, but questions and answers tend to be basic I found that Debate.org is overrun by spam. It seems to me that StackExchange could be the place to pose specific questions and EconSpark could be the place for more open ended conversations. I propose that we all point our students to those two forums to get some volume going.","title":"Economics discussion forums"},{"location":"thoughts/forums.html#economics-discussion-forums","text":"2020-Aug-9 Wouldn't it be nice if there were a place where economists can pose questions and get help from other economists? Wouldn't that be very helpful for undergraduate and graduate students who are trying to learn economics? But also for researchers who look for data sources, references, methods, ...? For software, online forums of this kind are commonplace. Even experience programmers consult them all the time. For learning new languages, they are essential. Economics needs its own discussion forum. For this to work, the forum must require registration. Posts cannot be anonymous. The discussion must be moderated. Otherwise, we end up with another facebook or twitter. Here are the forums that I know about: EconSpark organized by the AEA registration required, moderated volume is currently quite low Econ StackExchange currently listed as \"beta\" registration required, moderated focused on Q&A, not discussion there is reasonable volume, but questions and answers tend to be basic I found that Debate.org is overrun by spam. It seems to me that StackExchange could be the place to pose specific questions and EconSpark could be the place for more open ended conversations. I propose that we all point our students to those two forums to get some volume going.","title":"Economics Discussion Forums"},{"location":"thoughts/micro_macro.html","text":"Micro Versus Macro \u00b6 Why do macro models look so different from micro models? A caricature: A macro model: Has 7 parameters which are calibrated to match 7 data moments. Has decision rules that only depend on a few state variables. A micro model: Has 700 parameters which are estimated so that the model replicates the complete life histories of everyone in a dataset. All decisions a person ever makes in life are modeled. There are preference shocks everywhere. Decision rules depend on everything the researcher can observe. Why do researchers in the same profession, often studying the same question, write down models that look so different? I think the answer is that applied micro economists view models very differently from macro economists. In macro, a model is a proof of concept . It is a reasonable model with reasonable parameters that demonstrates that a particular mechanism can be big . In micro, a model is a close approximation of the true data generating process (that's why there is so much emphasis on hypothesis testing). The quantitative answers are taken seriously. Last updated: 2016-Dec","title":"Micro versus macro models"},{"location":"thoughts/micro_macro.html#micro-versus-macro","text":"Why do macro models look so different from micro models? A caricature: A macro model: Has 7 parameters which are calibrated to match 7 data moments. Has decision rules that only depend on a few state variables. A micro model: Has 700 parameters which are estimated so that the model replicates the complete life histories of everyone in a dataset. All decisions a person ever makes in life are modeled. There are preference shocks everywhere. Decision rules depend on everything the researcher can observe. Why do researchers in the same profession, often studying the same question, write down models that look so different? I think the answer is that applied micro economists view models very differently from macro economists. In macro, a model is a proof of concept . It is a reasonable model with reasonable parameters that demonstrates that a particular mechanism can be big . In micro, a model is a close approximation of the true data generating process (that's why there is so much emphasis on hypothesis testing). The quantitative answers are taken seriously. Last updated: 2016-Dec","title":"Micro Versus Macro"},{"location":"thoughts/models_beliefs.html","text":"Models and Beliefs \u00b6 I propose the hypothesis: It is very rare for models to change beliefs about reality. We (researchers) spend a rather large amount of time on structural models. Especially on getting quantitative answers out of them. Do the answers we get have much of an impact on what people believe about reality. I think the answer is \"no\". I am familiar with research on economic growth, cross-country income differences, and wealth distribution. Consider the basic questions from that literature. Why Are Some Countries Rich and Others Poor? \u00b6 Our current understanding seems alarmingly similar to that of 1996, when I got my degree. Capital is probably not important. I'm not sure we have a very good reason for believing this (see Caselli's JEL survey). Human capital: we don't know. Quantitative models are all over the place. Even if they weren't, I don't think anyone would take them very seriously. Immigrant earnings point in one direction (Hendricks 2002), but then maybe not (Hendricks and Schoellman 2016). TFP is probably important. But then we knew that back in the 1960s. Lots of research has changed beliefs very little. Why? Because we don't have clear evidence that we can interpret without a model. As for deep causes , most researchers probably believe that institutions are important. I would argue that this belief has not changed much over time. It has been supported by clever empirical papers (Acemoglu et al.). That work has changed beliefs. Notably, it is purely empirical, supported by a coherent historical narrative. Why Do Countries Grow? \u00b6 We don't really know anything about this. We like to write down \"R&D\" models, but that seems to have more to do with prejudice than with evidence. Is there any evidence to support that \"R&D\" is really what drives growth? It's probably true, but I say this because of my intuitive understanding of how the world works, not because of evidence. Why Do Some Households Hold Lots of Wealth? \u00b6 Here is a case where a model probably did change beliefs (Huggett 1996). I think this worked because households don't do very much in that model. We have a bunch of candidate solutions for generating high wealth holdings (inheritances and entrepreneurship are probably the leading candidates). How important these are is still not settled. Most researchers probably believe that entrepreneurship is important. But then this is somewhat obvious from looking at the data. I don't think that models did much to generate this belief. Implications \u00b6 If models don't change beliefs, then we are probably wasting a lot of time in macro research. Perhaps the old-fashioned approach of showing correlations (e.g., OLS regressions) and offering a coherent interpretation is underrated. Last updated: 2016-Dec","title":"Models and beliefs"},{"location":"thoughts/models_beliefs.html#models-and-beliefs","text":"I propose the hypothesis: It is very rare for models to change beliefs about reality. We (researchers) spend a rather large amount of time on structural models. Especially on getting quantitative answers out of them. Do the answers we get have much of an impact on what people believe about reality. I think the answer is \"no\". I am familiar with research on economic growth, cross-country income differences, and wealth distribution. Consider the basic questions from that literature.","title":"Models and Beliefs"},{"location":"thoughts/models_beliefs.html#why-are-some-countries-rich-and-others-poor","text":"Our current understanding seems alarmingly similar to that of 1996, when I got my degree. Capital is probably not important. I'm not sure we have a very good reason for believing this (see Caselli's JEL survey). Human capital: we don't know. Quantitative models are all over the place. Even if they weren't, I don't think anyone would take them very seriously. Immigrant earnings point in one direction (Hendricks 2002), but then maybe not (Hendricks and Schoellman 2016). TFP is probably important. But then we knew that back in the 1960s. Lots of research has changed beliefs very little. Why? Because we don't have clear evidence that we can interpret without a model. As for deep causes , most researchers probably believe that institutions are important. I would argue that this belief has not changed much over time. It has been supported by clever empirical papers (Acemoglu et al.). That work has changed beliefs. Notably, it is purely empirical, supported by a coherent historical narrative.","title":"Why Are Some Countries Rich and Others Poor?"},{"location":"thoughts/models_beliefs.html#why-do-countries-grow","text":"We don't really know anything about this. We like to write down \"R&D\" models, but that seems to have more to do with prejudice than with evidence. Is there any evidence to support that \"R&D\" is really what drives growth? It's probably true, but I say this because of my intuitive understanding of how the world works, not because of evidence.","title":"Why Do Countries Grow?"},{"location":"thoughts/models_beliefs.html#why-do-some-households-hold-lots-of-wealth","text":"Here is a case where a model probably did change beliefs (Huggett 1996). I think this worked because households don't do very much in that model. We have a bunch of candidate solutions for generating high wealth holdings (inheritances and entrepreneurship are probably the leading candidates). How important these are is still not settled. Most researchers probably believe that entrepreneurship is important. But then this is somewhat obvious from looking at the data. I don't think that models did much to generate this belief.","title":"Why Do Some Households Hold Lots of Wealth?"},{"location":"thoughts/models_beliefs.html#implications","text":"If models don't change beliefs, then we are probably wasting a lot of time in macro research. Perhaps the old-fashioned approach of showing correlations (e.g., OLS regressions) and offering a coherent interpretation is underrated. Last updated: 2016-Dec","title":"Implications"},{"location":"thoughts/quantitative_models.html","text":"The Question of Simple Models and Little Data \u00b6 For some time, I have been wondering why many highly competent authors in quantitative economics work with very stylized models and with very limited data. Examples: \u00b6 Hsieh/Hurst/Jones/Klenow (Econometrica, forthcoming) could use panel data to get a better idea of individuals' comparative advantage for particular occupations. Lagakos/Waugh (AER) could use panel data to see whether urban/rural migrants experience large wage gains (similar to Glazer/Mare using US data). An extreme example: Manuelli/Seshadri (AER) use essentially no data at all. Could one not pin down key model parameters, such as \"the elasticity\" in Manuelly/Seshadri, more precisely with more/better data? One possible resolution of the puzzle: these papers really point out the possibility that a particular cause-effect mechanism could be empirically important. To do so, they write down a simple model and calibrate it in a simple way. The point being made would then be rather limited: one can write down a non-nonsensical model and stick in non-nonsensical parameter values and find that the mechanism under study is \"big.\" Of course, this is not the way the papers are written. They typically contain quantitative statements, such as \"the entire rise in the US college wage premium can be accounted for by the changing relative abilities of college graduates\" (Hendricks/Schoellman, JME 2014; to point a finger at myself). An innocent reader (like myself, until recently) might take the quantitative results at face value. But then it is puzzling that the models so stylized and that not more data are used to discipline them. But then: if the papers merely point out a possibility, this puzzle is resolved. Perhaps, the authors understand that possibilities are all we can get from quantitative models. So we might as well proceed with simple examples instead of complicated models and detailed data. But then we have a major problem: quantitative economics is then limited to accumulating potentially important explanations for what we observe. In many cases, the number of explanations is quite large. Take the case of cross-country income gaps. If we add up the fractions explained by physical capital, human capital, misallocation, capital import frictions, etc., we end up explaining the observed income gaps many times over. Something seems fundamentally wrong here.","title":"On simple models calibrated using little data"},{"location":"thoughts/quantitative_models.html#the-question-of-simple-models-and-little-data","text":"For some time, I have been wondering why many highly competent authors in quantitative economics work with very stylized models and with very limited data.","title":"The Question of Simple Models and Little Data"},{"location":"thoughts/quantitative_models.html#examples","text":"Hsieh/Hurst/Jones/Klenow (Econometrica, forthcoming) could use panel data to get a better idea of individuals' comparative advantage for particular occupations. Lagakos/Waugh (AER) could use panel data to see whether urban/rural migrants experience large wage gains (similar to Glazer/Mare using US data). An extreme example: Manuelli/Seshadri (AER) use essentially no data at all. Could one not pin down key model parameters, such as \"the elasticity\" in Manuelly/Seshadri, more precisely with more/better data? One possible resolution of the puzzle: these papers really point out the possibility that a particular cause-effect mechanism could be empirically important. To do so, they write down a simple model and calibrate it in a simple way. The point being made would then be rather limited: one can write down a non-nonsensical model and stick in non-nonsensical parameter values and find that the mechanism under study is \"big.\" Of course, this is not the way the papers are written. They typically contain quantitative statements, such as \"the entire rise in the US college wage premium can be accounted for by the changing relative abilities of college graduates\" (Hendricks/Schoellman, JME 2014; to point a finger at myself). An innocent reader (like myself, until recently) might take the quantitative results at face value. But then it is puzzling that the models so stylized and that not more data are used to discipline them. But then: if the papers merely point out a possibility, this puzzle is resolved. Perhaps, the authors understand that possibilities are all we can get from quantitative models. So we might as well proceed with simple examples instead of complicated models and detailed data. But then we have a major problem: quantitative economics is then limited to accumulating potentially important explanations for what we observe. In many cases, the number of explanations is quite large. Take the case of cross-country income gaps. If we add up the fractions explained by physical capital, human capital, misallocation, capital import frictions, etc., we end up explaining the observed income gaps many times over. Something seems fundamentally wrong here.","title":"Examples:"},{"location":"thoughts/specialization.html","text":"Specialization (or the Lack Thereof) \u00b6 Researchers in other disciplines are highly specialized. Economists are not. This is inefficient. In Biology, someone may spend 20 years studying Red Ants in East Africa. It would by unthinkable for that person to suddenly write a paper on Emperor Penguins. In economics, the analogous behavior is entirely common. People write on topics they don't know anything about. And nobody thinks this is odd. As a referee, I commonly encounter authors that appear not to understand or not to be familiar with the literature. This is one cost of the lack of specialization. Another cost is duplication of effort. If an author wants to work with a particular dataset, he/she typically just figures out how that dataset \"works.\" This leads to mistakes and it wastes time. We need authors that specialize in specific datasets. Similarly, very few economists know how to write reasonable computer code. Having looked at quite a few examples of programs underlying published papers, I find: Spagetti code: single functions with over 1,000 lines of non-trivial code. No evidence that the code has been tested. Globals are used to set parameters. No easy way of swapping out model elements, even though a typical paper solves many different versions of a model. Little useful documentation. Essentially no general purpose code is used. Essentially no code is used that was written by someone else. In other words, most economists violate all the guidelines one would typically learn in Programming 101. Most code that is written is likely wrong. We need authors who specialize in programming. Consider again how other disciplines work. As an extreme example, experimental physics employs a wide variety of specialists (engineers, programmers, machine shop workers, etc). This makes it possible to run very complex projects, such as particle beam colliders. Economists do nothing of remotely similar complexity. We need to specialize.","title":"Economists need to specialize"},{"location":"thoughts/specialization.html#specialization-or-the-lack-thereof","text":"Researchers in other disciplines are highly specialized. Economists are not. This is inefficient. In Biology, someone may spend 20 years studying Red Ants in East Africa. It would by unthinkable for that person to suddenly write a paper on Emperor Penguins. In economics, the analogous behavior is entirely common. People write on topics they don't know anything about. And nobody thinks this is odd. As a referee, I commonly encounter authors that appear not to understand or not to be familiar with the literature. This is one cost of the lack of specialization. Another cost is duplication of effort. If an author wants to work with a particular dataset, he/she typically just figures out how that dataset \"works.\" This leads to mistakes and it wastes time. We need authors that specialize in specific datasets. Similarly, very few economists know how to write reasonable computer code. Having looked at quite a few examples of programs underlying published papers, I find: Spagetti code: single functions with over 1,000 lines of non-trivial code. No evidence that the code has been tested. Globals are used to set parameters. No easy way of swapping out model elements, even though a typical paper solves many different versions of a model. Little useful documentation. Essentially no general purpose code is used. Essentially no code is used that was written by someone else. In other words, most economists violate all the guidelines one would typically learn in Programming 101. Most code that is written is likely wrong. We need authors who specialize in programming. Consider again how other disciplines work. As an extreme example, experimental physics employs a wide variety of specialists (engineers, programmers, machine shop workers, etc). This makes it possible to run very complex projects, such as particle beam colliders. Economists do nothing of remotely similar complexity. We need to specialize.","title":"Specialization (or the Lack Thereof)"}]}