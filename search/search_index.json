{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Lutz Hendricks Associate Professor of Economics UNC Chapel Hill 06C Gardner Hall Chapel Hill, NC 27599 hendricksl at protonmail.com Teaching Spring 2021 \u00b6 Econ520 Advanced Macroeconomic Theory Econ890 Graduate field course on income and wealth inequality. Office hours: MW 3:45-4:45pm Due to Covid, office hours will be held online only. I encourage students to make appointments. Zoom information is shown in the sakai course site. Teaching Fall 2020 \u00b6 Econ720 : Advanced Macro Theory I (PhD) Notes \u00b6 I do not have openings for research positions at any level. This is my professional web site. Personal content is posted elsewhere. I do not have social media accounts (especially not Fakebook, SnapCheat, InstaScam, or Twister).","title":"Home"},{"location":"index.html#teaching-spring-2021","text":"Econ520 Advanced Macroeconomic Theory Econ890 Graduate field course on income and wealth inequality. Office hours: MW 3:45-4:45pm Due to Covid, office hours will be held online only. I encourage students to make appointments. Zoom information is shown in the sakai course site.","title":"Teaching Spring 2021"},{"location":"index.html#teaching-fall-2020","text":"Econ720 : Advanced Macro Theory I (PhD)","title":"Teaching Fall 2020"},{"location":"index.html#notes","text":"I do not have openings for research positions at any level. This is my professional web site. Personal content is posted elsewhere. I do not have social media accounts (especially not Fakebook, SnapCheat, InstaScam, or Twister).","title":"Notes"},{"location":"inactive_link.html","text":"{{markdown_header.txt}} This link is not yet active. If you think the link is broken, please report to Lutz Hendricks.","title":"Inactive link"},{"location":"test.html","text":"First Header Second Header Third Header Content Cell Content Cell Content Cell Content Cell Content Cell Content Cell","title":"Test"},{"location":"Research/computer_code.html","text":"Computer Code \u00b6 Notes on the Julia language . The purpose is to document solutions that I could not find in the Julia documentation. Updated periodically. My github repo contains code for recent projects. Newer code is written in Julia. Pre-2019 code is written in Matlab. The shared repo contains general purpose Matlab code. This is no longer updated. Making this code available is a small attempt at reducing duplication, given that economics lacks a code archive . Feel free to use my code in your research (with attribution, where appropriate). Related material: General notes on programming and Matlab Spring 2016 Econ821 course Replication code for Manuelli and Seshadri, \"Human Capital and the Wealth of Nations\", AER 2014 (Their original code as published on the AER web site contains a substantial error. The authors have confirmed this to me.) External Links \u00b6 Chris Carroll's notes on dynamic programming","title":"Computer code"},{"location":"Research/computer_code.html#computer-code","text":"Notes on the Julia language . The purpose is to document solutions that I could not find in the Julia documentation. Updated periodically. My github repo contains code for recent projects. Newer code is written in Julia. Pre-2019 code is written in Matlab. The shared repo contains general purpose Matlab code. This is no longer updated. Making this code available is a small attempt at reducing duplication, given that economics lacks a code archive . Feel free to use my code in your research (with attribution, where appropriate). Related material: General notes on programming and Matlab Spring 2016 Econ821 course Replication code for Manuelli and Seshadri, \"Human Capital and the Wealth of Nations\", AER 2014 (Their original code as published on the AER web site contains a substantial error. The authors have confirmed this to me.)","title":"Computer Code"},{"location":"Research/computer_code.html#external-links","text":"Chris Carroll's notes on dynamic programming","title":"External Links"},{"location":"Research/project_ideas.html","text":"{{../markdown_header.txt}} Some Ideas for Dissertation Projects \u00b6 This page contains a collection of ideas that may be useful for getting started on dissertation research. Talk to me if any of these sound interesting. Disclaimer : I haven't thought about these ideas carefully, so they may not be good ideas. Or they may have been done (note the date next to each idea). Or they may not be doable. Or boring, or fundamentally mistaken, or any of the other things that tend to derail research projects. Don't take the ideas as given. Use them to get started thinking about a set of questions. Some general tips for getting started with a dissertation are here . Human Capital \u00b6 Why did schooling stop rising in 1950? (10/08) \u00b6 U.S. educational attainment rose smoothly from at least 1900 to 1950. Then it stopped rising. Why? And why did schooling rise in the first place (some recent papers offer answers, but do I believe them?)? The Ag/Non-Ag or Urban-Rural Wage Gap ## (2015-05) \u00b6 Wages in non-ag are double those in ag. Wages in cities are higher than in villages (by how much?). Some papers suggest reasons. For example, Lagakos and Waugh (2013 AER) argue that selection is important. But nobody seems to use much data to study these questions. To me, this calls for panel data. One could observe the wage changes as a given person migrates from ag to non-ag. Taxation with risky human capital (6/01) \u00b6 A large literature studies how human capital responds to taxation. Almost all of this literature abstracts from most uncertainty (about earnings etc.). It seems obvious that this abstraction should lead to overstated tax effects (use the intuition from portfolio choice). It would be useful to quantify how large that bias is. This would require embedding realistic earnings uncertainty into a standard life-cycle model with schooling and job-training. It would also be nice to have some analytical results about the effect of uncertainty on tax elasticities in simpler models. A word of caution: There are a couple of papers looking at human capital under uncertainty, though it seems nobody has looked at this particular question. This needs to be checked, though. Why is schooling lumpy? (12/07) \u00b6 In virtually all theories of human capital, years of schooling are a continuous choice. In the data, the choice is lumpy (high school graduate or dropout). Why is schooling lumpy? Why is there a big (presumably permanent) earnings penalty for dropping out of college after 3 years with a good GPA? What can be learned about how human capital is produced and valued in the market? Does this have to do with the fact that grades are a noisy signal of ability? Why is grade completion a better signal?","title":"Project ideas"},{"location":"Research/project_ideas.html#some-ideas-for-dissertation-projects","text":"This page contains a collection of ideas that may be useful for getting started on dissertation research. Talk to me if any of these sound interesting. Disclaimer : I haven't thought about these ideas carefully, so they may not be good ideas. Or they may have been done (note the date next to each idea). Or they may not be doable. Or boring, or fundamentally mistaken, or any of the other things that tend to derail research projects. Don't take the ideas as given. Use them to get started thinking about a set of questions. Some general tips for getting started with a dissertation are here .","title":"Some Ideas for Dissertation Projects"},{"location":"Research/project_ideas.html#human-capital","text":"","title":"Human Capital"},{"location":"Research/project_ideas.html#why-did-schooling-stop-rising-in-1950-1008","text":"U.S. educational attainment rose smoothly from at least 1900 to 1950. Then it stopped rising. Why? And why did schooling rise in the first place (some recent papers offer answers, but do I believe them?)?","title":"Why did schooling stop rising in 1950? (10/08)"},{"location":"Research/project_ideas.html#the-agnon-ag-or-urban-rural-wage-gap-2015-05","text":"Wages in non-ag are double those in ag. Wages in cities are higher than in villages (by how much?). Some papers suggest reasons. For example, Lagakos and Waugh (2013 AER) argue that selection is important. But nobody seems to use much data to study these questions. To me, this calls for panel data. One could observe the wage changes as a given person migrates from ag to non-ag.","title":"The Ag/Non-Ag or Urban-Rural Wage Gap ## (2015-05)"},{"location":"Research/project_ideas.html#taxation-with-risky-human-capital-601","text":"A large literature studies how human capital responds to taxation. Almost all of this literature abstracts from most uncertainty (about earnings etc.). It seems obvious that this abstraction should lead to overstated tax effects (use the intuition from portfolio choice). It would be useful to quantify how large that bias is. This would require embedding realistic earnings uncertainty into a standard life-cycle model with schooling and job-training. It would also be nice to have some analytical results about the effect of uncertainty on tax elasticities in simpler models. A word of caution: There are a couple of papers looking at human capital under uncertainty, though it seems nobody has looked at this particular question. This needs to be checked, though.","title":"Taxation with risky human capital (6/01)"},{"location":"Research/project_ideas.html#why-is-schooling-lumpy-1207","text":"In virtually all theories of human capital, years of schooling are a continuous choice. In the data, the choice is lumpy (high school graduate or dropout). Why is schooling lumpy? Why is there a big (presumably permanent) earnings penalty for dropping out of college after 3 years with a good GPA? What can be learned about how human capital is produced and valued in the market? Does this have to do with the fact that grades are a noisy signal of ability? Why is grade completion a better signal?","title":"Why is schooling lumpy? (12/07)"},{"location":"Research/research.html","text":"Research: Human Capital \u00b6 Current working papers \u00b6 Selective College Admissions: Implications for Equity and Efficiency \u00b6 With Oksana Leukhina and Tatyana Koreshkova . Paper coming soon. Skilled Labor Productivity and Cross-country Income Differences \u00b6 With Todd Schoellman . Slides Accounting for the Evolution of U.S. Wage Inequality [soin] \u00b6 2013-May-10. Bibtex citation Publications \u00b6 College Quality and Attendance Patterns: A Long-run View \u00b6 With Chris Herrington and Todd Schoellman | American Economic Journal - Macroeconomics, 2021 . Bibtex entry Summary in \"The Region\" Human Capital and Development Accounting: New Evidence From Immigrant Earnings \u00b6 With Todd Schoellman , QJE , 2018 | Bibtex entry The Return to College: Selection and Dropout Risk \u00b6 With Oksana Leukhina | 2018, International Economic Review | Online Appendix | Bibtex citation How Risky Is College Investment? \u00b6 With Oksana Leukhina | 2017, Review of Economic Dynamics | Bibtex citation Student Abilities During the Expansion of U.S. Education [ability] \u00b6 With Todd Schoellman . Journal of Monetary Economics , 36: 19-36, 2014. Appendix . Bibtex citation Cross-country Variation in Educational Attainment: Structural Change or Within Industry Skill Upgrading? [hdind] \u00b6 Journal of Economic Growth 15(3), 2010. Bibtex citation . IPUMS Validation paper . Mapping from country specific to detailed industries . The Skill Composition of U.S. Cities [hc_cities] \u00b6 International Economic Review 52(1): 1-32, 2011. Bibtex citation Previous title: Educational attainment in U.S. cities. Taxation and Human Capital Accumulation \u00b6 Macroeconomic Dynamics 2004, 8(3) Paper . Bibtex citation Taxation and the Intergenerational Transmission of Human Capital \u00b6 Journal of Economics Dynamics and Control 2003, 27(9): 1639-1662. Paper . Bibtex citation How Important is Human Capital for Development? Evidence from Immigrant Earnings \u00b6 American Economic Review 2002, 92(1): 198-219. Bibtex citation . Technical Appendix . Data table with Mincer regressions and other source country data (MS Excel format). How Do Taxes Affect Human Capital? The Role of Intergenerational Mobility [hctax] \u00b6 Review of Economic Dynamics 2001, 4(3): 695-735. Technical Appendix | Bibtex citation Growth, Death, and Taxes [gdtax] \u00b6 Review of Economic Dynamics 2001, 4(1): 26-57. Bibtex citation Taxation and Long-Run Growth \u00b6 Journal of Monetary Economics , 1999, (43)2: 411-434. Bibtex citation The Technical Appendix contains details on computation and analytics. Program files are available in the following zip files: Main program files Shared program files Older working papers \u00b6 The Ben-Porath Model and Age-wage Profiles [ojttech] \u00b6 2012-Nov-27. Bibtex citation The Evolution of U.S. Wages: Skill Prices versus Human Capital \u00b6 2012-Feb-23. Bibtex citation Why Does Education Differ Across Countries? [scd_paper] \u00b6 Paper (First draft: March 2005). Bibtex citation Discussions \u00b6 MisMatch in Human Capital Accumulation","title":"Human capital"},{"location":"Research/research.html#research-human-capital","text":"","title":"Research: Human Capital"},{"location":"Research/research.html#current-working-papers","text":"","title":"Current working papers"},{"location":"Research/research.html#selective-college-admissions-implications-for-equity-and-efficiency","text":"With Oksana Leukhina and Tatyana Koreshkova . Paper coming soon.","title":"Selective College Admissions: Implications for Equity and Efficiency"},{"location":"Research/research.html#skilled-labor-productivity-and-cross-country-income-differences","text":"With Todd Schoellman . Slides","title":"Skilled Labor Productivity and Cross-country Income Differences"},{"location":"Research/research.html#accounting-for-the-evolution-of-us-wage-inequality-soin","text":"2013-May-10. Bibtex citation","title":"Accounting for the Evolution of U.S. Wage Inequality [soin]"},{"location":"Research/research.html#publications","text":"","title":"Publications"},{"location":"Research/research.html#college-quality-and-attendance-patterns-a-long-run-view","text":"With Chris Herrington and Todd Schoellman | American Economic Journal - Macroeconomics, 2021 . Bibtex entry Summary in \"The Region\"","title":"College Quality and Attendance Patterns: A Long-run View"},{"location":"Research/research.html#human-capital-and-development-accounting-new-evidence-from-immigrant-earnings","text":"With Todd Schoellman , QJE , 2018 | Bibtex entry","title":"Human Capital and Development Accounting: New Evidence From Immigrant Earnings"},{"location":"Research/research.html#the-return-to-college-selection-and-dropout-risk","text":"With Oksana Leukhina | 2018, International Economic Review | Online Appendix | Bibtex citation","title":"The Return to College: Selection and Dropout Risk"},{"location":"Research/research.html#how-risky-is-college-investment","text":"With Oksana Leukhina | 2017, Review of Economic Dynamics | Bibtex citation","title":"How Risky Is College Investment?"},{"location":"Research/research.html#student-abilities-during-the-expansion-of-us-education-ability","text":"With Todd Schoellman . Journal of Monetary Economics , 36: 19-36, 2014. Appendix . Bibtex citation","title":"Student Abilities During the Expansion of U.S. Education [ability]"},{"location":"Research/research.html#cross-country-variation-in-educational-attainment-structural-change-or-within-industry-skill-upgrading-hdind","text":"Journal of Economic Growth 15(3), 2010. Bibtex citation . IPUMS Validation paper . Mapping from country specific to detailed industries .","title":"Cross-country Variation in Educational Attainment: Structural Change or Within Industry Skill Upgrading? [hdind]"},{"location":"Research/research.html#the-skill-composition-of-us-cities-hc_cities","text":"International Economic Review 52(1): 1-32, 2011. Bibtex citation Previous title: Educational attainment in U.S. cities.","title":"The Skill Composition of U.S. Cities [hc_cities]"},{"location":"Research/research.html#taxation-and-human-capital-accumulation","text":"Macroeconomic Dynamics 2004, 8(3) Paper . Bibtex citation","title":"Taxation and Human Capital Accumulation"},{"location":"Research/research.html#taxation-and-the-intergenerational-transmission-of-human-capital","text":"Journal of Economics Dynamics and Control 2003, 27(9): 1639-1662. Paper . Bibtex citation","title":"Taxation and the Intergenerational Transmission of Human Capital"},{"location":"Research/research.html#how-important-is-human-capital-for-development-evidence-from-immigrant-earnings","text":"American Economic Review 2002, 92(1): 198-219. Bibtex citation . Technical Appendix . Data table with Mincer regressions and other source country data (MS Excel format).","title":"How Important is Human Capital for Development? Evidence from Immigrant Earnings"},{"location":"Research/research.html#how-do-taxes-affect-human-capital-the-role-of-intergenerational-mobility-hctax","text":"Review of Economic Dynamics 2001, 4(3): 695-735. Technical Appendix | Bibtex citation","title":"How Do Taxes Affect Human Capital? The Role of Intergenerational Mobility [hctax]"},{"location":"Research/research.html#growth-death-and-taxes-gdtax","text":"Review of Economic Dynamics 2001, 4(1): 26-57. Bibtex citation","title":"Growth, Death, and Taxes [gdtax]"},{"location":"Research/research.html#taxation-and-long-run-growth","text":"Journal of Monetary Economics , 1999, (43)2: 411-434. Bibtex citation The Technical Appendix contains details on computation and analytics. Program files are available in the following zip files: Main program files Shared program files","title":"Taxation and Long-Run Growth"},{"location":"Research/research.html#older-working-papers","text":"","title":"Older working papers"},{"location":"Research/research.html#the-ben-porath-model-and-age-wage-profiles-ojttech","text":"2012-Nov-27. Bibtex citation","title":"The Ben-Porath Model and Age-wage Profiles [ojttech]"},{"location":"Research/research.html#the-evolution-of-us-wages-skill-prices-versus-human-capital","text":"2012-Feb-23. Bibtex citation","title":"The Evolution of U.S. Wages: Skill Prices versus Human Capital"},{"location":"Research/research.html#why-does-education-differ-across-countries-scd_paper","text":"Paper (First draft: March 2005). Bibtex citation","title":"Why Does Education Differ Across Countries? [scd_paper]"},{"location":"Research/research.html#discussions","text":"MisMatch in Human Capital Accumulation","title":"Discussions"},{"location":"Research/research_other.html","text":"Wealth Distribution \u00b6 Retirement wealth and lifetime earnings \u00b6 International Economic Review , 2007, 48(2): 421-56. Bibtex citation How Important Is Discount Rate Heterogeneity for Wealth Inequality? \u00b6 Journal of Economic Dynamics & Control , 2007, 31(9): 3042-68. Bibtex citation Intended and Accidental Bequests in a Life-cycle Economy \u00b6 This paper studies quantitative importance of accidental versus intended bequests. The main finding is that accidental bequests account for at least half, and perhaps for all of observed bequests. Paper [First draft: August 2001] Bequests and Retirement Wealth in U.S. Data \u00b6 This is a background paper for \u201cIntended and Accidental Bequests in a Life-cycle Economy.\u201d It documents bequests and retirement wealth in the SCF and the PSID. Paper | Tables Other Topics \u00b6 Accounting for Changing Returns to Experience \u00b6 BEJM 2018 . Proposes a simple model with time-invariant age-efficiency profiles to account for changing returns to experience in CPS data. Paper | Bibtex citation | Code and additional results Constructing Age-Earnings Profiles From CPS Data \u00b6 Describes procedures for constructing age-wage profiles from March CPS data. Intended as documentation for the data used in several of my projects. The code is available on github . Paper | Bibtex entry Validation of IPUMS International Industry and Education Data \u00b6 This document collects validation information for selected samples of the IPUMS International dataset. The focus is on industry and education data. Paper (2010-Feb) The Intergenerational Persistence of Lifetime Earnings \u00b6 European Economic Review , 2007, 51: 125-44.","title":"Other topics"},{"location":"Research/research_other.html#wealth-distribution","text":"","title":"Wealth Distribution"},{"location":"Research/research_other.html#retirement-wealth-and-lifetime-earnings","text":"International Economic Review , 2007, 48(2): 421-56. Bibtex citation","title":"Retirement wealth and lifetime earnings"},{"location":"Research/research_other.html#how-important-is-discount-rate-heterogeneity-for-wealth-inequality","text":"Journal of Economic Dynamics & Control , 2007, 31(9): 3042-68. Bibtex citation","title":"How Important Is Discount Rate Heterogeneity for Wealth Inequality?"},{"location":"Research/research_other.html#intended-and-accidental-bequests-in-a-life-cycle-economy","text":"This paper studies quantitative importance of accidental versus intended bequests. The main finding is that accidental bequests account for at least half, and perhaps for all of observed bequests. Paper [First draft: August 2001]","title":"Intended and Accidental Bequests in a Life-cycle Economy"},{"location":"Research/research_other.html#bequests-and-retirement-wealth-in-us-data","text":"This is a background paper for \u201cIntended and Accidental Bequests in a Life-cycle Economy.\u201d It documents bequests and retirement wealth in the SCF and the PSID. Paper | Tables","title":"Bequests and Retirement Wealth in U.S. Data"},{"location":"Research/research_other.html#other-topics","text":"","title":"Other Topics"},{"location":"Research/research_other.html#accounting-for-changing-returns-to-experience","text":"BEJM 2018 . Proposes a simple model with time-invariant age-efficiency profiles to account for changing returns to experience in CPS data. Paper | Bibtex citation | Code and additional results","title":"Accounting for Changing Returns to Experience"},{"location":"Research/research_other.html#constructing-age-earnings-profiles-from-cps-data","text":"Describes procedures for constructing age-wage profiles from March CPS data. Intended as documentation for the data used in several of my projects. The code is available on github . Paper | Bibtex entry","title":"Constructing Age-Earnings Profiles From CPS Data"},{"location":"Research/research_other.html#validation-of-ipums-international-industry-and-education-data","text":"This document collects validation information for selected samples of the IPUMS International dataset. The focus is on industry and education data. Paper (2010-Feb)","title":"Validation of IPUMS International Industry and Education Data"},{"location":"Research/research_other.html#the-intergenerational-persistence-of-lifetime-earnings","text":"European Economic Review , 2007, 51: 125-44.","title":"The Intergenerational Persistence of Lifetime Earnings"},{"location":"econ520/econ520.html","text":"Econ520 - Advanced Macroeconomic Theory \u00b6 Spring 2021 - Prof. Lutz Hendricks \u00b6 Announcements \u00b6 Debate on the minimum wage by UNC faculty members. On 4/19 at 5pm via zoom. The zoom link for office hours (and for class recordings) is on sakai. Feb-23: I made a list of useful sources for your term paper. Feb-22: Since someone is always in quarantine these days, I plan to record future class meetings and post them on sakai. But please do not take this as an invitation to skip classes. This is still an in person class! A related note: I goofed with the Feb-17 recording. Sorry about that. Jan-21: I created a sakai site to post material that should not be visible to the public. Jan-19: The class is full. Waitlists are centralized this year. Please contact the director of undergraduate studies, Geetha Vaidyanathan. If you want to follow class meetings while you are on the waitlist, please contact me for a zoom link. In person classes begin Feb. 8 Important: you must have passed Intermediate Macroeconomics to register for this course. Slides will be updated as the course progresses. Final exam: May 14 at noon Notes on the midterm \u00b6 March 10, in class. Material covered: through Romer model (we did not get far enough to cover the Inequality material). If you miss the midterm for a valid reason (see Covid related absences ), you are entitled to a make-up exam. Alternatively, we can adjust the weight of the final and term paper. The exam will contain a combination of conceptual questions and model applications. See exams from previous years . Links \u00b6 Schedule Syllabus Math review problems - these are useful to remind yourself of some math that we will use. Tips for taking exams","title":"Econ520"},{"location":"econ520/econ520.html#econ520-advanced-macroeconomic-theory","text":"","title":"Econ520 - Advanced Macroeconomic Theory"},{"location":"econ520/econ520.html#spring-2021-prof-lutz-hendricks","text":"","title":"Spring 2021 - Prof. Lutz Hendricks"},{"location":"econ520/econ520.html#announcements","text":"Debate on the minimum wage by UNC faculty members. On 4/19 at 5pm via zoom. The zoom link for office hours (and for class recordings) is on sakai. Feb-23: I made a list of useful sources for your term paper. Feb-22: Since someone is always in quarantine these days, I plan to record future class meetings and post them on sakai. But please do not take this as an invitation to skip classes. This is still an in person class! A related note: I goofed with the Feb-17 recording. Sorry about that. Jan-21: I created a sakai site to post material that should not be visible to the public. Jan-19: The class is full. Waitlists are centralized this year. Please contact the director of undergraduate studies, Geetha Vaidyanathan. If you want to follow class meetings while you are on the waitlist, please contact me for a zoom link. In person classes begin Feb. 8 Important: you must have passed Intermediate Macroeconomics to register for this course. Slides will be updated as the course progresses. Final exam: May 14 at noon","title":"Announcements"},{"location":"econ520/econ520.html#notes-on-the-midterm","text":"March 10, in class. Material covered: through Romer model (we did not get far enough to cover the Inequality material). If you miss the midterm for a valid reason (see Covid related absences ), you are entitled to a make-up exam. Alternatively, we can adjust the weight of the final and term paper. The exam will contain a combination of conceptual questions and model applications. See exams from previous years .","title":"Notes on the midterm"},{"location":"econ520/econ520.html#links","text":"Schedule Syllabus Math review problems - these are useful to remind yourself of some math that we will use. Tips for taking exams","title":"Links"},{"location":"econ520/schedule520.html","text":"Special dates \u00b6 Feb-15 (Mon): Wellness day Mar-10 (Wed): Midterm: Material covered: TBA Apr-05 (Mon): Wellness day Economic Growth \u00b6 Jan-20 (Wed): Growth facts , In case you need a refresher: Growth rates and logarithms , PP (practice problems; previous exams are at the bottom of the page) Jan-25 (Mon): Methods for identifying causes and effects Jan-27 (Wed): The Role of Capital , PP Feb-01 (Mon): The Role of Capital, part 2 Feb-03 (Wed): Solow model Feb-08 (Mon): Solow diagram , PP Feb-10 (Wed): Solow Applications , Applications, part 2 Feb-17 (Wed): Discussion: How to prevent the end of economic growth Feb-22 (Mon): Institutions , PP Feb-24 (Wed): Growth and ideas Mar-01 (Mon): Romer model , PP Policy implications Inequality \u00b6 Mar-03 (Wed): Inequality facts Earnings inequality Mar-08 (Mon): The top 1 percent Intergenerational mobility Short Run \u00b6 Mar-15 (Mon): IS-LM model Mar-17 (Wed): Equilibrium , PP Medium Run \u00b6 Mar-22 (Mon): Labor market , PP Mar-24 (Wed): AS-AD model , PP (covers Phillips Curve) Mar-29 (Mon): Inflation and unemployment Mar-31 (Wed): Inflation expectations and monetary policy , PP Open Economy \u00b6 Apr-07 (Wed): Trade deficits , PP Apr-12 (Mon): Trade deficits (continued) Apr-14 (Wed): IS-LM model , PP Apr-19 (Mon): IS-LM floating exchange rate Apr-21 (Wed): IS-LM fixed exchange rate Apr-26 (Mon): AS-AD model , Policy analysis , PP Apr-28 (Wed): Costs and benefits of international trade Expectations \u00b6 May-03 (Mon): Asset prices , PP May-05 (Wed): Expectations and policy , PP May-05 (Wed): Model synthesis: SL May-05 (Wed): Last class","title":"Schedule520"},{"location":"econ520/schedule520.html#special-dates","text":"Feb-15 (Mon): Wellness day Mar-10 (Wed): Midterm: Material covered: TBA Apr-05 (Mon): Wellness day","title":"Special dates"},{"location":"econ520/schedule520.html#economic-growth","text":"Jan-20 (Wed): Growth facts , In case you need a refresher: Growth rates and logarithms , PP (practice problems; previous exams are at the bottom of the page) Jan-25 (Mon): Methods for identifying causes and effects Jan-27 (Wed): The Role of Capital , PP Feb-01 (Mon): The Role of Capital, part 2 Feb-03 (Wed): Solow model Feb-08 (Mon): Solow diagram , PP Feb-10 (Wed): Solow Applications , Applications, part 2 Feb-17 (Wed): Discussion: How to prevent the end of economic growth Feb-22 (Mon): Institutions , PP Feb-24 (Wed): Growth and ideas Mar-01 (Mon): Romer model , PP Policy implications","title":"Economic Growth"},{"location":"econ520/schedule520.html#inequality","text":"Mar-03 (Wed): Inequality facts Earnings inequality Mar-08 (Mon): The top 1 percent Intergenerational mobility","title":"Inequality"},{"location":"econ520/schedule520.html#short-run","text":"Mar-15 (Mon): IS-LM model Mar-17 (Wed): Equilibrium , PP","title":"Short Run"},{"location":"econ520/schedule520.html#medium-run","text":"Mar-22 (Mon): Labor market , PP Mar-24 (Wed): AS-AD model , PP (covers Phillips Curve) Mar-29 (Mon): Inflation and unemployment Mar-31 (Wed): Inflation expectations and monetary policy , PP","title":"Medium Run"},{"location":"econ520/schedule520.html#open-economy","text":"Apr-07 (Wed): Trade deficits , PP Apr-12 (Mon): Trade deficits (continued) Apr-14 (Wed): IS-LM model , PP Apr-19 (Mon): IS-LM floating exchange rate Apr-21 (Wed): IS-LM fixed exchange rate Apr-26 (Mon): AS-AD model , Policy analysis , PP Apr-28 (Wed): Costs and benefits of international trade","title":"Open Economy"},{"location":"econ520/schedule520.html#expectations","text":"May-03 (Mon): Asset prices , PP May-05 (Wed): Expectations and policy , PP May-05 (Wed): Model synthesis: SL May-05 (Wed): Last class","title":"Expectations"},{"location":"econ520/syllabus520.html","text":"Econ520 - Advanced Macroeconomic Theory \u00b6 Spring 2021 - Prof. Lutz Hendricks - Syllabus \u00b6 For those planning / buying ahead: the texts will be Charles Jones. Introduction to Economic Growth, 3rd edition, 2013, ISBN-13: 978-0393919172. * The 2nd edition is very similar to the 3rd edition. Olivier Blanchard. Macroeconomics, 8th ed., Pearson (ISBN-13: 9780136713883) Older editions of both books are ok and could be a lot less expensive. Ebooks are an affordable alternative. You will not need the MyLab access. Class meets: MW 11:15-12:30, Chapman 201 . Check the course web site regularly for updates. It contains contact info, office hours, class times, exam dates, course outline, slides, etc. Course objective: \u00b6 Econ520 develops macroeconomic models and applies them to real world issues. Topics include: Long-run growth. Cross-country income differences. Economic inequality. The twin deficits: the government budget and the trade deficit. Fiscal policy. Open economy (exchange rates, transmission of shocks across countries). Economies are complex systems. To understand them, it is necessary to write down models . Models need not be mathematical; they could be computational. But in this course, since we want to develop an understanding how macro variables interact, the models will be mathematical. Grading: \u00b6 Grades will be based on midterm (40%) final exam (45%) term paper (15%) If a student misses an exam for a good reason, the remaining exam accounts for 85% of the course grade. If a student misses an exam without a good reason, he/she will receive a score of 0 on that exam. There are no make-up exams . Each exam focuses on the material covered since the last exam. However, as new material builds on previously covered material, anything covered in the course up to the date of the exam is fair game. Cutoffs for letter grades are: A: 85, B: 70, C: 55, D: 45. There will be fractional grades (e.g. A-). How to Study for This Class \u00b6 Much of our time will be spent on analyzing models. There is only one way to learn how to do this: solve lots of practice problems . You will find such problems for each topic we cover posted on the course web page. The exam questions will similar in nature but tend to be shorter than the practice problems. If you feel that you are falling behind or if you have trouble with the practice problems, come to my office hours (listed on my web page). You should also read the textbook sections corresponding to the material we study in class. Additional reading material is listed at the end of the slides. A note on studying and classroom participation: \u00b6 The picture below shows Jean-Marc Cote's vision of the classroom in the year 2000. Unfortunately, this is not how it works... It is extremely important that you work through the practice problems for each section of the course. Also look at previous exams. If you find that you have trouble with these questions, come to my office hours. Feedback \u00b6 You can help improve this course by letting me know what you like and what you don't like. Drop me an e-mail or come to my office. Feel free to suggest topics you would like to discuss in class. Policies \u00b6 Please be on time when coming to class. Turn off your cell phones. Prerequisites \u00b6 Students must have passed Econ420 (Intermediate Macroeconomics). Basic calculus (derivatives) will be needed. If you are not comfortable with math or models, this is not the right course for you. Students should work through the math review problems posted on the course web site as soon as possible. Accessibility \u00b6 The University of North Carolina at Chapel Hill facilitates the implementation of reasonable accommodations, including resources and services, for students with disabilities, chronic medical conditions, a temporary disability or pregnancy complications resulting in barriers to fully accessing University courses, programs and activities. Accommodations are determined through the Office of Accessibility Resources and Service (ARS) for individuals with documented qualifying disabilities in accordance with applicable state and federal laws. See the ARS Website for contact information: or email ars@unc.edu. Conseling \u00b6 CAPS is strongly committed to addressing the mental health needs of a diverse student body through timely access to consultation and connection to clinically appropriate services, whether for short or long-term needs. Go to their website: https://caps.unc.edu/ or visit their facilities on the third floor of the Campus Health Services building for a walk-in evaluation to learn more. Title IX Resources \u00b6 Any student who is impacted by discrimination, harassment, interpersonal (relationship) violence, sexual violence, sexual exploitation, or stalking is encouraged to seek resources on campus or in the community. Please contact the Director of Title IX Compliance (Adrienne Allison \u2013 Adrienne.allison@unc.edu), Report and Response Coordinators in the Equal Opportunity and Compliance Office (reportandresponse@unc.edu), Counseling and Psychological Services (confidential), or the Gender Violence Services Coordinators (gvsc@unc.edu; confidential) to discuss your specific needs. Additional resources are available at safe.unc.edu. Special consideration \u00b6 Students will not be granted special consideration if they have attempted a piece of assessment and then ask for special consideration. Unless it is impossible for you to do so, you must contact your lecturer before the assessment is due if you expect to miss an assessment task. Failure to do this will weaken your case. Final exams can only be rescheduled by the Academic Dean. If you have a conflict, you need to contact him/her. Past exams \u00b6 (material in early years differs substantially from current year): 2021 Spring: Midterm 2017 Spring: Midterm , final 2016 Spring: Midterm , final 2015 Spring: exam1 , exam2 , final 2013 Fall: exam1 , exam2 , final . 2012 Fall: exam1 , exam2 , final . 2012 Spring: exam1 , exam2 , final . 2010 (course title was Econ499): exam1 , exam2 , final .","title":"Econ520 - Advanced Macroeconomic Theory #"},{"location":"econ520/syllabus520.html#econ520-advanced-macroeconomic-theory","text":"","title":"Econ520 - Advanced Macroeconomic Theory"},{"location":"econ520/syllabus520.html#spring-2021-prof-lutz-hendricks-syllabus","text":"For those planning / buying ahead: the texts will be Charles Jones. Introduction to Economic Growth, 3rd edition, 2013, ISBN-13: 978-0393919172. * The 2nd edition is very similar to the 3rd edition. Olivier Blanchard. Macroeconomics, 8th ed., Pearson (ISBN-13: 9780136713883) Older editions of both books are ok and could be a lot less expensive. Ebooks are an affordable alternative. You will not need the MyLab access. Class meets: MW 11:15-12:30, Chapman 201 . Check the course web site regularly for updates. It contains contact info, office hours, class times, exam dates, course outline, slides, etc.","title":"Spring 2021 - Prof. Lutz Hendricks - Syllabus"},{"location":"econ520/syllabus520.html#course-objective","text":"Econ520 develops macroeconomic models and applies them to real world issues. Topics include: Long-run growth. Cross-country income differences. Economic inequality. The twin deficits: the government budget and the trade deficit. Fiscal policy. Open economy (exchange rates, transmission of shocks across countries). Economies are complex systems. To understand them, it is necessary to write down models . Models need not be mathematical; they could be computational. But in this course, since we want to develop an understanding how macro variables interact, the models will be mathematical.","title":"Course objective:"},{"location":"econ520/syllabus520.html#grading","text":"Grades will be based on midterm (40%) final exam (45%) term paper (15%) If a student misses an exam for a good reason, the remaining exam accounts for 85% of the course grade. If a student misses an exam without a good reason, he/she will receive a score of 0 on that exam. There are no make-up exams . Each exam focuses on the material covered since the last exam. However, as new material builds on previously covered material, anything covered in the course up to the date of the exam is fair game. Cutoffs for letter grades are: A: 85, B: 70, C: 55, D: 45. There will be fractional grades (e.g. A-).","title":"Grading:"},{"location":"econ520/syllabus520.html#how-to-study-for-this-class","text":"Much of our time will be spent on analyzing models. There is only one way to learn how to do this: solve lots of practice problems . You will find such problems for each topic we cover posted on the course web page. The exam questions will similar in nature but tend to be shorter than the practice problems. If you feel that you are falling behind or if you have trouble with the practice problems, come to my office hours (listed on my web page). You should also read the textbook sections corresponding to the material we study in class. Additional reading material is listed at the end of the slides.","title":"How to Study for This Class"},{"location":"econ520/syllabus520.html#a-note-on-studying-and-classroom-participation","text":"The picture below shows Jean-Marc Cote's vision of the classroom in the year 2000. Unfortunately, this is not how it works... It is extremely important that you work through the practice problems for each section of the course. Also look at previous exams. If you find that you have trouble with these questions, come to my office hours.","title":"A note on studying and classroom participation:"},{"location":"econ520/syllabus520.html#feedback","text":"You can help improve this course by letting me know what you like and what you don't like. Drop me an e-mail or come to my office. Feel free to suggest topics you would like to discuss in class.","title":"Feedback"},{"location":"econ520/syllabus520.html#policies","text":"Please be on time when coming to class. Turn off your cell phones.","title":"Policies"},{"location":"econ520/syllabus520.html#prerequisites","text":"Students must have passed Econ420 (Intermediate Macroeconomics). Basic calculus (derivatives) will be needed. If you are not comfortable with math or models, this is not the right course for you. Students should work through the math review problems posted on the course web site as soon as possible.","title":"Prerequisites"},{"location":"econ520/syllabus520.html#accessibility","text":"The University of North Carolina at Chapel Hill facilitates the implementation of reasonable accommodations, including resources and services, for students with disabilities, chronic medical conditions, a temporary disability or pregnancy complications resulting in barriers to fully accessing University courses, programs and activities. Accommodations are determined through the Office of Accessibility Resources and Service (ARS) for individuals with documented qualifying disabilities in accordance with applicable state and federal laws. See the ARS Website for contact information: or email ars@unc.edu.","title":"Accessibility"},{"location":"econ520/syllabus520.html#conseling","text":"CAPS is strongly committed to addressing the mental health needs of a diverse student body through timely access to consultation and connection to clinically appropriate services, whether for short or long-term needs. Go to their website: https://caps.unc.edu/ or visit their facilities on the third floor of the Campus Health Services building for a walk-in evaluation to learn more.","title":"Conseling"},{"location":"econ520/syllabus520.html#title-ix-resources","text":"Any student who is impacted by discrimination, harassment, interpersonal (relationship) violence, sexual violence, sexual exploitation, or stalking is encouraged to seek resources on campus or in the community. Please contact the Director of Title IX Compliance (Adrienne Allison \u2013 Adrienne.allison@unc.edu), Report and Response Coordinators in the Equal Opportunity and Compliance Office (reportandresponse@unc.edu), Counseling and Psychological Services (confidential), or the Gender Violence Services Coordinators (gvsc@unc.edu; confidential) to discuss your specific needs. Additional resources are available at safe.unc.edu.","title":"Title IX Resources"},{"location":"econ520/syllabus520.html#special-consideration","text":"Students will not be granted special consideration if they have attempted a piece of assessment and then ask for special consideration. Unless it is impossible for you to do so, you must contact your lecturer before the assessment is due if you expect to miss an assessment task. Failure to do this will weaken your case. Final exams can only be rescheduled by the Academic Dean. If you have a conflict, you need to contact him/her.","title":"Special consideration"},{"location":"econ520/syllabus520.html#past-exams","text":"(material in early years differs substantially from current year): 2021 Spring: Midterm 2017 Spring: Midterm , final 2016 Spring: Midterm , final 2015 Spring: exam1 , exam2 , final 2013 Fall: exam1 , exam2 , final . 2012 Fall: exam1 , exam2 , final . 2012 Spring: exam1 , exam2 , final . 2010 (course title was Econ499): exam1 , exam2 , final .","title":"Past exams"},{"location":"econ520/term_paper.html","text":"Econ520 - Advanced Macroeconomic Theory \u00b6 Spring 2021 - Prof. Lutz Hendricks - Term Paper \u00b6 The term paper picks a topic, critically reviews the literature, and clearly lays out arguments on both sides of the debate. The paper is due by the last class meeting. During the week after the midterm (but better earlier), each student should submit a 1-2 page proposal that: states the topic outlines the main arguments provides at least 5 relevant references As you write / develop your argument, you should get in touch with me periodically to make sure everything is on track (and to clarify questions). Please provide all files in pdf format (not MS Word). I do not need hardcopies. Expectations \u00b6 The paper should demonstrate understanding of the literature. Relevant literature might include Fed or IMF publications, the Economist, NY Times, or Wall Street Journal, the Journal of Economic Perspectives lay out arguments on both sides of a debate. give the reader an idea about how the cited studies reached their conclusions give an idea of magnitudes. Macro questions are often about quantifying tradeoffs. For example, it is obvious that more progressive taxes reduce inequality. But is this a big or small effect? I do not expect innovation, modeling, theory, or original data work. that you read academic journal articles. that you reach a conclusion. If the experts disagree, I don't expect you to figure it out. There is no prescribed length. Obviously, you don't want to hand in 2 pages. Examples of well-written term papers: Negative interest rates , Racial inequality . Notes on Writing \u00b6 Cite your sources. When you make a claim, back it up. Nice words come last. First decide what you want to write. Outline that. When you are happy with the substance, fill in the words. Visual structure. There should be (sub-)headings that let the reader see at a glance how the document is structured. Explain how conclusions are reached. Saying \"A study by X showed that increasing top marginal taxes reduce income inequality by Y\" is not all that informative by itself. How was that conclusion reached? Why do other studies disagree? Possible Topics (but You May Choose Your Own) \u00b6 The topic needs to be fairly narrow. Examples: You could study the importance of international trade for rising income inequality. Studying all possible causes of rising income inequality would be too broad. You could study the pros and cons of a particular tax proposal (e.g., the flat tax). Below I list potential topics. They are generally phrased more broadly than what you would choose for a term paper. Growth: Do we need patent protection for innovation to occur? Why has manufacturing declined in the U.S. (international trade, technical change, ...)? Do certain policies stimulate long-run growth? Examples include tax cuts, deregulation, free trade agreements. Business cycles: Why was wage growth so slow during the recovery after the Great Recession? Fiscal policy: Effects of austerity policies in Greece or other European countries. What are the limits to government debt? Will interest rates remain low for a long time? Do tax cuts pay for themselves? Monetary policy: Should the Fed target asset prices? Can the Fed pursue unconventional monetary policies (QE, asset purchases) forever? What are the limits? Inequality: Effects of taxing the rich. Causes of rising income inequality. Potential policy responses. Labor market polarization: what will happen when more and more jobs get mechanized? Why has the labor share declined over time? What would happen if we taxed bequests? Or wealth? Would a minimum wage cause lots of unemployment? Open economy: Are exchange rate devaluations expansionary? Why are we running a trade deficit with China? Finding source material \u00b6 Academic journal articles are generally hard to read. Feel free to look, though, and you will get an idea what professional economists actually do. Sources with overview articles: The Journal of Economic Perspectives Brookings Institution Federal Reserve Banks publish articles aimed at explaining research to the general public. Examples are the Economic Letters of the San Francisco Fed. I maintain a short list . I would generally avoid political sources (Heritage Foundation; Congress; Cato Institute).","title":"Econ520 - Advanced Macroeconomic Theory #"},{"location":"econ520/term_paper.html#econ520-advanced-macroeconomic-theory","text":"","title":"Econ520 - Advanced Macroeconomic Theory"},{"location":"econ520/term_paper.html#spring-2021-prof-lutz-hendricks-term-paper","text":"The term paper picks a topic, critically reviews the literature, and clearly lays out arguments on both sides of the debate. The paper is due by the last class meeting. During the week after the midterm (but better earlier), each student should submit a 1-2 page proposal that: states the topic outlines the main arguments provides at least 5 relevant references As you write / develop your argument, you should get in touch with me periodically to make sure everything is on track (and to clarify questions). Please provide all files in pdf format (not MS Word). I do not need hardcopies.","title":"Spring 2021 - Prof. Lutz Hendricks - Term Paper"},{"location":"econ520/term_paper.html#expectations","text":"The paper should demonstrate understanding of the literature. Relevant literature might include Fed or IMF publications, the Economist, NY Times, or Wall Street Journal, the Journal of Economic Perspectives lay out arguments on both sides of a debate. give the reader an idea about how the cited studies reached their conclusions give an idea of magnitudes. Macro questions are often about quantifying tradeoffs. For example, it is obvious that more progressive taxes reduce inequality. But is this a big or small effect? I do not expect innovation, modeling, theory, or original data work. that you read academic journal articles. that you reach a conclusion. If the experts disagree, I don't expect you to figure it out. There is no prescribed length. Obviously, you don't want to hand in 2 pages. Examples of well-written term papers: Negative interest rates , Racial inequality .","title":"Expectations"},{"location":"econ520/term_paper.html#notes-on-writing","text":"Cite your sources. When you make a claim, back it up. Nice words come last. First decide what you want to write. Outline that. When you are happy with the substance, fill in the words. Visual structure. There should be (sub-)headings that let the reader see at a glance how the document is structured. Explain how conclusions are reached. Saying \"A study by X showed that increasing top marginal taxes reduce income inequality by Y\" is not all that informative by itself. How was that conclusion reached? Why do other studies disagree?","title":"Notes on Writing"},{"location":"econ520/term_paper.html#possible-topics-but-you-may-choose-your-own","text":"The topic needs to be fairly narrow. Examples: You could study the importance of international trade for rising income inequality. Studying all possible causes of rising income inequality would be too broad. You could study the pros and cons of a particular tax proposal (e.g., the flat tax). Below I list potential topics. They are generally phrased more broadly than what you would choose for a term paper. Growth: Do we need patent protection for innovation to occur? Why has manufacturing declined in the U.S. (international trade, technical change, ...)? Do certain policies stimulate long-run growth? Examples include tax cuts, deregulation, free trade agreements. Business cycles: Why was wage growth so slow during the recovery after the Great Recession? Fiscal policy: Effects of austerity policies in Greece or other European countries. What are the limits to government debt? Will interest rates remain low for a long time? Do tax cuts pay for themselves? Monetary policy: Should the Fed target asset prices? Can the Fed pursue unconventional monetary policies (QE, asset purchases) forever? What are the limits? Inequality: Effects of taxing the rich. Causes of rising income inequality. Potential policy responses. Labor market polarization: what will happen when more and more jobs get mechanized? Why has the labor share declined over time? What would happen if we taxed bequests? Or wealth? Would a minimum wage cause lots of unemployment? Open economy: Are exchange rate devaluations expansionary? Why are we running a trade deficit with China?","title":"Possible Topics (but You May Choose Your Own)"},{"location":"econ520/term_paper.html#finding-source-material","text":"Academic journal articles are generally hard to read. Feel free to look, though, and you will get an idea what professional economists actually do. Sources with overview articles: The Journal of Economic Perspectives Brookings Institution Federal Reserve Banks publish articles aimed at explaining research to the general public. Examples are the Economic Letters of the San Francisco Fed. I maintain a short list . I would generally avoid political sources (Heritage Foundation; Congress; Cato Institute).","title":"Finding source material"},{"location":"econ720/econ720.html","text":"Econ720: Advanced Macroeconomic Theory (PhD) \u00b6 Fall 2020. Prof. Lutz Hendricks. UNC Syllabus Schedule Announcements \u00b6 11/5: Final exam date Nov-18, 8-11am 11/4: I added a derivation for the Hamilton-Jacobi-Bellman equation in the creative destruction slides (that is the equation used to find V when patents get destroyed stochastically). It's a generically useful equation in many contexts. I posted answers for the midterm Notes on scanning exams and problem sets: Use a scanner or a scanning app. Do not take photos because the resulting files are very hard to read. A good scanning app will render the paper itself as white background. Play around with contrast adjustments to make the text readable. Notes on the midterm : Material covered: up to and including competitive equilibrium in the infinite horizon growth model. See previous exams for practice. I will post the exam on sakai at 8am. Answers are due by email by 9:30am. I will record class meetings via zoom and post recordings in Sakai. Please do not share with anyone outside of Econ720. For online discussions, I suggest to sign up at Econ StackExchange : there you can post questions that are not directly class related. The questions have to be specific (discussion questions are not permitted). For questions that are directly class related, please use the Sakai forum. You can of course also just email me directly, but using the forums has the benefit that others can see the conversations (and chime in).","title":"Econ720"},{"location":"econ720/econ720.html#econ720-advanced-macroeconomic-theory-phd","text":"Fall 2020. Prof. Lutz Hendricks. UNC Syllabus Schedule","title":"Econ720: Advanced Macroeconomic Theory (PhD)"},{"location":"econ720/econ720.html#announcements","text":"11/5: Final exam date Nov-18, 8-11am 11/4: I added a derivation for the Hamilton-Jacobi-Bellman equation in the creative destruction slides (that is the equation used to find V when patents get destroyed stochastically). It's a generically useful equation in many contexts. I posted answers for the midterm Notes on scanning exams and problem sets: Use a scanner or a scanning app. Do not take photos because the resulting files are very hard to read. A good scanning app will render the paper itself as white background. Play around with contrast adjustments to make the text readable. Notes on the midterm : Material covered: up to and including competitive equilibrium in the infinite horizon growth model. See previous exams for practice. I will post the exam on sakai at 8am. Answers are due by email by 9:30am. I will record class meetings via zoom and post recordings in Sakai. Please do not share with anyone outside of Econ720. For online discussions, I suggest to sign up at Econ StackExchange : there you can post questions that are not directly class related. The questions have to be specific (discussion questions are not permitted). For questions that are directly class related, please use the Sakai forum. You can of course also just email me directly, but using the forums has the benefit that others can see the conversations (and chime in).","title":"Announcements"},{"location":"econ720/schedule720.html","text":"Special dates ## \u00b6 Sep-07 (Mon): Labor day Sep-28 (Mon): Midterm: Material covered: TBA. Modern Macro ## \u00b6 Aug-10 (Mon): Modern macro , Here we talk about methods: how to set up a general equilibrium model and characterize its equilibrium. Aug-12 (Wed): Sequential trading and Arrow-Debreu Overlapping Generations ## \u00b6 Aug-17 (Mon): Model Aug-19 (Wed): OLG model (continued) Aug-24 (Mon): OLG model (continued) Aug-26 (Wed): Dynamics and steady state , solution for example , PS1 , answers Aug-31 (Mon): Efficiency and Social Security , RQ (review questions, not to be handed in) Sep-02 (Wed): Bequests Sep-09 (Wed): Money in OLG models , PS2 , answers Infinite Horizon, Discrete Time Models ## \u00b6 Sep-14 (Mon): The growth model Sep-16 (Wed): Dynamic programming Sep-21 (Mon): Competitive equilibrium , RQ , PS3 , answers Sep-23 (Wed): Cash in advance models , RQ , PS4 , answers Sep-30 (Wed): Two sector models , RQ , (Skipped this year) Example: Asset pricing , RQ , (Skipped this year) Dynamic programming theorems , Notes on Dynamic Programming , (Skipped this year) Infinite Horizon, Continuous Time Models ## \u00b6 Oct-05 (Mon): Solow model Oct-07 (Wed): Optimal control Oct-12 (Mon): The growth model Oct-14 (Wed): Competitive equilibrium Dynamics and phase diagrams (skipped this year), RQ Oct-19 (Mon): Money in the utility function , PS5 , answers Endogenous Growth ## \u00b6 Oct-21 (Wed): Endogenous growth: AK model , RQ , Phase diagram (skipped this year) Increasing varieties , RQ Oct-26 (Mon): Increasing varieties, part II Oct-28 (Wed): Knowledge spillovers and scale effects , PS6 , answers Nov-02 (Mon): Quality ladders Quality ladders with firm dynamics Stochastic Growth ## \u00b6 Nov-04 (Wed): Stochastic optimization Dynamic programming -- we will not talk about this in class. Think of it as a simple user guide to the results that are out there. Nov-09 (Mon): Asset pricing Nov-11 (Wed): Extensions , RQ , PS7 , answers Nov-16 (Mon): Stochastic growth model , RQ","title":"Schedule720"},{"location":"econ720/schedule720.html#special-dates","text":"Sep-07 (Mon): Labor day Sep-28 (Mon): Midterm: Material covered: TBA.","title":"Special dates ##"},{"location":"econ720/schedule720.html#modern-macro","text":"Aug-10 (Mon): Modern macro , Here we talk about methods: how to set up a general equilibrium model and characterize its equilibrium. Aug-12 (Wed): Sequential trading and Arrow-Debreu","title":"Modern Macro ##"},{"location":"econ720/schedule720.html#overlapping-generations","text":"Aug-17 (Mon): Model Aug-19 (Wed): OLG model (continued) Aug-24 (Mon): OLG model (continued) Aug-26 (Wed): Dynamics and steady state , solution for example , PS1 , answers Aug-31 (Mon): Efficiency and Social Security , RQ (review questions, not to be handed in) Sep-02 (Wed): Bequests Sep-09 (Wed): Money in OLG models , PS2 , answers","title":"Overlapping Generations ##"},{"location":"econ720/schedule720.html#infinite-horizon-discrete-time-models","text":"Sep-14 (Mon): The growth model Sep-16 (Wed): Dynamic programming Sep-21 (Mon): Competitive equilibrium , RQ , PS3 , answers Sep-23 (Wed): Cash in advance models , RQ , PS4 , answers Sep-30 (Wed): Two sector models , RQ , (Skipped this year) Example: Asset pricing , RQ , (Skipped this year) Dynamic programming theorems , Notes on Dynamic Programming , (Skipped this year)","title":"Infinite Horizon, Discrete Time Models ##"},{"location":"econ720/schedule720.html#infinite-horizon-continuous-time-models","text":"Oct-05 (Mon): Solow model Oct-07 (Wed): Optimal control Oct-12 (Mon): The growth model Oct-14 (Wed): Competitive equilibrium Dynamics and phase diagrams (skipped this year), RQ Oct-19 (Mon): Money in the utility function , PS5 , answers","title":"Infinite Horizon, Continuous Time Models ##"},{"location":"econ720/schedule720.html#endogenous-growth","text":"Oct-21 (Wed): Endogenous growth: AK model , RQ , Phase diagram (skipped this year) Increasing varieties , RQ Oct-26 (Mon): Increasing varieties, part II Oct-28 (Wed): Knowledge spillovers and scale effects , PS6 , answers Nov-02 (Mon): Quality ladders Quality ladders with firm dynamics","title":"Endogenous Growth ##"},{"location":"econ720/schedule720.html#stochastic-growth","text":"Nov-04 (Wed): Stochastic optimization Dynamic programming -- we will not talk about this in class. Think of it as a simple user guide to the results that are out there. Nov-09 (Mon): Asset pricing Nov-11 (Wed): Extensions , RQ , PS7 , answers Nov-16 (Mon): Stochastic growth model , RQ","title":"Stochastic Growth ##"},{"location":"econ720/syllabus720.html","text":"Econ720: Advanced Macroeconomic Theory (PhD) \u00b6 Fall 2020. Prof. Lutz Hendricks. UNC \u00b6 Course objective: \u00b6 Econ720 is the first course in the macro PhD sequence. Its objective is to teach basic versions of the standard models commonly used in macroeconomics. In parallel, the course develops the mathematical methods used to characterize the equilibria of the models. This is a largely a theory and methods course. But we will cover some applications to topics such as the distribution of wealth. The course schedule contains more detail. Organization: \u00b6 Two lectures per week: MW 8:00 - 9:15, Greenlaw 101 Recitation: Fri 8:00 - 8:50, Dey Hall Toy Lounge 409 TA: Yanran Guo, office hours TBA Course website: lhendricks.org/econ720/econ720.html Sakai site: https://sakai.unc.edu/portal/site/econ720 Grading: \u00b6 Midterm: 40%. Final: 50%. Problem sets: 10%. Exams are closed book and cover all material taught. Per university requirement, the final will last 3 hours. Review problems are for your practice and not to be turned in. Many are questions from previous exams. If a student misses a midterm, the weight of that midterm in the course grade will be added to the weight on the student\u2019s final. An exception will be made for University-approved absences . Students with this type of absence may request a make-up examination at a time convenient to both student and instructor. Special Arrangements for 2020: \u00b6 UNC has decided that the course will be taught in \"hybrid-flex\" format. There will be in person class meetings as usual. Class meetings will also be streamed live on zoom and recorded for later viewing by students in difficult time zones. During class, I will screen share the slides on my laptop, which are also projected on the projector screen in the classroom. I will ask one student to keep an eye on questions that come in via zoom , either by chat or using the raised hand feature. For safety reasons, I will not stay after class for questions or discussions. Office hours will be held online. I will hold scheduled office hours (as required by UNC), even though I have always found them imperfect ( n students show up at the same time with n-1 students waiting for the first to finish their discussion). I encourage everyone to make appointments instead. I also set up forums on sakai so that discussions among students and with me can occur asynchronously. Given that COVID cases are on the rise, it is likely that the course will switch to online only after the first few weeks. This is out of my control. It is also likely that the exams will switch to online. In that case, exams will be open book. Students who attend in person must wear masks and observe social distancing. No exceptions. Even so, meeting in person is dangerous and I will not force students who do not feel safe to attend in person. Feel free to switch between in person and remote attendance over time. Problem sets must be scanned and submitted electronically (probably by email). Text: \u00b6 Acemoglu, Introduction to Modern Economic Growth, MIT Press, ISBN-13: 978-0691132921 Additional readings are in the slides. Rules: \u00b6 Questions and comments are always welcome. You should download the slides before each class. However, I tend to change details even after posting the slides. Previous Exams \u00b6 Qualifying exams: August 2009 , January 2010 , August 2010 , January 2011 , August 2011 , January 2012 , August 2012 , January 2013 , August 2013 , January 2014 , August 2014 , January 2015 , August 2015 , January 2016 , August 2016 , January 2017 , August 2017 , May 2018 , May 2019 , Aug 2019 , June 2020 . Final exams: 2009 , 2010 , 2011 , 2012 , 2013 , 2014 , 2015 , 2016 , 2017 , 2018 , 2019 , 2020 . Midterms: 2008 (Iowa State), 2009 , 2009 take 3 , 2010 , 2011 , 2012 , 2013 , 2014 , 2015 , 2016 , 2017 , 2018 , 2019 , 2020 . If answers are missing, the exam questions are usually reused as problem sets. Additional Notes \u00b6 Reading material is listed at the end of the slides. Dirk Krueger\u2019s Macroeconomic Theory manuscript ([2012 version][]; this tends to move around on the web). Per Krusell\u2019s Real Macroeconomic Theory manuscript, 2014 version Required University Boilerplate Text \u00b6 This fall semester, while we are in the midst of a global pandemic, all enrolled students are required to wear a mask covering your mouth and nose at all times in our classroom. This requirement is to protect our educational community \u2014 your classmates and me \u2013 as we learn together. If you choose not to wear a mask, or wear it improperly, I will ask you to leave immediately, and I will submit a report to the Office of Student Conduct. At that point you will be disenrolled from this course for the protection of our educational community. An exemption to the mask wearing community standard will not typically be considered to be a reasonable accommodation. Individuals with a disability or health condition that prevents them from safely\u202fwearing a face\u202fmask must seek alternative accommodations through the Accessibility Resources and Service. For additional information, see Carolina Together. Any student who is impacted by discrimination, harassment, interpersonal (relationship) violence, sexual violence, sexual exploitation, or stalking is encouraged to seek resources on campus or in the community. Please contact the Director of Title IX Compliance (Adrienne Allison \u2013 Adrienne.allison@unc.edu), Report and Response Coordinators in the Equal Opportunity and Compliance Office (reportandresponse@unc.edu), Counseling and Psychological Services (confidential), or the Gender Violence Services Coordinators (gvsc@unc.edu; confidential) to discuss your specific needs. Additional resources are available at safe.unc.edu.","title":"Econ720: Advanced Macroeconomic Theory (PhD)"},{"location":"econ720/syllabus720.html#econ720-advanced-macroeconomic-theory-phd","text":"","title":"Econ720: Advanced Macroeconomic Theory (PhD)"},{"location":"econ720/syllabus720.html#fall-2020-prof-lutz-hendricks-unc","text":"","title":"Fall 2020. Prof. Lutz Hendricks. UNC"},{"location":"econ720/syllabus720.html#course-objective","text":"Econ720 is the first course in the macro PhD sequence. Its objective is to teach basic versions of the standard models commonly used in macroeconomics. In parallel, the course develops the mathematical methods used to characterize the equilibria of the models. This is a largely a theory and methods course. But we will cover some applications to topics such as the distribution of wealth. The course schedule contains more detail.","title":"Course objective:"},{"location":"econ720/syllabus720.html#organization","text":"Two lectures per week: MW 8:00 - 9:15, Greenlaw 101 Recitation: Fri 8:00 - 8:50, Dey Hall Toy Lounge 409 TA: Yanran Guo, office hours TBA Course website: lhendricks.org/econ720/econ720.html Sakai site: https://sakai.unc.edu/portal/site/econ720","title":"Organization:"},{"location":"econ720/syllabus720.html#grading","text":"Midterm: 40%. Final: 50%. Problem sets: 10%. Exams are closed book and cover all material taught. Per university requirement, the final will last 3 hours. Review problems are for your practice and not to be turned in. Many are questions from previous exams. If a student misses a midterm, the weight of that midterm in the course grade will be added to the weight on the student\u2019s final. An exception will be made for University-approved absences . Students with this type of absence may request a make-up examination at a time convenient to both student and instructor.","title":"Grading:"},{"location":"econ720/syllabus720.html#special-arrangements-for-2020","text":"UNC has decided that the course will be taught in \"hybrid-flex\" format. There will be in person class meetings as usual. Class meetings will also be streamed live on zoom and recorded for later viewing by students in difficult time zones. During class, I will screen share the slides on my laptop, which are also projected on the projector screen in the classroom. I will ask one student to keep an eye on questions that come in via zoom , either by chat or using the raised hand feature. For safety reasons, I will not stay after class for questions or discussions. Office hours will be held online. I will hold scheduled office hours (as required by UNC), even though I have always found them imperfect ( n students show up at the same time with n-1 students waiting for the first to finish their discussion). I encourage everyone to make appointments instead. I also set up forums on sakai so that discussions among students and with me can occur asynchronously. Given that COVID cases are on the rise, it is likely that the course will switch to online only after the first few weeks. This is out of my control. It is also likely that the exams will switch to online. In that case, exams will be open book. Students who attend in person must wear masks and observe social distancing. No exceptions. Even so, meeting in person is dangerous and I will not force students who do not feel safe to attend in person. Feel free to switch between in person and remote attendance over time. Problem sets must be scanned and submitted electronically (probably by email).","title":"Special Arrangements for 2020:"},{"location":"econ720/syllabus720.html#text","text":"Acemoglu, Introduction to Modern Economic Growth, MIT Press, ISBN-13: 978-0691132921 Additional readings are in the slides.","title":"Text:"},{"location":"econ720/syllabus720.html#rules","text":"Questions and comments are always welcome. You should download the slides before each class. However, I tend to change details even after posting the slides.","title":"Rules:"},{"location":"econ720/syllabus720.html#previous-exams","text":"Qualifying exams: August 2009 , January 2010 , August 2010 , January 2011 , August 2011 , January 2012 , August 2012 , January 2013 , August 2013 , January 2014 , August 2014 , January 2015 , August 2015 , January 2016 , August 2016 , January 2017 , August 2017 , May 2018 , May 2019 , Aug 2019 , June 2020 . Final exams: 2009 , 2010 , 2011 , 2012 , 2013 , 2014 , 2015 , 2016 , 2017 , 2018 , 2019 , 2020 . Midterms: 2008 (Iowa State), 2009 , 2009 take 3 , 2010 , 2011 , 2012 , 2013 , 2014 , 2015 , 2016 , 2017 , 2018 , 2019 , 2020 . If answers are missing, the exam questions are usually reused as problem sets.","title":"Previous Exams"},{"location":"econ720/syllabus720.html#additional-notes","text":"Reading material is listed at the end of the slides. Dirk Krueger\u2019s Macroeconomic Theory manuscript ([2012 version][]; this tends to move around on the web). Per Krusell\u2019s Real Macroeconomic Theory manuscript, 2014 version","title":"Additional Notes"},{"location":"econ720/syllabus720.html#required-university-boilerplate-text","text":"This fall semester, while we are in the midst of a global pandemic, all enrolled students are required to wear a mask covering your mouth and nose at all times in our classroom. This requirement is to protect our educational community \u2014 your classmates and me \u2013 as we learn together. If you choose not to wear a mask, or wear it improperly, I will ask you to leave immediately, and I will submit a report to the Office of Student Conduct. At that point you will be disenrolled from this course for the protection of our educational community. An exemption to the mask wearing community standard will not typically be considered to be a reasonable accommodation. Individuals with a disability or health condition that prevents them from safely\u202fwearing a face\u202fmask must seek alternative accommodations through the Accessibility Resources and Service. For additional information, see Carolina Together. Any student who is impacted by discrimination, harassment, interpersonal (relationship) violence, sexual violence, sexual exploitation, or stalking is encouraged to seek resources on campus or in the community. Please contact the Director of Title IX Compliance (Adrienne Allison \u2013 Adrienne.allison@unc.edu), Report and Response Coordinators in the Equal Opportunity and Compliance Office (reportandresponse@unc.edu), Counseling and Psychological Services (confidential), or the Gender Violence Services Coordinators (gvsc@unc.edu; confidential) to discuss your specific needs. Additional resources are available at safe.unc.edu.","title":"Required University Boilerplate Text"},{"location":"econ821/code_organization.html","text":"{{econ821_header.txt}} Organizing our code \u00b6 Directory structure \u00b6 Course home directory (e.g. ~/documents/econ821 ) shared : code for general purpose functions put on the matlab path by go_econ821 contains a function that returns constants shared by all projects: const_821.m shared code as zip file projectX : code for each project mat : matrix files .mat out : output files, such as figures, tables Project code \u00b6 Suffix each file with a project name, such as _olg . This ensures unique names. const_olg : defines all constants for a project model parameters directories figure formatting etc","title":"Code organization"},{"location":"econ821/code_organization.html#organizing-our-code","text":"","title":"Organizing our code"},{"location":"econ821/code_organization.html#directory-structure","text":"Course home directory (e.g. ~/documents/econ821 ) shared : code for general purpose functions put on the matlab path by go_econ821 contains a function that returns constants shared by all projects: const_821.m shared code as zip file projectX : code for each project mat : matrix files .mat out : output files, such as figures, tables","title":"Directory structure"},{"location":"econ821/code_organization.html#project-code","text":"Suffix each file with a project name, such as _olg . This ensures unique names. const_olg : defines all constants for a project model parameters directories figure formatting etc","title":"Project code"},{"location":"econ821/econ821%202016.html","text":"{{econ821_header.txt}} {{../markdown_header.txt}} Econ821: \"Monetary Economics\" \u00b6 [%ClassTerm]. Prof. Lutz Hendricks. UNC \u00b6 Outline: Announcements \u00b6 Organization \u00b6 Objectives \u00b6 Learn about state of the art research in selected areas of macro. Learn how to compute models and take them to the data. Identify potential topics for dissertation research. See my notes on finding research topics. We cover the following broad topics: \u00b6 Economic growth Cross-country income gaps Within country income / wealth inequality. Class structure \u00b6 A mixture of lectures, student presentations , and hands-on programming. The lectures present key papers in each topic. We will then replicate the results of select papers using Matlab . This class is somewhat experimental. We will have to figure out how to efficiently do programming in class as we go along. Suggestions are welcome. Grading \u00b6 The class is graded based on participation in class. Students are expected to present and discuss state-of-the art papers on the topics we will cover. Outline \u00b6 Matlab and Programming [matlab] \u00b6 Jan-12 to 21: The material for this section is hosted at ReadTheDocs Solving heterogeneous agent OLG models [olg] \u00b6 Jan-26: Partial equilibrium (these are slides presented in class) General equilibrium The code for this lives in the olg2d folder on Github . Jan-28: Stochastic model Feb-2: Many period stochastic model Feb-4: Computing the multi-period model Wealth Distribution [wealth] \u00b6 Feb-9: Background lecture Bequests Feb-11: Entrepreneurship Other extensions Feb-16: Student presentations ( notes on their format ) David: Cozzi Feb-18: Student presentations Deepak: Boserum Andrew: de Nardi (2016) Feb-23: Kanat: Campanale (2007) Redistribution \u00b6 Feb-25: Redistribution I Mar-1: Redistribution II Economic Growth [growth] \u00b6 Mar-3: Growth facts Data sources Cross-Country Income Differences [incomeGaps] \u00b6 Mar-8: Background on cross-country income gaps Human Capital \u00b6 Mar-8: Human capital quality Mar-10: Immigrant earnings Mar-15 to 17: Spring break Mar-22 to 29: Presentation and discussion of current papers (by students). possible papers are listed at the end of the slides (you may suggest others) Andrew: Jones (2014) Kanat: Lagakos et al \"Experience matters\" (now with a changed title) David: Manuelli & Seshadri (2014) Deepak: Hanushek & Woessman (2012) Misallocation \u00b6 Mar-31: Misallocation: Agriculture Misallocation: Plants Apr-7 to 12: Student presentations Kanat: Hsieh et al. (2013) David: Gollin et al. (2013) Andrew: Lagakos & Waugh (2013) Deepak: Restuccia & Santaeulalia (2015) Computing Manuelli & Seshadri (2014 AER) \u00b6 Apr-19: Notes on the model Apr-21: Computation: household problem my code is on github Apr-26: Last class The rise in US educational attainment End of Class \u00b6","title":"Econ821 2016"},{"location":"econ821/econ821%202016.html#econ821-monetary-economics","text":"","title":"Econ821: \"Monetary Economics\""},{"location":"econ821/econ821%202016.html#classterm-prof-lutz-hendricks-unc","text":"Outline:","title":"[%ClassTerm]. Prof. Lutz Hendricks. UNC"},{"location":"econ821/econ821%202016.html#announcements","text":"","title":"Announcements"},{"location":"econ821/econ821%202016.html#organization","text":"","title":"Organization"},{"location":"econ821/econ821%202016.html#objectives","text":"Learn about state of the art research in selected areas of macro. Learn how to compute models and take them to the data. Identify potential topics for dissertation research. See my notes on finding research topics.","title":"Objectives"},{"location":"econ821/econ821%202016.html#we-cover-the-following-broad-topics","text":"Economic growth Cross-country income gaps Within country income / wealth inequality.","title":"We cover the following broad topics:"},{"location":"econ821/econ821%202016.html#class-structure","text":"A mixture of lectures, student presentations , and hands-on programming. The lectures present key papers in each topic. We will then replicate the results of select papers using Matlab . This class is somewhat experimental. We will have to figure out how to efficiently do programming in class as we go along. Suggestions are welcome.","title":"Class structure"},{"location":"econ821/econ821%202016.html#grading","text":"The class is graded based on participation in class. Students are expected to present and discuss state-of-the art papers on the topics we will cover.","title":"Grading"},{"location":"econ821/econ821%202016.html#outline","text":"","title":"Outline"},{"location":"econ821/econ821%202016.html#matlab-and-programming-matlab","text":"Jan-12 to 21: The material for this section is hosted at ReadTheDocs","title":"Matlab and Programming [matlab]"},{"location":"econ821/econ821%202016.html#solving-heterogeneous-agent-olg-models-olg","text":"Jan-26: Partial equilibrium (these are slides presented in class) General equilibrium The code for this lives in the olg2d folder on Github . Jan-28: Stochastic model Feb-2: Many period stochastic model Feb-4: Computing the multi-period model","title":"Solving heterogeneous agent OLG models [olg]"},{"location":"econ821/econ821%202016.html#wealth-distribution-wealth","text":"Feb-9: Background lecture Bequests Feb-11: Entrepreneurship Other extensions Feb-16: Student presentations ( notes on their format ) David: Cozzi Feb-18: Student presentations Deepak: Boserum Andrew: de Nardi (2016) Feb-23: Kanat: Campanale (2007)","title":"Wealth Distribution [wealth]"},{"location":"econ821/econ821%202016.html#redistribution","text":"Feb-25: Redistribution I Mar-1: Redistribution II","title":"Redistribution"},{"location":"econ821/econ821%202016.html#economic-growth-growth","text":"Mar-3: Growth facts Data sources","title":"Economic Growth [growth]"},{"location":"econ821/econ821%202016.html#cross-country-income-differences-incomegaps","text":"Mar-8: Background on cross-country income gaps","title":"Cross-Country Income Differences [incomeGaps]"},{"location":"econ821/econ821%202016.html#human-capital","text":"Mar-8: Human capital quality Mar-10: Immigrant earnings Mar-15 to 17: Spring break Mar-22 to 29: Presentation and discussion of current papers (by students). possible papers are listed at the end of the slides (you may suggest others) Andrew: Jones (2014) Kanat: Lagakos et al \"Experience matters\" (now with a changed title) David: Manuelli & Seshadri (2014) Deepak: Hanushek & Woessman (2012)","title":"Human Capital"},{"location":"econ821/econ821%202016.html#misallocation","text":"Mar-31: Misallocation: Agriculture Misallocation: Plants Apr-7 to 12: Student presentations Kanat: Hsieh et al. (2013) David: Gollin et al. (2013) Andrew: Lagakos & Waugh (2013) Deepak: Restuccia & Santaeulalia (2015)","title":"Misallocation"},{"location":"econ821/econ821%202016.html#computing-manuelli-seshadri-2014-aer","text":"Apr-19: Notes on the model Apr-21: Computation: household problem my code is on github Apr-26: Last class The rise in US educational attainment","title":"Computing Manuelli &amp; Seshadri (2014 AER)"},{"location":"econ821/econ821%202016.html#end-of-class","text":"","title":"End of Class"},{"location":"econ821/student_presentations.html","text":"{{econ821_header.txt}} {{../markdown_header.txt}} Econ821: \"Monetary Economics\" \u00b6 [%ClassTerm]. Prof. Lutz Hendricks. UNC \u00b6 Student Presentations \u00b6 Format: short summary of what the paper does (assume everyone has read it) focus on key features of the analysis (no details) comment on what drives results / key assumptions identify weaknesses / opportunities for improvements Duration: aim for 35 minutes including class discussion Send me slides a few days before the presentation","title":"Student presentations"},{"location":"econ821/student_presentations.html#econ821-monetary-economics","text":"","title":"Econ821: \"Monetary Economics\""},{"location":"econ821/student_presentations.html#classterm-prof-lutz-hendricks-unc","text":"","title":"[%ClassTerm]. Prof. Lutz Hendricks. UNC"},{"location":"econ821/student_presentations.html#student-presentations","text":"Format: short summary of what the paper does (assume everyone has read it) focus on key features of the analysis (no details) comment on what drives results / key assumptions identify weaknesses / opportunities for improvements Duration: aim for 35 minutes including class discussion Send me slides a few days before the presentation","title":"Student Presentations"},{"location":"econ890/econ890.html","text":"Econ890: Topics in Income and Wealth Distribution \u00b6 Spring 2021. Prof. Lutz Hendricks. UNC Announcements \u00b6 Mar-16: Background lecture on top incomes Mar-4: Material on programming and Julia (still very preliminary). Feb-20: Background lecture on earnings distribution . Course Description \u00b6 Econ890 is a graduate course aimed at PhD students in their second year or higher. It is part of the macro field but may be of interest to students specializing in public policy or even applied micro. The course will focus on wealth and income inequality , mostly within countries. The objectives will be: Learn about state of the art research in the area of inequality and perhaps cross-country income differences. Develop ideas for research projects in the area. Organization \u00b6 The class meets MW 9:05-10:20 in Carolina 104. The sakai site mainly holds material that should not be visible to the public. The organization will be similar to a reading group. There will be a few lectures to provide background material and review classic papers from the literature. But most of the course will consist of student presentations that would be structured like discussions at a conference. The assumption is that everyone has read the papers discussed in each class meeting (probably 4 papers a week). The presenters offer insights into what makes each paper tick, what is compelling and what is not. Much of the time will be spent on simply discussing each paper. Over time, students come up with project ideas. Once a promising idea is identified, each student develops it as far as possible. This will at least entail placing the idea into the context of the literature, identifying the contribution, and outlining a model. The end product would be a fully written up research proposal. At various points during the class, students present their project ideas and receive comments from the class. In the past, this course covered computational methods as well. I have come to the conclusion that mixing these with the economic material is not productive. The department needs a dedicated course on computing structural models, but Econ890 is not that. (But, this too, is up for discussion.) Grading \u00b6 Grades will be based on: class presentations (35%) class participation (40%) research proposal(s) (25%) Student Presentations \u00b6 A typical class will discuss two papers; so we have about 35 minutes per paper. The discussion will be structured around a presentation that should be structured like a discussion at a conference. The presentation should accomplish the following: Briefly summarize what the paper does (assume everyone has read it). Focus on key features of the analysis (no details). Comment on what drives results / key assumptions. Identify weaknesses / opportunities for improvements. Send me your slides a few days before the presentation. Examples of what good discussions look like: Ellen McGrattan Research proposal(s) \u00b6 At various points in time, students are expected to present ideas for possible research papers. At the end of the course, one of these ideas will be written up as a proposal. This will look a bit like the introduction to a paper: state the question explain why it is important explain how it contributes to the literature explain the approach and why it is reasonable sketch a model and possible data sources outline possible conclusions / the paper's message. Outline \u00b6 The outline links to the papers that we will discuss. The exact dates will be filled in as students sign up for presentations. Links \u00b6 Online course in macro development","title":"Econ890"},{"location":"econ890/econ890.html#econ890-topics-in-income-and-wealth-distribution","text":"Spring 2021. Prof. Lutz Hendricks. UNC","title":"Econ890: Topics in Income and Wealth Distribution"},{"location":"econ890/econ890.html#announcements","text":"Mar-16: Background lecture on top incomes Mar-4: Material on programming and Julia (still very preliminary). Feb-20: Background lecture on earnings distribution .","title":"Announcements"},{"location":"econ890/econ890.html#course-description","text":"Econ890 is a graduate course aimed at PhD students in their second year or higher. It is part of the macro field but may be of interest to students specializing in public policy or even applied micro. The course will focus on wealth and income inequality , mostly within countries. The objectives will be: Learn about state of the art research in the area of inequality and perhaps cross-country income differences. Develop ideas for research projects in the area.","title":"Course Description"},{"location":"econ890/econ890.html#organization","text":"The class meets MW 9:05-10:20 in Carolina 104. The sakai site mainly holds material that should not be visible to the public. The organization will be similar to a reading group. There will be a few lectures to provide background material and review classic papers from the literature. But most of the course will consist of student presentations that would be structured like discussions at a conference. The assumption is that everyone has read the papers discussed in each class meeting (probably 4 papers a week). The presenters offer insights into what makes each paper tick, what is compelling and what is not. Much of the time will be spent on simply discussing each paper. Over time, students come up with project ideas. Once a promising idea is identified, each student develops it as far as possible. This will at least entail placing the idea into the context of the literature, identifying the contribution, and outlining a model. The end product would be a fully written up research proposal. At various points during the class, students present their project ideas and receive comments from the class. In the past, this course covered computational methods as well. I have come to the conclusion that mixing these with the economic material is not productive. The department needs a dedicated course on computing structural models, but Econ890 is not that. (But, this too, is up for discussion.)","title":"Organization"},{"location":"econ890/econ890.html#grading","text":"Grades will be based on: class presentations (35%) class participation (40%) research proposal(s) (25%)","title":"Grading"},{"location":"econ890/econ890.html#student-presentations","text":"A typical class will discuss two papers; so we have about 35 minutes per paper. The discussion will be structured around a presentation that should be structured like a discussion at a conference. The presentation should accomplish the following: Briefly summarize what the paper does (assume everyone has read it). Focus on key features of the analysis (no details). Comment on what drives results / key assumptions. Identify weaknesses / opportunities for improvements. Send me your slides a few days before the presentation. Examples of what good discussions look like: Ellen McGrattan","title":"Student Presentations"},{"location":"econ890/econ890.html#research-proposals","text":"At various points in time, students are expected to present ideas for possible research papers. At the end of the course, one of these ideas will be written up as a proposal. This will look a bit like the introduction to a paper: state the question explain why it is important explain how it contributes to the literature explain the approach and why it is reasonable sketch a model and possible data sources outline possible conclusions / the paper's message.","title":"Research proposal(s)"},{"location":"econ890/econ890.html#outline","text":"The outline links to the papers that we will discuss. The exact dates will be filled in as students sign up for presentations.","title":"Outline"},{"location":"econ890/econ890.html#links","text":"Online course in macro development","title":"Links"},{"location":"econ890/julia/code_loading.html","text":"Code Loading \u00b6 When you write a file with some code, how does Julia know where to find it? From the REPL include(/path/to/file.jl) does the trick. This has the same effect as typing the code in the REPL. The same can be done inside another file. But what if you have a big chunk of code that you want to be reusable? What if you want to use someone else's code? This is where packages come into play. The LOAD_PATH \u00b6 You can also load modules that are not packaged as packages by putting their directories into the LOAD_PATH environment variable. We will not use this approach. It is easier to package everything as a package instead.","title":"Code Loading"},{"location":"econ890/julia/code_loading.html#code-loading","text":"When you write a file with some code, how does Julia know where to find it? From the REPL include(/path/to/file.jl) does the trick. This has the same effect as typing the code in the REPL. The same can be done inside another file. But what if you have a big chunk of code that you want to be reusable? What if you want to use someone else's code? This is where packages come into play.","title":"Code Loading"},{"location":"econ890/julia/code_loading.html#the-load_path","text":"You can also load modules that are not packaged as packages by putting their directories into the LOAD_PATH environment variable. We will not use this approach. It is easier to package everything as a package instead.","title":"The LOAD_PATH"},{"location":"econ890/julia/debugging.html","text":"Debugging \u00b6 Some general notes and tips are here .","title":"Debugging"},{"location":"econ890/julia/debugging.html#debugging","text":"Some general notes and tips are here .","title":"Debugging"},{"location":"econ890/julia/econ_examples.html","text":"Econ Examples \u00b6 Example: Two period household \u00b6 Household solves \\(\\max u\\left(c,g\\right)\\) subject to \\(y=c+s \\) and \\(g=z+sR\\) A solution: \\(c,g,s\\) that solve 2 budget constraints and Euler equation \\(u_{c}=u_{g} R \\) Assume \\(u\\left(c,g\\right)=\\frac{c^{1-\\sigma}}{1-\\sigma}+\\beta\\frac{g^{1-\\sigma}}{1-\\sigma} \\) Pseudo code \u00b6 This is not a trivial program to write. So we break it down into trivial steps. See Tips on programming We design top-down. Level 1: \u00b6 Task: Find optimal \\(c\\). Set parameters. Set up a grid of values for c For each c: Calculate deviation from Euler equation. Find the c with the smallest deviation. Note: Usually one would not restrict \\(c\\) to lie on a grid. Level 2: \u00b6 Task: Calculate deviation from Euler equation. Given: guess for \\(c\\), parameter values Use budget constraints to calculate \\(s,g\\) Return deviation: \\( dev=u_{c}-u_{g}R \\) Level 3: \u00b6 Utility function. Return \\(u_{c} \\) and \\(u_{g} \\) for given \\(c,g\\) and parameters. Code \u00b6 We write the code bottom up. Utility function: Allow matrix inputs (cM, gM). Parameters as arguments. This should really be a general purpose function (my library contains an OOP version ). Sample call: >> hh_example_821(2, 0.5, 1.04, 0.9, 1.5) c = 1.224490 Dev = 0.034947 Exercises \u00b6 Write a CES utility function that computes \\(u'(c)\\) and \\(u(c)\\). Write a function that computes the inverse of \\(u'(c)\\). Write a test function that checks properties of the utility function: The inverse of the inverse equals \\(u'(c)\\). Marginal utility is decreasing. Extra credit: Package all of that into an object (a user defined data type). Now write all of this for \\(u(c)=e^{-\\phi c}\\). In your test function, set things up so that you only need to change a single line of code to test both utility functions (the benefit of OOP in action).","title":"Econ Examples"},{"location":"econ890/julia/econ_examples.html#econ-examples","text":"","title":"Econ Examples"},{"location":"econ890/julia/econ_examples.html#example-two-period-household","text":"Household solves \\(\\max u\\left(c,g\\right)\\) subject to \\(y=c+s \\) and \\(g=z+sR\\) A solution: \\(c,g,s\\) that solve 2 budget constraints and Euler equation \\(u_{c}=u_{g} R \\) Assume \\(u\\left(c,g\\right)=\\frac{c^{1-\\sigma}}{1-\\sigma}+\\beta\\frac{g^{1-\\sigma}}{1-\\sigma} \\)","title":"Example: Two period household"},{"location":"econ890/julia/econ_examples.html#pseudo-code","text":"This is not a trivial program to write. So we break it down into trivial steps. See Tips on programming We design top-down.","title":"Pseudo code"},{"location":"econ890/julia/econ_examples.html#level-1","text":"Task: Find optimal \\(c\\). Set parameters. Set up a grid of values for c For each c: Calculate deviation from Euler equation. Find the c with the smallest deviation. Note: Usually one would not restrict \\(c\\) to lie on a grid.","title":"Level 1:"},{"location":"econ890/julia/econ_examples.html#level-2","text":"Task: Calculate deviation from Euler equation. Given: guess for \\(c\\), parameter values Use budget constraints to calculate \\(s,g\\) Return deviation: \\( dev=u_{c}-u_{g}R \\)","title":"Level 2:"},{"location":"econ890/julia/econ_examples.html#level-3","text":"Utility function. Return \\(u_{c} \\) and \\(u_{g} \\) for given \\(c,g\\) and parameters.","title":"Level 3:"},{"location":"econ890/julia/econ_examples.html#code","text":"We write the code bottom up. Utility function: Allow matrix inputs (cM, gM). Parameters as arguments. This should really be a general purpose function (my library contains an OOP version ). Sample call: >> hh_example_821(2, 0.5, 1.04, 0.9, 1.5) c = 1.224490 Dev = 0.034947","title":"Code"},{"location":"econ890/julia/econ_examples.html#exercises","text":"Write a CES utility function that computes \\(u'(c)\\) and \\(u(c)\\). Write a function that computes the inverse of \\(u'(c)\\). Write a test function that checks properties of the utility function: The inverse of the inverse equals \\(u'(c)\\). Marginal utility is decreasing. Extra credit: Package all of that into an object (a user defined data type). Now write all of this for \\(u(c)=e^{-\\phi c}\\). In your test function, set things up so that you only need to change a single line of code to test both utility functions (the benefit of OOP in action).","title":"Exercises"},{"location":"econ890/julia/functions.html","text":"Functions and Scripts \u00b6 Encapsulation \u00b6 A key idea of structured programming : package code into self-contained functions avoid side effects A function should only change the rest of the world through the outputs it explicitly returns. This is called encapsulation . For this to work, all variables inside a function must be invisible to other code -- they are local . Example: \u00b6 julia> function f(x) a = 5; y = x + a; return y end f (generic function with 1 method) julia> a = 3; y = f(0) 5 julia> a 3 # Now the converse julia> function g(x) z = x + a; end g (generic function with 1 method) julia> g(1) 4 Note that g could see the variable a=3 defined in the REPL, but not the a inside of f . Setting a=3 in the REPL defined a global variable which is visible everywhere. Defining a variable inside a function produces a local variable instead. Passing by reference \u00b6 Variables are passed into functions \"by reference.\" This means that modifying a function argument changes its value after the function returns: julia> function h(x) x[1] = 2; println(x); return nothing end h (generic function with 1 method) julia> z = [1,2]; julia> h(z) [2, 2] julia> z 2-element Array{Int64,1}: 2 2 But note that this does not happen when the argument is immutable . julia> function h2(x) x = 19; @show x; return nothing end h2 (generic function with 1 method) julia> z = \"input\" \"input\" julia> h2(z) x = 19 julia> z \"input\" Namespaces \u00b6 A namespace is a set of functions or scripts that can \"see\" the same objects. Example: In the function f(x) above, a was in f(x) 's namespace, but not in g(x) 's. Conversely, the a inside f(x) is local and not in the command line's namespace. In Julia, namespaces are created by modules. Even what you run in the REPL lives in a module called Main . julia> module Foo f(x) = x ^ 2; end Main.Foo julia> f(2) ERROR: UndefVarError: f not defined Stacktrace: [1] top-level scope at REPL[3]:1 julia> using .Foo julia> Foo.f(2) 4 Functions versus Scripts \u00b6 Scripts are simply collections of commands that are run as if they were typed at the command prompt. Scripts run in the global namespace (in Main or in whatever module they are in). This is, generally speaking, not good. They create side effects. Rule of thumb: Always use functions, never scripts! Functions are similar to scripts with one crucial difference: All variables inside a function are private . Other functions cannot see the variables inside a function ( encapsulation ). Any variable a function should know must be passed to it as an input argument. Any variable to be retained after the function finishes must be passed out of it as a return argument. An important principle of structured programming: Package a well-defined task into a function with a simple interface. A function looks like this function f(x, y) # Do stuff with x and y -> z return z end A side note: Even built-in commands are often written in Julia. Global Variables \u00b6 To make a variable visible from anywhere, define it as a global . Remark: Avoid globals where possible. Unless they are constants. A function should be a self-contained unit with a clear interface to the outside world (via its input and output arguments). Globals create confusion.","title":"Functions and Scripts #"},{"location":"econ890/julia/functions.html#functions-and-scripts","text":"","title":"Functions and Scripts"},{"location":"econ890/julia/functions.html#encapsulation","text":"A key idea of structured programming : package code into self-contained functions avoid side effects A function should only change the rest of the world through the outputs it explicitly returns. This is called encapsulation . For this to work, all variables inside a function must be invisible to other code -- they are local .","title":"Encapsulation"},{"location":"econ890/julia/functions.html#example","text":"julia> function f(x) a = 5; y = x + a; return y end f (generic function with 1 method) julia> a = 3; y = f(0) 5 julia> a 3 # Now the converse julia> function g(x) z = x + a; end g (generic function with 1 method) julia> g(1) 4 Note that g could see the variable a=3 defined in the REPL, but not the a inside of f . Setting a=3 in the REPL defined a global variable which is visible everywhere. Defining a variable inside a function produces a local variable instead.","title":"Example:"},{"location":"econ890/julia/functions.html#passing-by-reference","text":"Variables are passed into functions \"by reference.\" This means that modifying a function argument changes its value after the function returns: julia> function h(x) x[1] = 2; println(x); return nothing end h (generic function with 1 method) julia> z = [1,2]; julia> h(z) [2, 2] julia> z 2-element Array{Int64,1}: 2 2 But note that this does not happen when the argument is immutable . julia> function h2(x) x = 19; @show x; return nothing end h2 (generic function with 1 method) julia> z = \"input\" \"input\" julia> h2(z) x = 19 julia> z \"input\"","title":"Passing by reference"},{"location":"econ890/julia/functions.html#namespaces","text":"A namespace is a set of functions or scripts that can \"see\" the same objects. Example: In the function f(x) above, a was in f(x) 's namespace, but not in g(x) 's. Conversely, the a inside f(x) is local and not in the command line's namespace. In Julia, namespaces are created by modules. Even what you run in the REPL lives in a module called Main . julia> module Foo f(x) = x ^ 2; end Main.Foo julia> f(2) ERROR: UndefVarError: f not defined Stacktrace: [1] top-level scope at REPL[3]:1 julia> using .Foo julia> Foo.f(2) 4","title":"Namespaces"},{"location":"econ890/julia/functions.html#functions-versus-scripts","text":"Scripts are simply collections of commands that are run as if they were typed at the command prompt. Scripts run in the global namespace (in Main or in whatever module they are in). This is, generally speaking, not good. They create side effects. Rule of thumb: Always use functions, never scripts! Functions are similar to scripts with one crucial difference: All variables inside a function are private . Other functions cannot see the variables inside a function ( encapsulation ). Any variable a function should know must be passed to it as an input argument. Any variable to be retained after the function finishes must be passed out of it as a return argument. An important principle of structured programming: Package a well-defined task into a function with a simple interface. A function looks like this function f(x, y) # Do stuff with x and y -> z return z end A side note: Even built-in commands are often written in Julia.","title":"Functions versus Scripts"},{"location":"econ890/julia/functions.html#global-variables","text":"To make a variable visible from anywhere, define it as a global . Remark: Avoid globals where possible. Unless they are constants. A function should be a self-contained unit with a clear interface to the outside world (via its input and output arguments). Globals create confusion.","title":"Global Variables"},{"location":"econ890/julia/getting_started.html","text":"Installing Julia \u00b6 I recommend running Julia from a terminal window with Visual Studio Code as editor. Installation hints Info on VS Code You also need the Julia VS Code extension. See also VSCode: the future for Julia development - TechyTok You may have another favorite text editor, but you will lose integration with the Julia language. Useful guides to getting started: QuantEcon The Julia documentation is really very good. It should be your go-to place for getting started. I find it useful to install a documentation browser (on MacOS that would be Dash ). It is faster to interact with the docs this way. Installation details \u00b6 Download the binary for your platform. Follow the instructions in the \"help\" link for your platform. You should add a path to the Julia binary in the terminal. Try that you can start Julia by typing julia from a terminal window. You should see the REPL . Type using Pkg . Type Pkg.add(\"OhMyREPL\") . You will see some registry updating messages. These can take time. Type Pkg.add(\"Revise\") . This adds the essential package Revise.jl . It massively improves the Julia workflow. Exit Julia by typing exit() . You are back at the terminal prompt. Edit \"~/.julia/config/startup.jl\" and add the line using OhMyREPL, Revise . This ensures that those packages are used every time you start Julia. Start Julia again and type Revise . This should not give an error message, indicating the Revise was installed successfully. Interacting with Julia \u00b6 At the terminal, type julia to start a Julia session. You will see the REPL, which is similar to Matlab's command line. At the REPL, you can type any Julia command and see the results displayed. Note the REPL inputs (and all Julia commands) are case sensitive. ? switches to REPL help mode. For example, ?abs will give help on the abs function: ?abs abs(x) The absolute value of `x`. When `abs` is applied to signed integers, overflow may occur, resulting in the return of a negative value. This overflow occurs only when `abs` is applied to the minimum representable value of a signed integer. That is, when `x == typemin(typeof(x))`, `abs(x) == x < 0`, not `-x` as might be expected. # Examples ```jldoctest julia> abs(-3) 3 julia> abs(1 + im) 1.4142135623730951 julia> abs(typemin(Int64)) -9223372036854775808 After Installation \u00b6 Once Julia is installed and running, it is useful to install a few helper packages. In the REPL, type using Pkg; Pkg.add(\"OhMyREPL\"); Pkg.add(\"Revise\"); This will take some time to execute. You should also: create a symlink (linux or macos) to the julia binary set the path to the Julia binary in the VS Code extension After making changes to installed packages, you should always restart the REPL. Ctrl-D quits the REPL.","title":"Installing Julia"},{"location":"econ890/julia/getting_started.html#installing-julia","text":"I recommend running Julia from a terminal window with Visual Studio Code as editor. Installation hints Info on VS Code You also need the Julia VS Code extension. See also VSCode: the future for Julia development - TechyTok You may have another favorite text editor, but you will lose integration with the Julia language. Useful guides to getting started: QuantEcon The Julia documentation is really very good. It should be your go-to place for getting started. I find it useful to install a documentation browser (on MacOS that would be Dash ). It is faster to interact with the docs this way.","title":"Installing Julia"},{"location":"econ890/julia/getting_started.html#installation-details","text":"Download the binary for your platform. Follow the instructions in the \"help\" link for your platform. You should add a path to the Julia binary in the terminal. Try that you can start Julia by typing julia from a terminal window. You should see the REPL . Type using Pkg . Type Pkg.add(\"OhMyREPL\") . You will see some registry updating messages. These can take time. Type Pkg.add(\"Revise\") . This adds the essential package Revise.jl . It massively improves the Julia workflow. Exit Julia by typing exit() . You are back at the terminal prompt. Edit \"~/.julia/config/startup.jl\" and add the line using OhMyREPL, Revise . This ensures that those packages are used every time you start Julia. Start Julia again and type Revise . This should not give an error message, indicating the Revise was installed successfully.","title":"Installation details"},{"location":"econ890/julia/getting_started.html#interacting-with-julia","text":"At the terminal, type julia to start a Julia session. You will see the REPL, which is similar to Matlab's command line. At the REPL, you can type any Julia command and see the results displayed. Note the REPL inputs (and all Julia commands) are case sensitive. ? switches to REPL help mode. For example, ?abs will give help on the abs function: ?abs abs(x) The absolute value of `x`. When `abs` is applied to signed integers, overflow may occur, resulting in the return of a negative value. This overflow occurs only when `abs` is applied to the minimum representable value of a signed integer. That is, when `x == typemin(typeof(x))`, `abs(x) == x < 0`, not `-x` as might be expected. # Examples ```jldoctest julia> abs(-3) 3 julia> abs(1 + im) 1.4142135623730951 julia> abs(typemin(Int64)) -9223372036854775808","title":"Interacting with Julia"},{"location":"econ890/julia/getting_started.html#after-installation","text":"Once Julia is installed and running, it is useful to install a few helper packages. In the REPL, type using Pkg; Pkg.add(\"OhMyREPL\"); Pkg.add(\"Revise\"); This will take some time to execute. You should also: create a symlink (linux or macos) to the julia binary set the path to the Julia binary in the VS Code extension After making changes to installed packages, you should always restart the REPL. Ctrl-D quits the REPL.","title":"After Installation"},{"location":"econ890/julia/oop.html","text":"Object Oriented Programming (OOP) \u00b6 The Idea \u00b6 OOP takes structured programming to the next level. Structured programming encapsulates local data in a function. The user does not need to know anything about the function other than the interface (inputs and outputs). OOP recognizes that some groups of functions \"hang together\" because they operate on the same object. One idea is to group these functions together. The second idea is that certain persistent data \"belong to\" an object. They should only be manipulated by functions that also \"belong to\" the object. OOP therefore bundles data (called properties ) and functions (called methods ) together. Example: Utility function \u00b6 \\(u(c,l) = c ^{(1-\\sigma)} / (1-\\sigma) + \\phi \\log(l)\\) Persistent data include: parameters (\\(\\sigma, \\phi\\)). Methods include: compute \\(u_{c}, u(c,l)\\), inverse marginal utility, indifference curves. Benefits \u00b6 There is nothing that OOP can do that could not be done without OOP. The benefits lie in code organization. The programmer sees all methods that operate on the object in one place. That makes it easier to test the code modify the code ensure consistency Since all code is in one place, it is easy to swap out. Imagine you want to compute a model with different utility functions. With OOP, all you need to do is swap out the utility function object. Ideally, the other code remains unchanged. Drawbacks \u00b6 Some view OOP as misguided. The focus should be on algorithms or interfaces, not objects. I don't think there is a right answer. Some code \"naturally\" structures itself around objects. Example: Utility functions, their parameters, and the obvious methods (computing utility, marginal utility, ...). Other code \"naturally\" structures itself around algorithms. This is particularly true for \"lower level\" tasks, such as sorting. References \u00b6 Matlab documentation on object oriented programming .","title":"Object Oriented Programming (OOP) #"},{"location":"econ890/julia/oop.html#object-oriented-programming-oop","text":"","title":"Object Oriented Programming (OOP)"},{"location":"econ890/julia/oop.html#the-idea","text":"OOP takes structured programming to the next level. Structured programming encapsulates local data in a function. The user does not need to know anything about the function other than the interface (inputs and outputs). OOP recognizes that some groups of functions \"hang together\" because they operate on the same object. One idea is to group these functions together. The second idea is that certain persistent data \"belong to\" an object. They should only be manipulated by functions that also \"belong to\" the object. OOP therefore bundles data (called properties ) and functions (called methods ) together.","title":"The Idea"},{"location":"econ890/julia/oop.html#example-utility-function","text":"\\(u(c,l) = c ^{(1-\\sigma)} / (1-\\sigma) + \\phi \\log(l)\\) Persistent data include: parameters (\\(\\sigma, \\phi\\)). Methods include: compute \\(u_{c}, u(c,l)\\), inverse marginal utility, indifference curves.","title":"Example: Utility function"},{"location":"econ890/julia/oop.html#benefits","text":"There is nothing that OOP can do that could not be done without OOP. The benefits lie in code organization. The programmer sees all methods that operate on the object in one place. That makes it easier to test the code modify the code ensure consistency Since all code is in one place, it is easy to swap out. Imagine you want to compute a model with different utility functions. With OOP, all you need to do is swap out the utility function object. Ideally, the other code remains unchanged.","title":"Benefits"},{"location":"econ890/julia/oop.html#drawbacks","text":"Some view OOP as misguided. The focus should be on algorithms or interfaces, not objects. I don't think there is a right answer. Some code \"naturally\" structures itself around objects. Example: Utility functions, their parameters, and the obvious methods (computing utility, marginal utility, ...). Other code \"naturally\" structures itself around algorithms. This is particularly true for \"lower level\" tasks, such as sorting.","title":"Drawbacks"},{"location":"econ890/julia/oop.html#references","text":"Matlab documentation on object oriented programming .","title":"References"},{"location":"econ890/julia/outline.html","text":"Julia for Economists \u00b6 Our approach will be to compute a version of the classic Huggett (1996) model. We will start simple, but eventually (time permitting) get to the point where our code will be well structured, reusable, and tested. Table of Contents \u00b6 Basics \u00b6 Getting started Types and variables Functions Writing solid code Object oriented programming Packages Testing Debugging Solving a Permanent Income Model \u00b6 Simple minded approach OOP approach Shooting approach Policy function iteration","title":"Julia for Economists"},{"location":"econ890/julia/outline.html#julia-for-economists","text":"Our approach will be to compute a version of the classic Huggett (1996) model. We will start simple, but eventually (time permitting) get to the point where our code will be well structured, reusable, and tested.","title":"Julia for Economists"},{"location":"econ890/julia/outline.html#table-of-contents","text":"","title":"Table of Contents"},{"location":"econ890/julia/outline.html#basics","text":"Getting started Types and variables Functions Writing solid code Object oriented programming Packages Testing Debugging","title":"Basics"},{"location":"econ890/julia/outline.html#solving-a-permanent-income-model","text":"Simple minded approach OOP approach Shooting approach Policy function iteration","title":"Solving a Permanent Income Model"},{"location":"econ890/julia/packages.html","text":"Packages \u00b6 A package is a directory with code that declares all of its dependencies. It is self-contained. A package is a type of \"environment\". Environments \u00b6 This is a key concept for Julia! At any point in time, Julia activates one directory as the active environment. This determines which packages (think code libraries) can be loaded with using MyPackage . To keep track of what is visible, the directory that contains a file Project.toml file. This file declares all of the available packages, their versions, and their locations. When you start Julia, you are in the v1.5 environment (replace the 1.5 with the Julia version that you are using). Tip: keep this environment minimal. Here you just want to list packages that you use while developing your code (e.g. Revise.jl ). If you look at Project.toml , you see something like: shell> cat ~/.julia/environments/v1.6/Project.toml [deps] OhMyREPL = \"5fb14364-9ced-5910-84b2-373655c76a03\" Revise = \"295af30f-e4ad-537b-8983-00126c2a3abe\" Each line gives the name and UUID (a unique id) of each available package. An easier way of seeing the same info: julia> using Pkg julia> Pkg.status() Status `~/.julia/environments/v1.5/Project.toml` [5fb14364] OhMyREPL v0.5.10 [295af30f] Revise v3.1.12 This means that using Revise will make the code in Revise.jl available. But if I try using Plots , I get an error message: julia> using Plots ERROR: ArgumentError: Package Plots not found in current path: - Run `import Pkg; Pkg.add(\"Plots\")` to install the Plots package. This basically says: Julia cannot find an entry for Plots in Project.toml . So the code cannot be used until I run Pkg.add(\"Plots\") . If you now activate a different directory using Pkg.activate(\"/path/to/dir\") , additional packages become available. Note that the packages known from v1.5 are not \"forgotten.\" Each time I activate a new environment, packages get added to the known list of loadable packages. This is known as stacked environments . They are stacked in the sense that activating another environment retains the packages that are already activated. This is the reason why you want your v.1.5 environment to be minimal. The Registry \u00b6 Packages are often registered: the authors create an entry in the Julia General Registry for their package. If this is the case, Pkg.add(\"Revise\") works. Julia looks up the most recent version in the registry and downloads the code from a github repo. The code goes into a hidden directory in .julia/packages . Each version of Revise that you ever use gets stored there. You rarely need to worry about where this code lives. If a package is not registered, presumably because you wrote it yourself, using it gets a bit more complicated. A good approach is to create your own local registry (using LocalRegistry.jl ). Then your not officially registered packages are treated like registered ones. For starter purposes, the alternative is to develop your packages instead with Pkg.develop(/path/to/MyPackage) . What does this do? It simply adds an entry in Project.toml that links the package name MyPackage to the directory where the code can be found. There is one fundamental difference between add and develop . add fixes the version of the package until you manually Pkg.update(\"MyPackage\") . Even if the developer changes the code, the version that you are using remains unchanged. develop tells Julia to track whatever code changes happen in the directory where the package code resides (the one you provide with the develop command). Packages \u00b6 So, what is a package? It really is a special case of an environment that satisfies some additional criteria (e.g., a specific directory structure is present). One expectation is that src/MyPackage.jl defines the module MyPackage plus types and functions. To use a package, write using MyPackage and voila - all the types and functions defined in MyPackage are available in your code, including the code MyPackage requires from other packages. Dependency Hell \u00b6 So, you create an environment and add packages A and B . Both A and B depend on X and Y , but X also depends on Y . But when different people wrote A , B , and X they were using different versions of Y (and perhaps also of X ). How can the resulting code possibly run successfully? This problem is called \"dependency hell\". The solution relies on meaningful version numbers together with explicity compatibility specifications. Version numbers (at least for registered packages) have precise meaning. Minor version bumps (e.g. from 1.4 to 1.5 ) are expected to be non-breaking . They can add features, but not change the existing API. This is called semantic versioning and it is the cornerstone of decentralized software development. Each package's Project.toml contains a [compat] section that specifies the versions of all packages that are compatible. The package manager's job is to combine the Project.toml s of all packages used (directly or indirectly) and to figure out a combination of version numbers that satisfies all compatibility requirements. One might expect that this could never work in a project that uses dozens of packages, but, surprisingly, it generally works out just fine.","title":"Packages"},{"location":"econ890/julia/packages.html#packages","text":"A package is a directory with code that declares all of its dependencies. It is self-contained. A package is a type of \"environment\".","title":"Packages"},{"location":"econ890/julia/packages.html#environments","text":"This is a key concept for Julia! At any point in time, Julia activates one directory as the active environment. This determines which packages (think code libraries) can be loaded with using MyPackage . To keep track of what is visible, the directory that contains a file Project.toml file. This file declares all of the available packages, their versions, and their locations. When you start Julia, you are in the v1.5 environment (replace the 1.5 with the Julia version that you are using). Tip: keep this environment minimal. Here you just want to list packages that you use while developing your code (e.g. Revise.jl ). If you look at Project.toml , you see something like: shell> cat ~/.julia/environments/v1.6/Project.toml [deps] OhMyREPL = \"5fb14364-9ced-5910-84b2-373655c76a03\" Revise = \"295af30f-e4ad-537b-8983-00126c2a3abe\" Each line gives the name and UUID (a unique id) of each available package. An easier way of seeing the same info: julia> using Pkg julia> Pkg.status() Status `~/.julia/environments/v1.5/Project.toml` [5fb14364] OhMyREPL v0.5.10 [295af30f] Revise v3.1.12 This means that using Revise will make the code in Revise.jl available. But if I try using Plots , I get an error message: julia> using Plots ERROR: ArgumentError: Package Plots not found in current path: - Run `import Pkg; Pkg.add(\"Plots\")` to install the Plots package. This basically says: Julia cannot find an entry for Plots in Project.toml . So the code cannot be used until I run Pkg.add(\"Plots\") . If you now activate a different directory using Pkg.activate(\"/path/to/dir\") , additional packages become available. Note that the packages known from v1.5 are not \"forgotten.\" Each time I activate a new environment, packages get added to the known list of loadable packages. This is known as stacked environments . They are stacked in the sense that activating another environment retains the packages that are already activated. This is the reason why you want your v.1.5 environment to be minimal.","title":"Environments"},{"location":"econ890/julia/packages.html#the-registry","text":"Packages are often registered: the authors create an entry in the Julia General Registry for their package. If this is the case, Pkg.add(\"Revise\") works. Julia looks up the most recent version in the registry and downloads the code from a github repo. The code goes into a hidden directory in .julia/packages . Each version of Revise that you ever use gets stored there. You rarely need to worry about where this code lives. If a package is not registered, presumably because you wrote it yourself, using it gets a bit more complicated. A good approach is to create your own local registry (using LocalRegistry.jl ). Then your not officially registered packages are treated like registered ones. For starter purposes, the alternative is to develop your packages instead with Pkg.develop(/path/to/MyPackage) . What does this do? It simply adds an entry in Project.toml that links the package name MyPackage to the directory where the code can be found. There is one fundamental difference between add and develop . add fixes the version of the package until you manually Pkg.update(\"MyPackage\") . Even if the developer changes the code, the version that you are using remains unchanged. develop tells Julia to track whatever code changes happen in the directory where the package code resides (the one you provide with the develop command).","title":"The Registry"},{"location":"econ890/julia/packages.html#packages_1","text":"So, what is a package? It really is a special case of an environment that satisfies some additional criteria (e.g., a specific directory structure is present). One expectation is that src/MyPackage.jl defines the module MyPackage plus types and functions. To use a package, write using MyPackage and voila - all the types and functions defined in MyPackage are available in your code, including the code MyPackage requires from other packages.","title":"Packages"},{"location":"econ890/julia/packages.html#dependency-hell","text":"So, you create an environment and add packages A and B . Both A and B depend on X and Y , but X also depends on Y . But when different people wrote A , B , and X they were using different versions of Y (and perhaps also of X ). How can the resulting code possibly run successfully? This problem is called \"dependency hell\". The solution relies on meaningful version numbers together with explicity compatibility specifications. Version numbers (at least for registered packages) have precise meaning. Minor version bumps (e.g. from 1.4 to 1.5 ) are expected to be non-breaking . They can add features, but not change the existing API. This is called semantic versioning and it is the cornerstone of decentralized software development. Each package's Project.toml contains a [compat] section that specifies the versions of all packages that are compatible. The package manager's job is to combine the Project.toml s of all packages used (directly or indirectly) and to figure out a combination of version numbers that satisfies all compatibility requirements. One might expect that this could never work in a project that uses dozens of packages, but, surprisingly, it generally works out just fine.","title":"Dependency Hell"},{"location":"econ890/julia/solid_code.html","text":"Writing Solid Code \u00b6 This section discusses general programming concepts. Structured Programming \u00b6 Break down a process into chunks. Package each chunk into a separate function. A key idea: aside from an explicitly specified set of inputs and outputs, the function is independent of the rest of the world ( encapsulation ). Write your code top down by stepwise refinement Start with an outline of the steps. For each step: if it's trivial: write it out in pseudo code . it it's not: write another outline for that step Finally, translate the pseudo code into code. Each function should be short and perform exactly one task . Write reusable code \u00b6 Write each function to be sufficiently general, so it can be reused in other projects. Over time, you will accumulate a library of code that can be used over and over. Example: Write code that produces marginal products, average costs, etc for a CES production function. Notes on Writing Code \u00b6 Read a good book on best practices in programming. I see a lot of very poorly written code that is impossible to understand and not robust. Do yourself a favor and save a lot of time down the road by learning to how write quality code. A book I like is \"Writing Solid Code.\" Some rules \u00b6 No literals as in x=zeros([5,3]) or for i1 = 1 : 57 . It's not robust and hard to read. No global variables. Don't worry about speed. Worry about robustness and transparency. Your code should contain lots of self-testing code. Most code is so fast that the loss of speed is irrelevant. If it is relevant, have a switch that globally switches test code on and off. Avoid using reserved words, in particular i as an index. Style matters \u00b6 This point is hard to overstate. It is extremely important to write code that is easy to understand and easy to maintain. In practice, you often revisit programs months or years after they were written. They need to be well documented and well structured. The programs needed to solve a stochastic OLG model have thousands of lines of code. The only way to understand something this complex is to break it into logical, self-contained pieces (a function that solves the household problem, another that solves the firm problem, etc.). One example of how important this is: Air traffic control centers still operate with hardware from the 1970s. The reason is that nobody understands the software well enough to port it to new hardware. The FAA has already spent billions of dollars on unsuccessful attempts to rewrite this mess. Another example is the Space Shuttle, which runs (now \"ran\") on hardware from the 1960s. The reason is again that the software engineers can no longer understand the existing code. There are many books on good programming style. One that I like is Writing Solid Code by Steve Maguire. Read it! Avoid literals \u00b6 Your code should rarely use specific values for any object. When you refer to an object, do so by its name. For example, create variables to hold directory names and constants. The reason is that code is otherwise hard to change and maintain. Imagine you set some parameter sigma=2 , but refer to it as 2 in your code instead of sigma . If you decide to try sigma = 3 , you need to locate and change every occurrence of sigma in your code. It's a mess. The Golden Rule is: Every literal must have a name. Its value is defined in one place only. Related to this: do not hard-code functional forms . If you want to compute the marginal product of capital, write a function for it. Otherwise, if you want to switch from Cobb-Douglas to CES, you have to rewrite all your programs. Object oriented programming makes it easy to swap out entire parts of a model. We will talk about this later. Self-Test Code \u00b6 Your code should test itself automatically and periodically. Embed error catching code everywhere (use valideattributes ). Catching bugs early makes them easier to find. A trick to prevent your code from getting slowed down by self-testing: add a debugging switch as an input argument to each function (I call it dbg ). if dbg == false : go for speed and turn off self-testing if dbg == true , run all self-test code The process is then: Write code. Make sure it runs (correct syntax). Make sure it is correct (run all self-test code -- slow) When you are confident that your code is good, set dbg = false and go for speed But every now and then, randomly switch dbg on so that self tests are run (little cost in terms of run time; a lot of gain in terms of confidence in your code). Optimization \u00b6 Optimization refers to program modifications that speed up execution. Think before you optimize! Most code runs so fast that optimization is simply a waste of time. Also: Beware of your intuition about where the program spends most of its time. Here is an example: Consider the function that solves a stochastic OLG model. It turns out that it spends 80% of its time running the Matlab interpolation function interp1 ! There is little point optimizing the rest of the code. To find out what makes your program slow, use a Profiler. Common mistakes \u00b6 Passing arguments in the wrong order. \u00b6 Often functions have lots of input arguments. This is generally a sign of poor design. It is easy to confuse the order and write myfun(b,a) instead of myfun(a,b) . To avoid this: check that inputs have admissible values. Reusing variable names. \u00b6 It is easy to use a variable name twice without noticing. This can produce tricky bugs. One way of avoiding this: keep your functions short . Some experts advocate that functions should be 4 lines of code or less. This is probably not realistic, but you get the idea. Indexing problems. \u00b6 It is easy to make mistakes when extracting elements from matrices. This is especially true for code that wraps a loop into a single line of code. For example, this is easy to read: for ix = 1 : nx zV[ix] = xV[ix+2] + yV[nx + 2 - ix]; end This is the same thing, more compact but harder to read: zV = xV[3 : nx+2] .+ yV[nx+1 : -1 : 2]; Tip: Write out code explicitly. Once it works, one can still make it faster (if that is even worthwhile). Note that vectorizing code does not improve speed in Julia (unless you exploit the parallel execution capabilities of modern CPUs). Another common indexing mistake is to use too few arguments. For example: x = rand([3,4]); y = x(3); This should produce a syntax error, but it does not. Instead, it flattens x into a vector and then takes the 3rd element. Material for Economists \u00b6 Quantitative Economics by Sargent and Stachursky a really nice collection of lectures and exercises that covers both programming and the economics of the material (in Julia and Python) Tony Smith: Tips for quantitative work in economics Material Not for Economists \u00b6 Lifehacker: teach yourself how to code","title":"Writing Solid Code"},{"location":"econ890/julia/solid_code.html#writing-solid-code","text":"This section discusses general programming concepts.","title":"Writing Solid Code"},{"location":"econ890/julia/solid_code.html#structured-programming","text":"Break down a process into chunks. Package each chunk into a separate function. A key idea: aside from an explicitly specified set of inputs and outputs, the function is independent of the rest of the world ( encapsulation ). Write your code top down by stepwise refinement Start with an outline of the steps. For each step: if it's trivial: write it out in pseudo code . it it's not: write another outline for that step Finally, translate the pseudo code into code. Each function should be short and perform exactly one task .","title":"Structured Programming"},{"location":"econ890/julia/solid_code.html#write-reusable-code","text":"Write each function to be sufficiently general, so it can be reused in other projects. Over time, you will accumulate a library of code that can be used over and over. Example: Write code that produces marginal products, average costs, etc for a CES production function.","title":"Write reusable code"},{"location":"econ890/julia/solid_code.html#notes-on-writing-code","text":"Read a good book on best practices in programming. I see a lot of very poorly written code that is impossible to understand and not robust. Do yourself a favor and save a lot of time down the road by learning to how write quality code. A book I like is \"Writing Solid Code.\"","title":"Notes on Writing Code"},{"location":"econ890/julia/solid_code.html#some-rules","text":"No literals as in x=zeros([5,3]) or for i1 = 1 : 57 . It's not robust and hard to read. No global variables. Don't worry about speed. Worry about robustness and transparency. Your code should contain lots of self-testing code. Most code is so fast that the loss of speed is irrelevant. If it is relevant, have a switch that globally switches test code on and off. Avoid using reserved words, in particular i as an index.","title":"Some rules"},{"location":"econ890/julia/solid_code.html#style-matters","text":"This point is hard to overstate. It is extremely important to write code that is easy to understand and easy to maintain. In practice, you often revisit programs months or years after they were written. They need to be well documented and well structured. The programs needed to solve a stochastic OLG model have thousands of lines of code. The only way to understand something this complex is to break it into logical, self-contained pieces (a function that solves the household problem, another that solves the firm problem, etc.). One example of how important this is: Air traffic control centers still operate with hardware from the 1970s. The reason is that nobody understands the software well enough to port it to new hardware. The FAA has already spent billions of dollars on unsuccessful attempts to rewrite this mess. Another example is the Space Shuttle, which runs (now \"ran\") on hardware from the 1960s. The reason is again that the software engineers can no longer understand the existing code. There are many books on good programming style. One that I like is Writing Solid Code by Steve Maguire. Read it!","title":"Style matters"},{"location":"econ890/julia/solid_code.html#avoid-literals","text":"Your code should rarely use specific values for any object. When you refer to an object, do so by its name. For example, create variables to hold directory names and constants. The reason is that code is otherwise hard to change and maintain. Imagine you set some parameter sigma=2 , but refer to it as 2 in your code instead of sigma . If you decide to try sigma = 3 , you need to locate and change every occurrence of sigma in your code. It's a mess. The Golden Rule is: Every literal must have a name. Its value is defined in one place only. Related to this: do not hard-code functional forms . If you want to compute the marginal product of capital, write a function for it. Otherwise, if you want to switch from Cobb-Douglas to CES, you have to rewrite all your programs. Object oriented programming makes it easy to swap out entire parts of a model. We will talk about this later.","title":"Avoid literals"},{"location":"econ890/julia/solid_code.html#self-test-code","text":"Your code should test itself automatically and periodically. Embed error catching code everywhere (use valideattributes ). Catching bugs early makes them easier to find. A trick to prevent your code from getting slowed down by self-testing: add a debugging switch as an input argument to each function (I call it dbg ). if dbg == false : go for speed and turn off self-testing if dbg == true , run all self-test code The process is then: Write code. Make sure it runs (correct syntax). Make sure it is correct (run all self-test code -- slow) When you are confident that your code is good, set dbg = false and go for speed But every now and then, randomly switch dbg on so that self tests are run (little cost in terms of run time; a lot of gain in terms of confidence in your code).","title":"Self-Test Code"},{"location":"econ890/julia/solid_code.html#optimization","text":"Optimization refers to program modifications that speed up execution. Think before you optimize! Most code runs so fast that optimization is simply a waste of time. Also: Beware of your intuition about where the program spends most of its time. Here is an example: Consider the function that solves a stochastic OLG model. It turns out that it spends 80% of its time running the Matlab interpolation function interp1 ! There is little point optimizing the rest of the code. To find out what makes your program slow, use a Profiler.","title":"Optimization"},{"location":"econ890/julia/solid_code.html#common-mistakes","text":"","title":"Common mistakes"},{"location":"econ890/julia/solid_code.html#passing-arguments-in-the-wrong-order","text":"Often functions have lots of input arguments. This is generally a sign of poor design. It is easy to confuse the order and write myfun(b,a) instead of myfun(a,b) . To avoid this: check that inputs have admissible values.","title":"Passing arguments in the wrong order."},{"location":"econ890/julia/solid_code.html#reusing-variable-names","text":"It is easy to use a variable name twice without noticing. This can produce tricky bugs. One way of avoiding this: keep your functions short . Some experts advocate that functions should be 4 lines of code or less. This is probably not realistic, but you get the idea.","title":"Reusing variable names."},{"location":"econ890/julia/solid_code.html#indexing-problems","text":"It is easy to make mistakes when extracting elements from matrices. This is especially true for code that wraps a loop into a single line of code. For example, this is easy to read: for ix = 1 : nx zV[ix] = xV[ix+2] + yV[nx + 2 - ix]; end This is the same thing, more compact but harder to read: zV = xV[3 : nx+2] .+ yV[nx+1 : -1 : 2]; Tip: Write out code explicitly. Once it works, one can still make it faster (if that is even worthwhile). Note that vectorizing code does not improve speed in Julia (unless you exploit the parallel execution capabilities of modern CPUs). Another common indexing mistake is to use too few arguments. For example: x = rand([3,4]); y = x(3); This should produce a syntax error, but it does not. Instead, it flattens x into a vector and then takes the 3rd element.","title":"Indexing problems."},{"location":"econ890/julia/solid_code.html#material-for-economists","text":"Quantitative Economics by Sargent and Stachursky a really nice collection of lectures and exercises that covers both programming and the economics of the material (in Julia and Python) Tony Smith: Tips for quantitative work in economics","title":"Material for Economists"},{"location":"econ890/julia/solid_code.html#material-not-for-economists","text":"Lifehacker: teach yourself how to code","title":"Material Not for Economists"},{"location":"econ890/julia/testing.html","text":"Testing \u00b6 The golden rule: When you write a function, write a test function to go with it. It is hard to overstate the importance of automated testing. It gives you peace of mind. When you change some code, you can simply rerun your test suite and ensure that nothing has been broken. The key is to fully automate the testing. Your project should have a single function that runs all tests in order. All programming languages have unit testing frameworks that make it easy to automate this process. Julia's is described here .","title":"Testing"},{"location":"econ890/julia/testing.html#testing","text":"The golden rule: When you write a function, write a test function to go with it. It is hard to overstate the importance of automated testing. It gives you peace of mind. When you change some code, you can simply rerun your test suite and ensure that nothing has been broken. The key is to fully automate the testing. Your project should have a single function that runs all tests in order. All programming languages have unit testing frameworks that make it easy to automate this process. Julia's is described here .","title":"Testing"},{"location":"econ890/julia/types.html","text":"Variables and Types \u00b6 When you issue an assignment statement, such as x = 2 you create a variable called x . What does this actually mean? Julia creates a place in memory where the value 2 is stored. It then creates a \"binding\" so that the symbol :x from now on points to that location in memory. (This is actually not the way it works for scalar real numbers, but we will set this detail aside right now.) The memory location now has a type . In this case, it is Int64 : typeof(x) Int64 Julia is dynamically typed . This means that I can change the type of x by simply reassigning a new value or by converting the value to a different type: x=Float64(x) 2.0 Doing this kind of thing is generally a bad idea, but it is legal. It is a bad idea because it confuses the reader of the code and the compiler. Important types include: Scalar numbers, such as 1 or 1.0 . Strings, such as \"this is a string\". Arrays of numbers, such as [1 2; 3 4] . Dict : a container that maps names to values; similar to a struct in Matlab. Struct : a composite type with fixed fields; similar to a class in Matlab. Supertypes and Subtypes \u00b6 One DataType is Number . This includes integers, floating point numbers, etc. Types come in hierarchies. For example: Base.show_supertypes(Int64) Int64 <: Signed <: Integer <: Real <: Number <: Any shows that Int64 is a subtype of Signed etc. Only the \"lowest\" types in the hierarchy are concrete types that can actually be assigned values. The higher up types are abstract . They only exist to make a type hierarchy. Why do types come in a hierarchy? Mainly because some functions are defined on certain groups of types, but not on others. For example, sin(\"abc\") does not make sense, but sin(x) makes sense for various types of Number . Scalar Numbers \u00b6 The main Number types that we care about are integers and floats. Integers come in various flavors depending on how many digits they can store and whether or not they are signed. The default is Int64 which stores 64 bits and is signed. UInt8 requires only 8 bits, but it cannot store large values. Overflow warning: if you assign a value that is too large for a type to store, you get overflow issues: y=UInt8(12345678) InexactError: trunc(UInt8, 12345678) Stacktrace: [1] throw_inexacterror(::Symbol, ::Type{UInt8}, ::Int64) at ./boot.jl:558 [2] checked_trunc_uint at ./boot.jl:588 [inlined] [3] toUInt8 at ./boot.jl:650 [inlined] [4] UInt8(::Int64) at ./boot.jl:710 [5] top-level scope at In[5]:1 [6] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091 This throws an error because Julia cannot convert a large number to a UInt8 . The several lines below the error message are a stack trace . It shows where in your code the error occurred. This is important for debugging. Vectors \u00b6 To create a vector, simply fill it with values: a = [1, 2, 3] 3-element Array{Int64,1}: 1 2 3 Vectors are simply one-dimensional array s. julia> Vector{Int} === Array{Int,1} true There are no row vectors in Julia. A row vector is a 1xN Matrix : julia> a = [1 2 3] 1\u00d73 Array{Int64,2}: 1 2 3 julia> a isa Matrix{Int} true Indexing \u00b6 To extract elements from a vector, hand it a list of indices. a = [2, 3, 4, 5]; # Note the double brackets a[[1, 3]] 2-element Array{Int64,1}: 2 4 # What we are really doing is idx = [1, 3]; a[idx] Then there is logical indexing: a = [1, 2, 3]; a[[true, false, true]] 2-element Array{Int64,1}: 1 3 Ranges \u00b6 In Matlab, 1:3 is a Vector , but not in Julia: julia> 1:3 1:3 julia> typeof(1:3) UnitRange{Int64} The main difference between a Vector and a Range is that the vector is allocated upon construction (its values are computed and stored in memory). A Range is an Iterator . You can iteratore over its elements, but they are not computed until needed. Therefore, the Range does not allocate memory. This is a big deal when lots of values are involved. However, a Range is an AbstractArray ; so all the indexing that works on Vectors also works on Range s. Exercises \u00b6 Start with x = 1 : 3 : 30 . Find all even elements. Find all elements between 5 and 20. Set all even elements to their negative values. Matrices \u00b6 A Matrix is a 2-dimensional array. There are also n-dimensional arrays (see below). To create a matrix, simply fill it with values. julia> a = [1 2 3; 4 5 6] 2\u00d73 Array{Int64,2}: 1 2 3 4 5 6 Many commands work directly on matrices. julia> a = [1 2 3]; b = [2; 1; 1]; a * b 1-element Array{Int64,1}: 7 julia> c=b*a 3\u00d73 Array{Int64,2}: 2 4 6 1 2 3 1 2 3 To extract elements: julia> c[1,2] 4 julia> c[1:2, 2:3] 2\u00d72 Array{Int64,2}: 4 6 2 3 To extract a row (but note that this produces a Vector ): julia> c[1,:] 3-element Array{Int64,1}: 2 4 6 Linear indexing works as well: julia> c[4] 4 julia> c[4] == c[1,2] true In memory, Arrays are stored like Vectors . The compiler just keeps track of how the user wants to interpret the data. Multi-dimensional Arrays \u00b6 Arrays can have more than 2 dimensions. julia> using Random julia> a = rand(4,3,2) 4\u00d73\u00d72 Array{Float64,3}: [:, :, 1] = 0.146411 0.908415 0.568039 0.444156 0.434034 0.875361 0.429705 0.704086 0.71789 0.502228 0.124412 0.771808 [:, :, 2] = 0.862953 0.58189 0.549077 0.722745 0.677342 0.330188 0.0543144 0.161877 0.358381 0.312414 0.0681076 0.822319 Indexing generates new arrays with potentially fewer dimensions: julia> a[:,1,:] 4\u00d72 Array{Float64,2}: 0.146411 0.862953 0.444156 0.722745 0.429705 0.0543144 0.502228 0.312414 Array Exercises \u00b6 Construct a matrix A with elements [2,4,...,20] in row 1 and [1,4,7,...,28] in row 2. Replace row 1 with its square. Find all columns where row 1 > row 2. Let x=ones(10,1) . Compute Ax . Strings \u00b6 In contrast to Matlab, Strings are not Vector{Char} . They are their own type. A String is created by providing characters inside quotes: a = \"This is a string\" But strings can be indexed like character vectors: julia> a[4] 's': ASCII/Unicode U+0073 (category Ll: Letter, lowercase)","title":"Variables and Types"},{"location":"econ890/julia/types.html#variables-and-types","text":"When you issue an assignment statement, such as x = 2 you create a variable called x . What does this actually mean? Julia creates a place in memory where the value 2 is stored. It then creates a \"binding\" so that the symbol :x from now on points to that location in memory. (This is actually not the way it works for scalar real numbers, but we will set this detail aside right now.) The memory location now has a type . In this case, it is Int64 : typeof(x) Int64 Julia is dynamically typed . This means that I can change the type of x by simply reassigning a new value or by converting the value to a different type: x=Float64(x) 2.0 Doing this kind of thing is generally a bad idea, but it is legal. It is a bad idea because it confuses the reader of the code and the compiler. Important types include: Scalar numbers, such as 1 or 1.0 . Strings, such as \"this is a string\". Arrays of numbers, such as [1 2; 3 4] . Dict : a container that maps names to values; similar to a struct in Matlab. Struct : a composite type with fixed fields; similar to a class in Matlab.","title":"Variables and Types"},{"location":"econ890/julia/types.html#supertypes-and-subtypes","text":"One DataType is Number . This includes integers, floating point numbers, etc. Types come in hierarchies. For example: Base.show_supertypes(Int64) Int64 <: Signed <: Integer <: Real <: Number <: Any shows that Int64 is a subtype of Signed etc. Only the \"lowest\" types in the hierarchy are concrete types that can actually be assigned values. The higher up types are abstract . They only exist to make a type hierarchy. Why do types come in a hierarchy? Mainly because some functions are defined on certain groups of types, but not on others. For example, sin(\"abc\") does not make sense, but sin(x) makes sense for various types of Number .","title":"Supertypes and Subtypes"},{"location":"econ890/julia/types.html#scalar-numbers","text":"The main Number types that we care about are integers and floats. Integers come in various flavors depending on how many digits they can store and whether or not they are signed. The default is Int64 which stores 64 bits and is signed. UInt8 requires only 8 bits, but it cannot store large values. Overflow warning: if you assign a value that is too large for a type to store, you get overflow issues: y=UInt8(12345678) InexactError: trunc(UInt8, 12345678) Stacktrace: [1] throw_inexacterror(::Symbol, ::Type{UInt8}, ::Int64) at ./boot.jl:558 [2] checked_trunc_uint at ./boot.jl:588 [inlined] [3] toUInt8 at ./boot.jl:650 [inlined] [4] UInt8(::Int64) at ./boot.jl:710 [5] top-level scope at In[5]:1 [6] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091 This throws an error because Julia cannot convert a large number to a UInt8 . The several lines below the error message are a stack trace . It shows where in your code the error occurred. This is important for debugging.","title":"Scalar Numbers"},{"location":"econ890/julia/types.html#vectors","text":"To create a vector, simply fill it with values: a = [1, 2, 3] 3-element Array{Int64,1}: 1 2 3 Vectors are simply one-dimensional array s. julia> Vector{Int} === Array{Int,1} true There are no row vectors in Julia. A row vector is a 1xN Matrix : julia> a = [1 2 3] 1\u00d73 Array{Int64,2}: 1 2 3 julia> a isa Matrix{Int} true","title":"Vectors"},{"location":"econ890/julia/types.html#indexing","text":"To extract elements from a vector, hand it a list of indices. a = [2, 3, 4, 5]; # Note the double brackets a[[1, 3]] 2-element Array{Int64,1}: 2 4 # What we are really doing is idx = [1, 3]; a[idx] Then there is logical indexing: a = [1, 2, 3]; a[[true, false, true]] 2-element Array{Int64,1}: 1 3","title":"Indexing"},{"location":"econ890/julia/types.html#ranges","text":"In Matlab, 1:3 is a Vector , but not in Julia: julia> 1:3 1:3 julia> typeof(1:3) UnitRange{Int64} The main difference between a Vector and a Range is that the vector is allocated upon construction (its values are computed and stored in memory). A Range is an Iterator . You can iteratore over its elements, but they are not computed until needed. Therefore, the Range does not allocate memory. This is a big deal when lots of values are involved. However, a Range is an AbstractArray ; so all the indexing that works on Vectors also works on Range s.","title":"Ranges"},{"location":"econ890/julia/types.html#exercises","text":"Start with x = 1 : 3 : 30 . Find all even elements. Find all elements between 5 and 20. Set all even elements to their negative values.","title":"Exercises"},{"location":"econ890/julia/types.html#matrices","text":"A Matrix is a 2-dimensional array. There are also n-dimensional arrays (see below). To create a matrix, simply fill it with values. julia> a = [1 2 3; 4 5 6] 2\u00d73 Array{Int64,2}: 1 2 3 4 5 6 Many commands work directly on matrices. julia> a = [1 2 3]; b = [2; 1; 1]; a * b 1-element Array{Int64,1}: 7 julia> c=b*a 3\u00d73 Array{Int64,2}: 2 4 6 1 2 3 1 2 3 To extract elements: julia> c[1,2] 4 julia> c[1:2, 2:3] 2\u00d72 Array{Int64,2}: 4 6 2 3 To extract a row (but note that this produces a Vector ): julia> c[1,:] 3-element Array{Int64,1}: 2 4 6 Linear indexing works as well: julia> c[4] 4 julia> c[4] == c[1,2] true In memory, Arrays are stored like Vectors . The compiler just keeps track of how the user wants to interpret the data.","title":"Matrices"},{"location":"econ890/julia/types.html#multi-dimensional-arrays","text":"Arrays can have more than 2 dimensions. julia> using Random julia> a = rand(4,3,2) 4\u00d73\u00d72 Array{Float64,3}: [:, :, 1] = 0.146411 0.908415 0.568039 0.444156 0.434034 0.875361 0.429705 0.704086 0.71789 0.502228 0.124412 0.771808 [:, :, 2] = 0.862953 0.58189 0.549077 0.722745 0.677342 0.330188 0.0543144 0.161877 0.358381 0.312414 0.0681076 0.822319 Indexing generates new arrays with potentially fewer dimensions: julia> a[:,1,:] 4\u00d72 Array{Float64,2}: 0.146411 0.862953 0.444156 0.722745 0.429705 0.0543144 0.502228 0.312414","title":"Multi-dimensional Arrays"},{"location":"econ890/julia/types.html#array-exercises","text":"Construct a matrix A with elements [2,4,...,20] in row 1 and [1,4,7,...,28] in row 2. Replace row 1 with its square. Find all columns where row 1 > row 2. Let x=ones(10,1) . Compute Ax .","title":"Array Exercises"},{"location":"econ890/julia/types.html#strings","text":"In contrast to Matlab, Strings are not Vector{Char} . They are their own type. A String is created by providing characters inside quotes: a = \"This is a string\" But strings can be indexed like character vectors: julia> a[4] 's': ASCII/Unicode U+0073 (category Ll: Letter, lowercase)","title":"Strings"},{"location":"econ890/julia/pih/pih1.html","text":"Solving a Permanent Income Model \u00b6 Eventually, we want to solve Huggett (1996), but that's complicated. So we start simpler. Model \u00b6 A household lives for \\(T\\) periods. Preferences are \\(\\sum_{t=1}^T \\beta^t \\frac{c_{t}^{1-\\sigma}}{1-\\sigma}\\) Lifetime income is \\(Y\\) . Lifetime budget constraint: \\(Y=\\sum_{t=1}^T R^{1-t} c_t\\) Solution \u00b6 The consumption growth rate is given by \\(g(c)=(\\beta R)^{1/\\sigma}\\) . Present value of consumption: \\[ Y=\\sum_t R^{1-t} c_t = c_1 \\sum_t [g(c)/R]^{1-t} \\] Recall: \\(\\sum_{t=0}^{T-1} x_t = \\frac{x^T - 1}{x - 1}\\) Therefore: \\[Y=c_{1}\\frac{\\left[g(c)/R\\right]^{T}-1}{g\\left(c\\right)/R-1}\\] Algorithm \u00b6 Inputs: \\(Y, R, T, \\beta, \\sigma\\) . Compute \\(c_1\\) . \\(c_t = c_1 g(c)^{t-1}\\) Excercise: write this! My solution Testing \u00b6 We need a test. This is where using packages comes in handy: it makes writing tests easy. For now, we just wing it and write a test script. We want to test: Euler equation holds. Budget constraint holds. Exercise: write this! Changing the Utility Function \u00b6 In real world applications, you want to explore alternative functional forms etc. Let's try log utility instead. In our simple example, this is easy because log utility is just the special case of \\(\\sigma=1\\) . But let's pretend this were not the case (we cannot try any old utility function because we have baked into our solution that consumption growth is a constant). This simple change requires that we hunt through all of our code to find which lines depend on the functional form for utility. Once we have found all of those, we need to replace each with if logUtility # use the log expression else # use the CRRA expression end And then we have to keep track of the fact that each utility function requires its own set of parameters. Those parameters have to be passed from one function to the next all throughout the code. There has to be a better way!","title":"Solving a Permanent Income Model"},{"location":"econ890/julia/pih/pih1.html#solving-a-permanent-income-model","text":"Eventually, we want to solve Huggett (1996), but that's complicated. So we start simpler.","title":"Solving a Permanent Income Model"},{"location":"econ890/julia/pih/pih1.html#model","text":"A household lives for \\(T\\) periods. Preferences are \\(\\sum_{t=1}^T \\beta^t \\frac{c_{t}^{1-\\sigma}}{1-\\sigma}\\) Lifetime income is \\(Y\\) . Lifetime budget constraint: \\(Y=\\sum_{t=1}^T R^{1-t} c_t\\)","title":"Model"},{"location":"econ890/julia/pih/pih1.html#solution","text":"The consumption growth rate is given by \\(g(c)=(\\beta R)^{1/\\sigma}\\) . Present value of consumption: \\[ Y=\\sum_t R^{1-t} c_t = c_1 \\sum_t [g(c)/R]^{1-t} \\] Recall: \\(\\sum_{t=0}^{T-1} x_t = \\frac{x^T - 1}{x - 1}\\) Therefore: \\[Y=c_{1}\\frac{\\left[g(c)/R\\right]^{T}-1}{g\\left(c\\right)/R-1}\\]","title":"Solution"},{"location":"econ890/julia/pih/pih1.html#algorithm","text":"Inputs: \\(Y, R, T, \\beta, \\sigma\\) . Compute \\(c_1\\) . \\(c_t = c_1 g(c)^{t-1}\\) Excercise: write this! My solution","title":"Algorithm"},{"location":"econ890/julia/pih/pih1.html#testing","text":"We need a test. This is where using packages comes in handy: it makes writing tests easy. For now, we just wing it and write a test script. We want to test: Euler equation holds. Budget constraint holds. Exercise: write this!","title":"Testing"},{"location":"econ890/julia/pih/pih1.html#changing-the-utility-function","text":"In real world applications, you want to explore alternative functional forms etc. Let's try log utility instead. In our simple example, this is easy because log utility is just the special case of \\(\\sigma=1\\) . But let's pretend this were not the case (we cannot try any old utility function because we have baked into our solution that consumption growth is a constant). This simple change requires that we hunt through all of our code to find which lines depend on the functional form for utility. Once we have found all of those, we need to replace each with if logUtility # use the log expression else # use the CRRA expression end And then we have to keep track of the fact that each utility function requires its own set of parameters. Those parameters have to be passed from one function to the next all throughout the code. There has to be a better way!","title":"Changing the Utility Function"},{"location":"econ890/julia/pih/pih2.html","text":"Solving a Permanent Income Model: OOP Approach \u00b6 Our insight so far: hard-wiring functional forms does not work. How can we build a more flexible model? One approach: define a Model object it contains the fixed parameters \\(T\\) , \\(R\\) , \\(Y\\) plus another object that specifies preferences and their parameters Then we can: init the model with the right preferences and parameters just pass the Model around (not the collection of parameters) Factoring out Preferences \u00b6 Utility functions are not model specific (certainly not in this case). It would make sense to factor out all of the code that does utility calculations. Then we can: easily reuse that code in other projects test that code independently of everything else ensure that eacy utility function supports the same interface, so they can be easily swapped in and out. What do we want utility functions to do? compute \\(u(c)\\) and \\(u'(c)\\) it is often also useful to know inverse marginal utility compute the growth rate of \\(c\\) and (related) Euler equation deviations This defines the API that is visible to the outside world and common to all utility functions. Note: If we were a bit more serious, we would think about embedding all of this into a bigger set of utility functions that depend on multiple arguments. Let's start with log utility. Log has no parameters, so we have struct UtilityLog end But for CRRA we have struct UtilityCRRA sigma :: Float64 end Note: We generally would not want to hard-wire that sigma is a Float64 . More generic would be a parametric type : struct UtilityCRRA{T} sigma :: T end But we keep things simple for now. Since we are packaging the code, we should really put it into a module (or better: a package). But we defer this as well for later. Exercise: write code for the utility functions. My solution Exercise: write tests for the utility functions. My solution Making a Model \u00b6 Now we easily build a Model from its parts. struct Model Y :: Float64 R :: Float64 T :: Int beta :: Float64 u :: AbstractUtility end m = Model(10.0, 1.04, 30, 0.98, UtilityLog()); Note: switching out the utility function is now trivial adding new utility functions is just as trivial the code does not contain any if utilityLog type switches Exercise: Write this code - and don't forget the tests. My solution and the tests I packaged everything in modules because: eventually, this should go into a package (therefore into a module) once we define structs , we cannot repeatedly include the code (invalid redefinition of the struct) the module makes sure that we don't have side-effects.","title":"Solving a Permanent Income Model: OOP Approach"},{"location":"econ890/julia/pih/pih2.html#solving-a-permanent-income-model-oop-approach","text":"Our insight so far: hard-wiring functional forms does not work. How can we build a more flexible model? One approach: define a Model object it contains the fixed parameters \\(T\\) , \\(R\\) , \\(Y\\) plus another object that specifies preferences and their parameters Then we can: init the model with the right preferences and parameters just pass the Model around (not the collection of parameters)","title":"Solving a Permanent Income Model: OOP Approach"},{"location":"econ890/julia/pih/pih2.html#factoring-out-preferences","text":"Utility functions are not model specific (certainly not in this case). It would make sense to factor out all of the code that does utility calculations. Then we can: easily reuse that code in other projects test that code independently of everything else ensure that eacy utility function supports the same interface, so they can be easily swapped in and out. What do we want utility functions to do? compute \\(u(c)\\) and \\(u'(c)\\) it is often also useful to know inverse marginal utility compute the growth rate of \\(c\\) and (related) Euler equation deviations This defines the API that is visible to the outside world and common to all utility functions. Note: If we were a bit more serious, we would think about embedding all of this into a bigger set of utility functions that depend on multiple arguments. Let's start with log utility. Log has no parameters, so we have struct UtilityLog end But for CRRA we have struct UtilityCRRA sigma :: Float64 end Note: We generally would not want to hard-wire that sigma is a Float64 . More generic would be a parametric type : struct UtilityCRRA{T} sigma :: T end But we keep things simple for now. Since we are packaging the code, we should really put it into a module (or better: a package). But we defer this as well for later. Exercise: write code for the utility functions. My solution Exercise: write tests for the utility functions. My solution","title":"Factoring out Preferences"},{"location":"econ890/julia/pih/pih2.html#making-a-model","text":"Now we easily build a Model from its parts. struct Model Y :: Float64 R :: Float64 T :: Int beta :: Float64 u :: AbstractUtility end m = Model(10.0, 1.04, 30, 0.98, UtilityLog()); Note: switching out the utility function is now trivial adding new utility functions is just as trivial the code does not contain any if utilityLog type switches Exercise: Write this code - and don't forget the tests. My solution and the tests I packaged everything in modules because: eventually, this should go into a package (therefore into a module) once we define structs , we cannot repeatedly include the code (invalid redefinition of the struct) the module makes sure that we don't have side-effects.","title":"Making a Model"},{"location":"econ890/julia/pih/pih3.html","text":"Permanent Income Model 3: Shooting \u00b6 Generalize the model to non-homothetic preferences. Now \\(g(c)\\) depends on \\(c\\) . There is no closed-form solution. Algorithm: Shooting \u00b6 Search over values for \\(c_{T}\\) . For each: Compute \\(c_t\\) from the Euler equation (backwards). Compute the present value of consumption. Check the lifetime budget constraint. Interpolation \u00b6 A simple way of finding the optimal \\(c_T\\) : Compute the present value of consumption on a grid of \\(c_T\\) . Interpolate between grid points to find the value that satisfies the budget constraint. Exercise: write this code - and don't forget the tests In my solution , the interpolation is simply hand coded. Usually, one would use a package for this (such as Interpolations.jl ). Interpolation is, of course, inefficient. We need to compute a large number of grid points for \\(c_T\\) . A better solution is to use a numerical optimizer. Solving this model is an example of root finding. We are looking for the solution to \\(f(c_T)=0\\) . There are various libraries that offer algorithms for root finding and for the more common problem of minimizing a function. Using these libraries requires that we install packages . In this case, we will use Roots.jl . See root finding . find_zero finds the root of a function f(x) . This is what we will use. Excercise: write this code. My solution with test","title":"Permanent Income Model 3: Shooting"},{"location":"econ890/julia/pih/pih3.html#permanent-income-model-3-shooting","text":"Generalize the model to non-homothetic preferences. Now \\(g(c)\\) depends on \\(c\\) . There is no closed-form solution.","title":"Permanent Income Model 3: Shooting"},{"location":"econ890/julia/pih/pih3.html#algorithm-shooting","text":"Search over values for \\(c_{T}\\) . For each: Compute \\(c_t\\) from the Euler equation (backwards). Compute the present value of consumption. Check the lifetime budget constraint.","title":"Algorithm: Shooting"},{"location":"econ890/julia/pih/pih3.html#interpolation","text":"A simple way of finding the optimal \\(c_T\\) : Compute the present value of consumption on a grid of \\(c_T\\) . Interpolate between grid points to find the value that satisfies the budget constraint. Exercise: write this code - and don't forget the tests In my solution , the interpolation is simply hand coded. Usually, one would use a package for this (such as Interpolations.jl ). Interpolation is, of course, inefficient. We need to compute a large number of grid points for \\(c_T\\) . A better solution is to use a numerical optimizer. Solving this model is an example of root finding. We are looking for the solution to \\(f(c_T)=0\\) . There are various libraries that offer algorithms for root finding and for the more common problem of minimizing a function. Using these libraries requires that we install packages . In this case, we will use Roots.jl . See root finding . find_zero finds the root of a function f(x) . This is what we will use. Excercise: write this code. My solution with test","title":"Interpolation"},{"location":"econ890/julia/pih/pih4.html","text":"Permanent Income Model 4: Value Function Iteration \u00b6 Now we solve the model by backward induction. This is not efficient in this case, but gets us started on methods for the more general Huggett model. The math \u00b6 Bellman equation: \\[V(k,t)=\\max_{k'} U(w+rk-k') + \\beta V(k',t+1)\\] with first order condition \\[U'(w+rk-k')=\\beta V_{k}(k',t+1)\\] and envelope condition \\[V_{k}(k,t) = r U'(w + rk - k')\\] Value Function Iteration \u00b6 Start at \\(t = T\\) with \\[V(k,T) = U(w+rk)\\] Set up a grid for \\(k\\) . For each \\(k\\) on the grid: maximize \\(U(w+rk-k') + \\beta V(k',t+1)\\) by searching over \\(k'\\) this gives \\(k'=G(k,t)\\) compute \\(V(k,t) = U(w+rk-G(k,t)) + \\beta V(G(k,t), t+1)\\) Problem: We need to evaluate \\(V(k',t+1)\\) off the grid. Solution: Interpolation (below). This is inefficient it involves a numerical maximization for each \\(k\\) grid point it is much easier (numerically) to find a root than to maximize a function Approximate \\(V_{k}(k,t)\\) \u00b6 Start at \\(t=T\\) with \\[V_{k}(k,T)=U'(w+rk-k')\\] Set up a grid for \\(k\\) . For each \\(k\\) on the grid: Search for the root of \\(U'(w+rk-k')-\\beta V_{k}(k',t+1)\\) Compute the decision rule \\(k' = G(k,t)\\) Compute \\(V_{k}(k,t) = r U'(w + rk - G(k,t))\\) Problem: We have \\(V_{k}\\) on the grid, but for the root finding we need \\(V_{k}\\) off the grid. Solution: Construct a function that approximates \\(V_{k}\\) based on the grid points that we have computed. Problem: \\(V_{k}\\) is highly nonlinear, so it is hard to approximate. Solution: Restate the FOC as \\(w+rk-k'=U'^{-1}(\\beta V_{k}(k',t+1))\\) . Approximate the RHS of this expression. Find the root of the corresponding deviation: \\(k'=G(k,t)\\) . Use this to compute \\(V_{k}(k,t)\\) on the grid. Policy Function Iteration \u00b6 We don't really care about \\(V\\) or \\(V_{k}\\) . All we need is \\(k'=G(k,t)\\) . So we approximate this directly. Start at \\(t=T\\) with \\(G(k,T) = 0\\) . Set up a grid for \\(k\\) . For each \\(k\\) on the grid: find the root of the Euler equation \\( \\(U'(w+rk-k') - \\beta R U'(w'+rk'-G(k', t+1))\\) \\) but better (not as non-linear): \\( \\(w+rk-k' - U'^{-1}(\\beta R U'(w'+rk'-G(k', t+1)))\\) \\) this gives \\(k'=G(k,t)\\) on the \\(k\\) grid. Again, we need to interpolate the policy function between grid points. Notes on root finding . Let's think about this problem a bit more. The expression \\[w+rk-k' - U'^{-1}(\\beta R U'(w'+rk'-G(k', t+1)))\\] can be thought of as \\(D(k',k)\\) . We are looking for \\(D(k',k) = 0\\) . The solution is \\(G(k', t)\\) . Let's start from the \"inside\" of the problem. Suppose we have \\(D(k', k)\\) on the grid, our first task is to make this a continuous function. This is done with interpolation . One approach that we used before: each time we need to get a value \\(D(k', k)\\) , we call an interpolation function. But this is tedious and inelegant. The better approach is to construct a continuous function that represents \\(D(k', k)\\) . One package that does this is Interpolations.jl . QuantEcon contains a nice description that we will use here. Making a package \u00b6 Now that our code is getting more complex, it is time to make it into a package . Instructions for creating packages are here . Some details: It is helpful to have a github account and put your packages there. But you can skip this step for the purposes of this class. If you have a github account, you create your (empty) package there and then clone it to the local machine. Then you run PkgSkeleton or PkgTemplates to fill in the required Julia bits. After creating this package, copy utility.jl and its tests to src and test , respectively. Add dependencies (e.g., Pkg.add(\"Random\") ) until ] test works. Writing the solution code \u00b6 This looks complicated. So how do we make it tractable? Structured programming and top down design to the rescue. The trick is to simply write out the steps that we want to perform without worrying about how to do each: Solve the last period: \\(G(k', T) = 0\\) . This is trivial. For each \\(t\\) (backwards): Make a capital grid for period \\(t\\) . Find \\(k' = G(k, t)\\) for each grid point. Interpolate \\(G(k, t)\\) to make a continuous function. Now write this out in code and you have solve() in vfi.jl . Next, we fill in details. solve_last_period is basically trivial. solve_one_period just calls ... solve_one_point which checks for corner solutions runs find_zero on \\(D(k', k)\\) Finally, we need to check the solution to make sure it satisfies budget constraint and Euler equation Exercise: write this code","title":"Permanent Income Model 4: Value Function Iteration"},{"location":"econ890/julia/pih/pih4.html#permanent-income-model-4-value-function-iteration","text":"Now we solve the model by backward induction. This is not efficient in this case, but gets us started on methods for the more general Huggett model.","title":"Permanent Income Model 4: Value Function Iteration"},{"location":"econ890/julia/pih/pih4.html#the-math","text":"Bellman equation: \\[V(k,t)=\\max_{k'} U(w+rk-k') + \\beta V(k',t+1)\\] with first order condition \\[U'(w+rk-k')=\\beta V_{k}(k',t+1)\\] and envelope condition \\[V_{k}(k,t) = r U'(w + rk - k')\\]","title":"The math"},{"location":"econ890/julia/pih/pih4.html#value-function-iteration","text":"Start at \\(t = T\\) with \\[V(k,T) = U(w+rk)\\] Set up a grid for \\(k\\) . For each \\(k\\) on the grid: maximize \\(U(w+rk-k') + \\beta V(k',t+1)\\) by searching over \\(k'\\) this gives \\(k'=G(k,t)\\) compute \\(V(k,t) = U(w+rk-G(k,t)) + \\beta V(G(k,t), t+1)\\) Problem: We need to evaluate \\(V(k',t+1)\\) off the grid. Solution: Interpolation (below). This is inefficient it involves a numerical maximization for each \\(k\\) grid point it is much easier (numerically) to find a root than to maximize a function","title":"Value Function Iteration"},{"location":"econ890/julia/pih/pih4.html#approximate-v_kkt","text":"Start at \\(t=T\\) with \\[V_{k}(k,T)=U'(w+rk-k')\\] Set up a grid for \\(k\\) . For each \\(k\\) on the grid: Search for the root of \\(U'(w+rk-k')-\\beta V_{k}(k',t+1)\\) Compute the decision rule \\(k' = G(k,t)\\) Compute \\(V_{k}(k,t) = r U'(w + rk - G(k,t))\\) Problem: We have \\(V_{k}\\) on the grid, but for the root finding we need \\(V_{k}\\) off the grid. Solution: Construct a function that approximates \\(V_{k}\\) based on the grid points that we have computed. Problem: \\(V_{k}\\) is highly nonlinear, so it is hard to approximate. Solution: Restate the FOC as \\(w+rk-k'=U'^{-1}(\\beta V_{k}(k',t+1))\\) . Approximate the RHS of this expression. Find the root of the corresponding deviation: \\(k'=G(k,t)\\) . Use this to compute \\(V_{k}(k,t)\\) on the grid.","title":"Approximate \\(V_{k}(k,t)\\)"},{"location":"econ890/julia/pih/pih4.html#policy-function-iteration","text":"We don't really care about \\(V\\) or \\(V_{k}\\) . All we need is \\(k'=G(k,t)\\) . So we approximate this directly. Start at \\(t=T\\) with \\(G(k,T) = 0\\) . Set up a grid for \\(k\\) . For each \\(k\\) on the grid: find the root of the Euler equation \\( \\(U'(w+rk-k') - \\beta R U'(w'+rk'-G(k', t+1))\\) \\) but better (not as non-linear): \\( \\(w+rk-k' - U'^{-1}(\\beta R U'(w'+rk'-G(k', t+1)))\\) \\) this gives \\(k'=G(k,t)\\) on the \\(k\\) grid. Again, we need to interpolate the policy function between grid points. Notes on root finding . Let's think about this problem a bit more. The expression \\[w+rk-k' - U'^{-1}(\\beta R U'(w'+rk'-G(k', t+1)))\\] can be thought of as \\(D(k',k)\\) . We are looking for \\(D(k',k) = 0\\) . The solution is \\(G(k', t)\\) . Let's start from the \"inside\" of the problem. Suppose we have \\(D(k', k)\\) on the grid, our first task is to make this a continuous function. This is done with interpolation . One approach that we used before: each time we need to get a value \\(D(k', k)\\) , we call an interpolation function. But this is tedious and inelegant. The better approach is to construct a continuous function that represents \\(D(k', k)\\) . One package that does this is Interpolations.jl . QuantEcon contains a nice description that we will use here.","title":"Policy Function Iteration"},{"location":"econ890/julia/pih/pih4.html#making-a-package","text":"Now that our code is getting more complex, it is time to make it into a package . Instructions for creating packages are here . Some details: It is helpful to have a github account and put your packages there. But you can skip this step for the purposes of this class. If you have a github account, you create your (empty) package there and then clone it to the local machine. Then you run PkgSkeleton or PkgTemplates to fill in the required Julia bits. After creating this package, copy utility.jl and its tests to src and test , respectively. Add dependencies (e.g., Pkg.add(\"Random\") ) until ] test works.","title":"Making a package"},{"location":"econ890/julia/pih/pih4.html#writing-the-solution-code","text":"This looks complicated. So how do we make it tractable? Structured programming and top down design to the rescue. The trick is to simply write out the steps that we want to perform without worrying about how to do each: Solve the last period: \\(G(k', T) = 0\\) . This is trivial. For each \\(t\\) (backwards): Make a capital grid for period \\(t\\) . Find \\(k' = G(k, t)\\) for each grid point. Interpolate \\(G(k, t)\\) to make a continuous function. Now write this out in code and you have solve() in vfi.jl . Next, we fill in details. solve_last_period is basically trivial. solve_one_period just calls ... solve_one_point which checks for corner solutions runs find_zero on \\(D(k', k)\\) Finally, we need to check the solution to make sure it satisfies budget constraint and Euler equation Exercise: write this code","title":"Writing the solution code"},{"location":"econ890/julia/pih/root_finding.html","text":"Root Finding \u00b6 Root finding means finding the zero of a function, i.e., find \\(x^*\\) such that \\(f(x^*) = 0\\) . For this type of problem, we use code packaged into reusable libraries, called \"packages\". See the Section on Packages . In this case, we will use Roots.jl . Before we can use Roots , we need to add it as a dependency to the current environment : julia> cd(\"/Users/lutz/Documents/data/web/professional/docs/econ890/julia/\") (@v1.5) pkg> activate . Activating new environment at `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` We have now activated the environment described by Project.toml in this directory. To get the Pkg commands to work, type ] and the pkg> prompt appears. Backspace backs out of the Pkg mode in the REPL. To see which packages are already contained in the enviroment: (julia) pkg> st Status `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` (empty project) This makes sense; we have not added any packages yet. But keep in mind that everything we activated before (including all packages in your v1.5 environment are still available). Let's add Roots : (julia) pkg> add Roots Updating registry at `~/.julia/registries/General` ######################################################################## 100.0% Updating registry at `~/.julia/registries/registryLH` Updating git-repo `https://github.com/hendri54/registryLH` Resolving package versions... Updating `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` [f2b01f46] + Roots v1.0.8 Updating `~/Documents/data/web/professional/docs/econ890/julia/Manifest.toml` [f2b01f46] + Roots v1.0.8 [de0858da] + Printf [4ec0a83e] + Unicode (julia) pkg> st Status `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` [f2b01f46] Roots v1.0.8 Now using Roots works. Roots is a registered package, so it can be installed with pkg> add Roots . The package manager looks up where to find the files for Roots in the General Registry and downloads them. The code for Roots now resides in a subdirectory of .julia/packages . Each version of Roots gets its own subdirectory. So you can have several versions installed at the same time. But: Only one version of a package can be loaded at any given time. This can lead to interesting problems... Note that all of the dependencies of Roots were also installed automatically (in this case, Printf and Unicode ). Now we can use all functions that were exported by Roots.jl . For example: help?> find_zero search: find_zero find_zeros find_zero! find_zero(fs, x0, M, [N::AbstractBracketing]; kwargs...) Interface to one of several methods for find zeros of a univariate function. [...] julia> f(x) = exp(x) - x^4; julia> find_zero(f, (8, 9), Bisection()) 8.6131694564414 Closures \u00b6 We encounter a common problem: find_zero expects a one-argument function f(x) . But the function that we use takes 2 arguments: a model and \\(c_T\\) . This type of problem is solved using a closure . A closure is a function that \"captures\" some of the variables in the calling namespace. Example: julia> function foo() x = 1; g(y) = x + y; @show g(2) x = 2; @show g(2) end foo (generic function with 1 method) julia> foo() g(2) = 3 g(2) = 4 Note that g has \"captured\" the variable x from foo . g behaves as if there were an implicit second argument. Anonymous functions \u00b6 When closures are used, they often remain unnamed. Example: julia> findfirst(x -> x > 2, 1:10) 3 # This is the same as julia> f(x) = x > 2; julia> findfirst(f, 1:10) 3 But note: julia> [x -> x^2 for x in (1,2,3)] 3-element Array{var\"#9#11\",1}: #9 (generic function with 1 method) #9 (generic function with 1 method) #9 (generic function with 1 method)","title":"Root Finding"},{"location":"econ890/julia/pih/root_finding.html#root-finding","text":"Root finding means finding the zero of a function, i.e., find \\(x^*\\) such that \\(f(x^*) = 0\\) . For this type of problem, we use code packaged into reusable libraries, called \"packages\". See the Section on Packages . In this case, we will use Roots.jl . Before we can use Roots , we need to add it as a dependency to the current environment : julia> cd(\"/Users/lutz/Documents/data/web/professional/docs/econ890/julia/\") (@v1.5) pkg> activate . Activating new environment at `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` We have now activated the environment described by Project.toml in this directory. To get the Pkg commands to work, type ] and the pkg> prompt appears. Backspace backs out of the Pkg mode in the REPL. To see which packages are already contained in the enviroment: (julia) pkg> st Status `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` (empty project) This makes sense; we have not added any packages yet. But keep in mind that everything we activated before (including all packages in your v1.5 environment are still available). Let's add Roots : (julia) pkg> add Roots Updating registry at `~/.julia/registries/General` ######################################################################## 100.0% Updating registry at `~/.julia/registries/registryLH` Updating git-repo `https://github.com/hendri54/registryLH` Resolving package versions... Updating `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` [f2b01f46] + Roots v1.0.8 Updating `~/Documents/data/web/professional/docs/econ890/julia/Manifest.toml` [f2b01f46] + Roots v1.0.8 [de0858da] + Printf [4ec0a83e] + Unicode (julia) pkg> st Status `~/Documents/data/web/professional/docs/econ890/julia/Project.toml` [f2b01f46] Roots v1.0.8 Now using Roots works. Roots is a registered package, so it can be installed with pkg> add Roots . The package manager looks up where to find the files for Roots in the General Registry and downloads them. The code for Roots now resides in a subdirectory of .julia/packages . Each version of Roots gets its own subdirectory. So you can have several versions installed at the same time. But: Only one version of a package can be loaded at any given time. This can lead to interesting problems... Note that all of the dependencies of Roots were also installed automatically (in this case, Printf and Unicode ). Now we can use all functions that were exported by Roots.jl . For example: help?> find_zero search: find_zero find_zeros find_zero! find_zero(fs, x0, M, [N::AbstractBracketing]; kwargs...) Interface to one of several methods for find zeros of a univariate function. [...] julia> f(x) = exp(x) - x^4; julia> find_zero(f, (8, 9), Bisection()) 8.6131694564414","title":"Root Finding"},{"location":"econ890/julia/pih/root_finding.html#closures","text":"We encounter a common problem: find_zero expects a one-argument function f(x) . But the function that we use takes 2 arguments: a model and \\(c_T\\) . This type of problem is solved using a closure . A closure is a function that \"captures\" some of the variables in the calling namespace. Example: julia> function foo() x = 1; g(y) = x + y; @show g(2) x = 2; @show g(2) end foo (generic function with 1 method) julia> foo() g(2) = 3 g(2) = 4 Note that g has \"captured\" the variable x from foo . g behaves as if there were an implicit second argument.","title":"Closures"},{"location":"econ890/julia/pih/root_finding.html#anonymous-functions","text":"When closures are used, they often remain unnamed. Example: julia> findfirst(x -> x > 2, 1:10) 3 # This is the same as julia> f(x) = x > 2; julia> findfirst(f, 1:10) 3 But note: julia> [x -> x^2 for x in (1,2,3)] 3-element Array{var\"#9#11\",1}: #9 (generic function with 1 method) #9 (generic function with 1 method) #9 (generic function with 1 method)","title":"Anonymous functions"},{"location":"graduate/computational_econ.html","text":"References: Computational Methods \u00b6 Text Books for Macroeconomists \u00b6 Heer, Burkhard, and Alfred Maussner. \"Dynamic General Equilibrium Modelling Springer Berlin.\" Heidelberg, New York (2008).","title":"References: Computational Methods #"},{"location":"graduate/computational_econ.html#references-computational-methods","text":"","title":"References: Computational Methods"},{"location":"graduate/computational_econ.html#text-books-for-macroeconomists","text":"Heer, Burkhard, and Alfred Maussner. \"Dynamic General Equilibrium Modelling Springer Berlin.\" Heidelberg, New York (2008).","title":"Text Books for Macroeconomists"},{"location":"graduate/discussion_forums.html","text":"{{../markdown_header.txt}} Economics Discussion Forums \u00b6 EconSpark * seems focuses on job market, but there is a \"general questions\" section Forums that seem overrun by spam: * Debate.org","title":"Discussion forums"},{"location":"graduate/discussion_forums.html#economics-discussion-forums","text":"EconSpark * seems focuses on job market, but there is a \"general questions\" section Forums that seem overrun by spam: * Debate.org","title":"Economics Discussion Forums"},{"location":"graduate/dissertation_tips.html","text":"Dissertation Tips \u00b6 Finding a topic \u00b6 Work top down \u00b6 When you start out, you just don't know which questions are interesting, which have been answered, etc. So you start broadly. Pick something that interests you and start reading. Let's use cross-country income gaps as an example. Rich countries are 25 times richer than poor countries. Why? Start reading. Take notes on what you read. Organize your notes, so you understand the \"tree of questions\" in that literature. In our example, part of the tree may look like this: How important are capital, human capital, and productivity? Within human capital: how that this be measured? Why does it differ across countries? Within the measurement question: there is a Mincerian approach and a production function approach. Questions there: how can we measure inputs to human capital production? How can we estimate a production function? The point is to get from vague, broad questions to specific questions that one could potentially study. Advisors \u00b6 Even a well posed question does not help you if you cannot find an advisor. Therefore, you need to focus on areas where someone on the faculty has expertise. At the very start of your search, you should visit the websites of faculty members in your field of interest and read some of their recent papers. This will give you an idea of the range of topics that you can get support for. It will also give you feel for the techniques that each faculty member uses (e.g., theory, econometrics, computational modeling). The best approach is to not look for a topic. \u00b6 Just sit down and try to understand how the literature answers a question of interest. Yes: a question ! Good project ideas end with a question mark. Be suspicious of ideas like \"we want to explore ...\" Be very suspcious about ideas like \"what happens when feature x is added to a model?\" You need a question. Anyway, at some point you'll get the idea of what others think about the question of interest (or even of what interesting questions in a given area may be). Then simply ask: \" Do I believe what I have read? Is it convincing? \" Forget the fact that you are looking for a project. Just ask whether you believe what you have read. You will typically find that there are many shaky issues in the proposed answers. That's where an idea is born. If you find something that is really unconvincing, it is an opportunity to do better. Example : You decide to study the question: \"How much does human capital differ across countries?\" The literature basically has two types of answers. Mincer equations: Regress log wages on schooling for U.S. workers. Assume that workers with given schooling have the same human capital in all countries. Estimate a schooling production function. Estimate schooling inputs for a set of countries. Calculate human capital from the production function. The Mincer approach is not credible because it must assume that workers with given schooling have the same human capital everywhere. The production function approach turns out to be very tricky. It is extremely hard to measure schooling inputs (parental time, school inputs, child study time, child abilities, peer effects, etc.) and outputs (adult wages?). The functional form of the school production function is unknown. This leads to two project ideas : Try to improve the estimation of human capital production functions. Look for better data (existing studies did not use individual data - this actually would be a good project which has not been done at the time I am writing this). Try to measure human capital without estimating a production function. How can this be done? If one could observe the productivity of workers from different countries, that would work. This leads to the idea: estimate the productivity of workers from country x as the wages earned by U.S. immigrants from that country (Hendricks 2002 AER). Of course, in most cases it will simply be too hard to do better. Then you don't believe that the existing findings are bullet proof, but they are still the best answers available. It is useful to keep these kinds of situations in the back of your mind. Perhaps you'll see something later that allows you to follow through with your idea after all. Example : The migration literature argues about immigrant quality and earnings of immigrants relative to natives. But it's very hard to figure out what's really going on in all the data because we don't have longitudinal observations. So there is a clear potential for improvement, but it's not feasible because the data don't exist. Write that down. Later on you find out about the German Socioeconomic Panel and the fact that it oversamples guestworkers. Perhaps one could use that data to address the open issues? (This is actually a project idea worth pursuing, not just a ficticious example. In fact, recently a number of papers using longitudinal immigrant data have come out in top journals.) Use common sense . A fair number of good ideas are obvious with hindsight. Example: A large literature has studied the causes of cross-country income gaps. Many hypotheses were investigated: human capital, organization capital, trade, etc. But common sense tells us that institutions are important. The obvious evidence comes from divided countries (East and West Germany) and from the former Soviet Block. Strangely, it took a very long time for this idea to be explored in economic research. One more suggestion: Work on a topic that at least one local faculty member knows in detail . Otherwise, it will be hard to convince your committee members to spend a lot of time on your project. And the comments you will receive may be far off the mark. Make a serious effort to demolish your ideas. \u00b6 What happens once you have found a candidate topic: Try to convince yourself that the idea is no good . This is important. Before you sink any time into an idea, make sure it is worth it. Most ideas are not worth anything. There are many reasons. Perhaps the idea is too marginal. But more commonly it is outright flawed. Make a list of objections against your idea. Be sure you know how to respond to them. Talk to people and ask them for objections. Do this early . Do not wait until you have a model or (worse) a paper draft. One objection could destroy the entire effort you put into the project. Such as: \"X has done that already in a 1955 paper\" or \"This does not make sense because of XYZ.\" Be sure to try simple examples first. They sometimes reveal fundamental flaws in an idea or question. Example: You want to argue that schooling accounts for large cross-country income gaps. You think about a model in which human capital depends on schooling according to h(s) = h(0) * g(s). A back of the envelope calculations that this cannot work. To generate income gaps of, say, a factor 10, you would need h(12)/h(2)=10 (U.S. versus Uganda). Then the return to schooling would have to be enormous. A similar advice applies to the implementation. You may have a good question, but not a good way of answering it. Don't forget common sense . A lot of papers go through sophisticated analysis of a model that just doesn't make common sense. Motivation, Ideas, and Lack Thereof \u00b6 A common problem with dissertation topics is lack of motivation or lack of an idea. I often see papers that extend existing work in minor ways without any good reason why that should be done. Often, these are extensions of field papers. Usually, these turn out to be a waste of time. Relaxing an assumption does not make a paper . You need to convince people that it matters to attack a question in a more general way. A paper needs an idea . It is easy to find good questions. It is hard to find good ideas. Do not waste time on a project until you have convinced yourself that the idea is worthwhile. A question is something broad like: \"How important are productivity shocks for business cycles?\" \"Why does education differ across countries?\" An idea is a specific approach to answering a question. Such as: Kydland & Prescott for the business cycle question. Before you start working on the details, you should be able to explain in non-technical terms why your idea has merit. If you can't do that, chances are your idea is not important. Depth \u00b6 Writing a good paper requires that you really understand the literature. You should read a lot and think a lot. See my comments on specialization. When you start reading about a subject, you will generate lots of ideas. Most of these are no good, but you won't be able to see this until you really understand the literature. Defer the Details \u00b6 I see a lot of students with half-baked ideas and fully worked out models. This is a waste of time. In most cases, don't write down a model until you can precisely state: What is the question? Why is it important? What is the approach? Why does the approach make sense? What is the potential punchline? To borrow from Lee Ohanian: How does your paper change the way I think about the world? How does it fit into the literature? This, by the way, makes a good template for an Introduction. You cannot know what ingredients your model needs to have, until you can answer these questions. To Plan or Not to Plan? \u00b6 Some people ask: \"what is your research agenda?\" Ideally one could answer: \"I want to understand this big picture question and here are the steps that will get me there ... At the end I should have the following papers ...\" If that works, great! It usually doesn't (take a look at Parente and Prescott Barriers to Riches for a great example where it did work). There are at least two reasons: Until you have actually done a step in the plan, you typically have no idea what will come out (especially if the work has any empirical content). But what comes next depends critically on what you found before. It is hard to come up with a good idea/question that can actually be done. It is darn hard to come up with a whole sequence of such ideas at a time. Therefore, be realistic and take project ideas one at a time. Think of each dissertation chapter as one publishable paper. Don't try to write a monolithic dissertation where one chapter leads cleanly to the next. It's perfectly fine if your chapters address different questions. Specialize! \u00b6 At any cost, avoid working on several unrelated problems. To be successful, you must specialize. Each time you work on a new topic, you incur the large fixed cost of really, deeply understanding the literature. It is therefore essential to zero in on one or two areas and then stick to those for several years. If you do not follow this advice, you will encounter two problems: Your papers will lack depth. They may look superficially interesting, but experts will view your papers as missing the point. When you try to publish your work, you will have to convince referees that you should be taken seriously. They need to know that you have published in the same area before. Aim to associate your name with a topic. If you work in many different areas, nobody will know who you are. But if you persistently work in one area, people will hear your name and immediately think: \"he/she works on X.\" This is how your work is taken seriously and how to get impact. Disclaimer: I am sure there are reasonable people who vehemently disagree with my views on this. Theory vs. Empirical Work \u00b6 Theory is glamorous and in many respects just more interesting and more fun to do than data work. If you doubt that, start reading the documentation for the PSID. Data work involves a lot of tedious steps and a lot of time during which essentially nothing is learned (except about the twisted minds of those who publish data sets). If you doubt that, start reading the documentation for the PSID. And yet, you should consider doing empirical work. For one simple reason: It may get you a job. There are loads of theorists coming out of top departments every year. The best of them get jobs. The others often have a hard time because the market for pure theory is not that large. Having an empirical project or at least a serious empirical part in your dissertation immensely increases the range of jobs you can apply for. There is unfortunately a big barrier standing between graduate students and data: Empirical work is hardly ever taught. The first time around, the startup investment required for using a data set is very large. If you doubt that, start reading the documentation for the PSID. Which is why many grad students never touch any data. But this obstacle can be overcome through persistence. Communicating with your committee members (CMs) \u00b6 Remember: your CMs don't think about your project all the time. They forget details between meetings. Therefore: Stay in touch regularly. Too many students show up with a completed paper that was written without any input from the CMs. They are then surprised when the CMs think that major revisions are needed. Have a short summary document ready. In particular, have a document with the model equations. Prepare for each meeting. Summarize your progress and the issues to be discussed in a short document. Documents should not be written in prose. Prose is a waste of time for the writer and for the reader. Use an outline format. Respond to comments. Do not just ignore them. Again, a short reply document is useful. Writing \u00b6 Early on, write out a plan for the paper It should address the items in the intro. Be clear about what results you may get and what the contribution would be. Until you can clearly state the potential contribution of the project, don't spend any time on it. Models are presented in a standard format: Describe demographics, preferences, endowments, technologies, market arrangements. State each agent's problem. Define an equilibrium. Only when all of this is done are you allowed to analyze the properties of the model. See also notes on writing . To Ph.D. or not to Ph.D.? \u00b6 Finally, a word for those who are considering whether or not to apply for a Ph.D. program: If you are not sure you want a Ph.D., do something else. The Ph.D. program is structured with a single outcome in mind: to place graduating students as faculty in Research I universities. The material learned is useful for only one purpose: for publishing research in academic journals. It is not useful for consulting, for working in businesses or the government (other than the Fed), or even for teaching. Therefore, if you are not sure you want to do academic research for the rest of your life, do not apply for Ph.D. programs in economics. An MA or an MBA always has a higher payoff and will save you years of frustration.","title":"Dissertation Tips #"},{"location":"graduate/dissertation_tips.html#dissertation-tips","text":"","title":"Dissertation Tips"},{"location":"graduate/dissertation_tips.html#finding-a-topic","text":"","title":"Finding a topic"},{"location":"graduate/dissertation_tips.html#work-top-down","text":"When you start out, you just don't know which questions are interesting, which have been answered, etc. So you start broadly. Pick something that interests you and start reading. Let's use cross-country income gaps as an example. Rich countries are 25 times richer than poor countries. Why? Start reading. Take notes on what you read. Organize your notes, so you understand the \"tree of questions\" in that literature. In our example, part of the tree may look like this: How important are capital, human capital, and productivity? Within human capital: how that this be measured? Why does it differ across countries? Within the measurement question: there is a Mincerian approach and a production function approach. Questions there: how can we measure inputs to human capital production? How can we estimate a production function? The point is to get from vague, broad questions to specific questions that one could potentially study.","title":"Work top down"},{"location":"graduate/dissertation_tips.html#advisors","text":"Even a well posed question does not help you if you cannot find an advisor. Therefore, you need to focus on areas where someone on the faculty has expertise. At the very start of your search, you should visit the websites of faculty members in your field of interest and read some of their recent papers. This will give you an idea of the range of topics that you can get support for. It will also give you feel for the techniques that each faculty member uses (e.g., theory, econometrics, computational modeling).","title":"Advisors"},{"location":"graduate/dissertation_tips.html#the-best-approach-is-to-not-look-for-a-topic","text":"Just sit down and try to understand how the literature answers a question of interest. Yes: a question ! Good project ideas end with a question mark. Be suspicious of ideas like \"we want to explore ...\" Be very suspcious about ideas like \"what happens when feature x is added to a model?\" You need a question. Anyway, at some point you'll get the idea of what others think about the question of interest (or even of what interesting questions in a given area may be). Then simply ask: \" Do I believe what I have read? Is it convincing? \" Forget the fact that you are looking for a project. Just ask whether you believe what you have read. You will typically find that there are many shaky issues in the proposed answers. That's where an idea is born. If you find something that is really unconvincing, it is an opportunity to do better. Example : You decide to study the question: \"How much does human capital differ across countries?\" The literature basically has two types of answers. Mincer equations: Regress log wages on schooling for U.S. workers. Assume that workers with given schooling have the same human capital in all countries. Estimate a schooling production function. Estimate schooling inputs for a set of countries. Calculate human capital from the production function. The Mincer approach is not credible because it must assume that workers with given schooling have the same human capital everywhere. The production function approach turns out to be very tricky. It is extremely hard to measure schooling inputs (parental time, school inputs, child study time, child abilities, peer effects, etc.) and outputs (adult wages?). The functional form of the school production function is unknown. This leads to two project ideas : Try to improve the estimation of human capital production functions. Look for better data (existing studies did not use individual data - this actually would be a good project which has not been done at the time I am writing this). Try to measure human capital without estimating a production function. How can this be done? If one could observe the productivity of workers from different countries, that would work. This leads to the idea: estimate the productivity of workers from country x as the wages earned by U.S. immigrants from that country (Hendricks 2002 AER). Of course, in most cases it will simply be too hard to do better. Then you don't believe that the existing findings are bullet proof, but they are still the best answers available. It is useful to keep these kinds of situations in the back of your mind. Perhaps you'll see something later that allows you to follow through with your idea after all. Example : The migration literature argues about immigrant quality and earnings of immigrants relative to natives. But it's very hard to figure out what's really going on in all the data because we don't have longitudinal observations. So there is a clear potential for improvement, but it's not feasible because the data don't exist. Write that down. Later on you find out about the German Socioeconomic Panel and the fact that it oversamples guestworkers. Perhaps one could use that data to address the open issues? (This is actually a project idea worth pursuing, not just a ficticious example. In fact, recently a number of papers using longitudinal immigrant data have come out in top journals.) Use common sense . A fair number of good ideas are obvious with hindsight. Example: A large literature has studied the causes of cross-country income gaps. Many hypotheses were investigated: human capital, organization capital, trade, etc. But common sense tells us that institutions are important. The obvious evidence comes from divided countries (East and West Germany) and from the former Soviet Block. Strangely, it took a very long time for this idea to be explored in economic research. One more suggestion: Work on a topic that at least one local faculty member knows in detail . Otherwise, it will be hard to convince your committee members to spend a lot of time on your project. And the comments you will receive may be far off the mark.","title":"The best approach is to not look for a topic."},{"location":"graduate/dissertation_tips.html#make-a-serious-effort-to-demolish-your-ideas","text":"What happens once you have found a candidate topic: Try to convince yourself that the idea is no good . This is important. Before you sink any time into an idea, make sure it is worth it. Most ideas are not worth anything. There are many reasons. Perhaps the idea is too marginal. But more commonly it is outright flawed. Make a list of objections against your idea. Be sure you know how to respond to them. Talk to people and ask them for objections. Do this early . Do not wait until you have a model or (worse) a paper draft. One objection could destroy the entire effort you put into the project. Such as: \"X has done that already in a 1955 paper\" or \"This does not make sense because of XYZ.\" Be sure to try simple examples first. They sometimes reveal fundamental flaws in an idea or question. Example: You want to argue that schooling accounts for large cross-country income gaps. You think about a model in which human capital depends on schooling according to h(s) = h(0) * g(s). A back of the envelope calculations that this cannot work. To generate income gaps of, say, a factor 10, you would need h(12)/h(2)=10 (U.S. versus Uganda). Then the return to schooling would have to be enormous. A similar advice applies to the implementation. You may have a good question, but not a good way of answering it. Don't forget common sense . A lot of papers go through sophisticated analysis of a model that just doesn't make common sense.","title":"Make a serious effort to demolish your ideas."},{"location":"graduate/dissertation_tips.html#motivation-ideas-and-lack-thereof","text":"A common problem with dissertation topics is lack of motivation or lack of an idea. I often see papers that extend existing work in minor ways without any good reason why that should be done. Often, these are extensions of field papers. Usually, these turn out to be a waste of time. Relaxing an assumption does not make a paper . You need to convince people that it matters to attack a question in a more general way. A paper needs an idea . It is easy to find good questions. It is hard to find good ideas. Do not waste time on a project until you have convinced yourself that the idea is worthwhile. A question is something broad like: \"How important are productivity shocks for business cycles?\" \"Why does education differ across countries?\" An idea is a specific approach to answering a question. Such as: Kydland & Prescott for the business cycle question. Before you start working on the details, you should be able to explain in non-technical terms why your idea has merit. If you can't do that, chances are your idea is not important.","title":"Motivation, Ideas, and Lack Thereof"},{"location":"graduate/dissertation_tips.html#depth","text":"Writing a good paper requires that you really understand the literature. You should read a lot and think a lot. See my comments on specialization. When you start reading about a subject, you will generate lots of ideas. Most of these are no good, but you won't be able to see this until you really understand the literature.","title":"Depth"},{"location":"graduate/dissertation_tips.html#defer-the-details","text":"I see a lot of students with half-baked ideas and fully worked out models. This is a waste of time. In most cases, don't write down a model until you can precisely state: What is the question? Why is it important? What is the approach? Why does the approach make sense? What is the potential punchline? To borrow from Lee Ohanian: How does your paper change the way I think about the world? How does it fit into the literature? This, by the way, makes a good template for an Introduction. You cannot know what ingredients your model needs to have, until you can answer these questions.","title":"Defer the Details"},{"location":"graduate/dissertation_tips.html#to-plan-or-not-to-plan","text":"Some people ask: \"what is your research agenda?\" Ideally one could answer: \"I want to understand this big picture question and here are the steps that will get me there ... At the end I should have the following papers ...\" If that works, great! It usually doesn't (take a look at Parente and Prescott Barriers to Riches for a great example where it did work). There are at least two reasons: Until you have actually done a step in the plan, you typically have no idea what will come out (especially if the work has any empirical content). But what comes next depends critically on what you found before. It is hard to come up with a good idea/question that can actually be done. It is darn hard to come up with a whole sequence of such ideas at a time. Therefore, be realistic and take project ideas one at a time. Think of each dissertation chapter as one publishable paper. Don't try to write a monolithic dissertation where one chapter leads cleanly to the next. It's perfectly fine if your chapters address different questions.","title":"To Plan or Not to Plan?"},{"location":"graduate/dissertation_tips.html#specialize","text":"At any cost, avoid working on several unrelated problems. To be successful, you must specialize. Each time you work on a new topic, you incur the large fixed cost of really, deeply understanding the literature. It is therefore essential to zero in on one or two areas and then stick to those for several years. If you do not follow this advice, you will encounter two problems: Your papers will lack depth. They may look superficially interesting, but experts will view your papers as missing the point. When you try to publish your work, you will have to convince referees that you should be taken seriously. They need to know that you have published in the same area before. Aim to associate your name with a topic. If you work in many different areas, nobody will know who you are. But if you persistently work in one area, people will hear your name and immediately think: \"he/she works on X.\" This is how your work is taken seriously and how to get impact. Disclaimer: I am sure there are reasonable people who vehemently disagree with my views on this.","title":"Specialize!"},{"location":"graduate/dissertation_tips.html#theory-vs-empirical-work","text":"Theory is glamorous and in many respects just more interesting and more fun to do than data work. If you doubt that, start reading the documentation for the PSID. Data work involves a lot of tedious steps and a lot of time during which essentially nothing is learned (except about the twisted minds of those who publish data sets). If you doubt that, start reading the documentation for the PSID. And yet, you should consider doing empirical work. For one simple reason: It may get you a job. There are loads of theorists coming out of top departments every year. The best of them get jobs. The others often have a hard time because the market for pure theory is not that large. Having an empirical project or at least a serious empirical part in your dissertation immensely increases the range of jobs you can apply for. There is unfortunately a big barrier standing between graduate students and data: Empirical work is hardly ever taught. The first time around, the startup investment required for using a data set is very large. If you doubt that, start reading the documentation for the PSID. Which is why many grad students never touch any data. But this obstacle can be overcome through persistence.","title":"Theory vs. Empirical Work"},{"location":"graduate/dissertation_tips.html#communicating-with-your-committee-members-cms","text":"Remember: your CMs don't think about your project all the time. They forget details between meetings. Therefore: Stay in touch regularly. Too many students show up with a completed paper that was written without any input from the CMs. They are then surprised when the CMs think that major revisions are needed. Have a short summary document ready. In particular, have a document with the model equations. Prepare for each meeting. Summarize your progress and the issues to be discussed in a short document. Documents should not be written in prose. Prose is a waste of time for the writer and for the reader. Use an outline format. Respond to comments. Do not just ignore them. Again, a short reply document is useful.","title":"Communicating with your committee members (CMs)"},{"location":"graduate/dissertation_tips.html#writing","text":"Early on, write out a plan for the paper It should address the items in the intro. Be clear about what results you may get and what the contribution would be. Until you can clearly state the potential contribution of the project, don't spend any time on it. Models are presented in a standard format: Describe demographics, preferences, endowments, technologies, market arrangements. State each agent's problem. Define an equilibrium. Only when all of this is done are you allowed to analyze the properties of the model. See also notes on writing .","title":"Writing"},{"location":"graduate/dissertation_tips.html#to-phd-or-not-to-phd","text":"Finally, a word for those who are considering whether or not to apply for a Ph.D. program: If you are not sure you want a Ph.D., do something else. The Ph.D. program is structured with a single outcome in mind: to place graduating students as faculty in Research I universities. The material learned is useful for only one purpose: for publishing research in academic journals. It is not useful for consulting, for working in businesses or the government (other than the Fed), or even for teaching. Therefore, if you are not sure you want to do academic research for the rest of your life, do not apply for Ph.D. programs in economics. An MA or an MBA always has a higher payoff and will save you years of frustration.","title":"To Ph.D. or not to Ph.D.?"},{"location":"graduate/field_papers.html","text":"{{../markdown_header.txt}} Field Papers in Macro/International \u00b6 A field paper should contain at least a critical literature review. Critical means: the review should identify potential avenues for future research. In many cases, students will have identified a potential topic by the time they start their field paper. Then it makes sense to keep the literature review short and focus on the initial steps of the proposed research. Each student should get his/her topic approved by a faculty member at the start. While field papers are eventually read by 2 faculty members, the \"field paper advisor\" will have an important say in the outcome. For 2016, the due date is September 9. FAQ \u00b6 You do not need an abstract.","title":"Field papers"},{"location":"graduate/field_papers.html#field-papers-in-macrointernational","text":"A field paper should contain at least a critical literature review. Critical means: the review should identify potential avenues for future research. In many cases, students will have identified a potential topic by the time they start their field paper. Then it makes sense to keep the literature review short and focus on the initial steps of the proposed research. Each student should get his/her topic approved by a faculty member at the start. While field papers are eventually read by 2 faculty members, the \"field paper advisor\" will have an important say in the outcome. For 2016, the due date is September 9.","title":"Field Papers in Macro/International"},{"location":"graduate/field_papers.html#faq","text":"You do not need an abstract.","title":"FAQ"},{"location":"graduate/graduate.html","text":"Graduate Teaching Notes \u00b6 Computational issues \u00b6 Spring 2016 Econ821 course on wealth distribution and computational methods (using Matlab). Matlab and Programming Using killdevil at UNC Notes on data sources Tips for using IPUMS data Dissertation tips \u00b6 Tips for dissertations, especially on finding topics Tips for writing Tips for presenting a paper Other \u00b6 Tips for first year PhD Students Notes on field papers in macro/international Exam tips","title":"Graduate notes"},{"location":"graduate/graduate.html#graduate-teaching-notes","text":"","title":"Graduate Teaching Notes"},{"location":"graduate/graduate.html#computational-issues","text":"Spring 2016 Econ821 course on wealth distribution and computational methods (using Matlab). Matlab and Programming Using killdevil at UNC Notes on data sources Tips for using IPUMS data","title":"Computational issues"},{"location":"graduate/graduate.html#dissertation-tips","text":"Tips for dissertations, especially on finding topics Tips for writing Tips for presenting a paper","title":"Dissertation tips"},{"location":"graduate/graduate.html#other","text":"Tips for first year PhD Students Notes on field papers in macro/international Exam tips","title":"Other"},{"location":"graduate/killdevil.html","text":"{{../markdown_header.txt}} Using HPCs at UNC \u00b6 Crashing jobs \u00b6 When jobs crash without explanation: * check whether over disc quota. Quota is 52GB in 2020. * the reason may be errors writing to files. This terminates a process without any info on the reason in the log. * Matlab ignores file writing errors. It just keeps running. The crash only occurs when file reads fails. Uploading Files \u00b6 Set up login via ssh keys. Then use rsync to upload and download files. Submitting Jobs \u00b6 Longleaf uses slurm Changing software versions \u00b6 module avail julia lists available versions. module add julia/1.4.1 adds a module temporarily. But need to module save to make it permanent. module rm removes a module module list lists currently installed ones. Matlab Issues \u00b6 It is easiest to replicate the local directory structure on killdevil . Then running files on the cluster just requires a change in the base directory that all other directories hang off. Write your code so that the data are placed in the right folder (different on unix cluster vs local machine). Write a matlab function that does the computations and can be called from the command line. Command syntax: bsub -n 8 -R \"span[hosts=1]\" matlab -nodisplay -nosplash -r \"run_batch_so1('fminsearch',1,1,7)\" -logfile set7.out -n 8 : requests 8 cores - the max matlab can handle run_batch_so1 is my command file in this example. Kure jobs crash regularly. It is important to make sure the optimization algorithm can hot-start (resume after a crash using a saved history). Saving files: Matlab cannot save large / complex files. It crashes. Only save the minimum optimization history needed to hot-start. When using parallel algorithms, make sure different instances do not try to read / write the same file at the same time. A simple semaphore approach is easily implemented (each instance locks the file it wants to access by writing a file, e.g. \"lock07_param.mat\" indicates that instance 7 has locked the file param.mat).","title":"Killdevil"},{"location":"graduate/killdevil.html#using-hpcs-at-unc","text":"","title":"Using HPCs at UNC"},{"location":"graduate/killdevil.html#crashing-jobs","text":"When jobs crash without explanation: * check whether over disc quota. Quota is 52GB in 2020. * the reason may be errors writing to files. This terminates a process without any info on the reason in the log. * Matlab ignores file writing errors. It just keeps running. The crash only occurs when file reads fails.","title":"Crashing jobs"},{"location":"graduate/killdevil.html#uploading-files","text":"Set up login via ssh keys. Then use rsync to upload and download files.","title":"Uploading Files"},{"location":"graduate/killdevil.html#submitting-jobs","text":"Longleaf uses slurm","title":"Submitting Jobs"},{"location":"graduate/killdevil.html#changing-software-versions","text":"module avail julia lists available versions. module add julia/1.4.1 adds a module temporarily. But need to module save to make it permanent. module rm removes a module module list lists currently installed ones.","title":"Changing software versions"},{"location":"graduate/killdevil.html#matlab-issues","text":"It is easiest to replicate the local directory structure on killdevil . Then running files on the cluster just requires a change in the base directory that all other directories hang off. Write your code so that the data are placed in the right folder (different on unix cluster vs local machine). Write a matlab function that does the computations and can be called from the command line. Command syntax: bsub -n 8 -R \"span[hosts=1]\" matlab -nodisplay -nosplash -r \"run_batch_so1('fminsearch',1,1,7)\" -logfile set7.out -n 8 : requests 8 cores - the max matlab can handle run_batch_so1 is my command file in this example. Kure jobs crash regularly. It is important to make sure the optimization algorithm can hot-start (resume after a crash using a saved history). Saving files: Matlab cannot save large / complex files. It crashes. Only save the minimum optimization history needed to hot-start. When using parallel algorithms, make sure different instances do not try to read / write the same file at the same time. A simple semaphore approach is easily implemented (each instance locks the file it wants to access by writing a file, e.g. \"lock07_param.mat\" indicates that instance 7 has locked the file param.mat).","title":"Matlab Issues"},{"location":"graduate/presentation_tips.html","text":"{{../markdown_header.txt}} Tips for Presenting a Paper \u00b6 Intro \u00b6 Clearly state: what is the question? (this should be one of your first slides) how is it approached? why is the approach reasonable? what are the findings? how does the paper change the way I think about economics? (due to Lee Ohanian). After the intro, people must have the paper's main message firmly in their minds. Slides \u00b6 Don't put too much on a slide. The Pat Kehoe test is useful: drop the slide on the floor; can you still read everything? Every slides must have a point. It must state its point clearly. You should have no more than 30 slides for a 90 minute presentation, unless there is very little on each slide.","title":"Presentation tips"},{"location":"graduate/presentation_tips.html#tips-for-presenting-a-paper","text":"","title":"Tips for Presenting a Paper"},{"location":"graduate/presentation_tips.html#intro","text":"Clearly state: what is the question? (this should be one of your first slides) how is it approached? why is the approach reasonable? what are the findings? how does the paper change the way I think about economics? (due to Lee Ohanian). After the intro, people must have the paper's main message firmly in their minds.","title":"Intro"},{"location":"graduate/presentation_tips.html#slides","text":"Don't put too much on a slide. The Pat Kehoe test is useful: drop the slide on the floor; can you still read everything? Every slides must have a point. It must state its point clearly. You should have no more than 30 slides for a 90 minute presentation, unless there is very little on each slide.","title":"Slides"},{"location":"graduate/writing_tips.html","text":"{{../markdown_header.txt}} Tips for Writing a Paper \u00b6 For some exceptionally well written papers, take a look at the work of Richard Rogerson. Structure of the presentation \u00b6 Introduction \u00b6 Your introduction should answer the following questions (due to Lee Ohanian): What is the question to be answered? Why is it important? (Often obvious) How is it approached? Why is the approach reasonable? What is the main result? How does the paper change the way I think about economics? What is the contribution? What is new relative to the literature? Literature review \u00b6 The literature review's goal is not to write a survey of the related literature. Instead, it clarifies your contribution relative to previous work. Presenting models \u00b6 Separate the presentation of what you do from the discussion of why you do it. Brief comments mixed in with the model presentation are ok. Long discussions make it hard to follow what you actually do. Separate the presentation of the model from the derivation of its implications. It is very confusing to read a paper that mixes assumptions with results. First present the model. Define equilibrium. Then derive properties of the equilibrium. There is a standard structure for presenting a model : Demographics Endowments Preferences Technologies Market arrangements Only once these have been stated is it acceptable to talk about equilibrium properties or agents' problems. Next, describe the agents' problems, and define an equilibrium. The process of writing \u00b6 Nice wording comes last \u00b6 First decide on what you want to write. Just write that down. Focus on structure. Ignore wording and formatting. Only when everything is in place does it make sense to worry about construcing nice sentences. When you write a section, ask yourself: what is the message of this section? And then write the answer to that question as the section's intro sentence. Do not mix levels of abstraction (a rule borrowed from programming). When you discuss high level arguments (e.g. in the Introduction), do not mix in details. Think of your document as a nested list or an outline. There should be a place (the Intro) where the reader can get the entire story (minus detail) on about one page. Then think of each section as elaborating the details of the overall argument. Ideally, the reader should be able to read the level 2 sections (skipping the level 3s) and get the entire argument again, just with a bit more detail. The level 3 sections then provide even more detail. Each such section should by itself make a self-contained point. PS: I wish there was a technology for actually writing papers as nested, collapsible lists. Why are we still writing (and formatting) documents as if they were printed and read on paper? Tips and tricks \u00b6 A little trick: When you are unsure about notation, define latex commands for the mathematical symbols. Example: \\newcommand{\\capShare}{\\alpha} . Then y = A k^\\capShare . Avoid literals in your text. Let your code write a latex preamble with statments like \\newcommand{\\meanWage}{7.53} . Then in the text: \"the mean wage in the sample is $\\meanWage\". That way, you don't have to manually update the numbers in the text. It's more robust. Tables \u00b6 Don't write tables by hand. Let your code write them. It's faster and it avoids mistakes. It is fairly easy to write basic Latex tables using code. I have Matlab code for this purpose in my github repo. Links \u00b6 Tips on Writing Economics Papers by R. Carter Hill (a collection of links) A Guide to Writing in Economics by P. Dudenhefer. Written for undergraduate writing, but also useful for PhD students. Writing Tips For Economics Research Papers by P. Nikilov.","title":"Writing tips"},{"location":"graduate/writing_tips.html#tips-for-writing-a-paper","text":"For some exceptionally well written papers, take a look at the work of Richard Rogerson.","title":"Tips for Writing a Paper"},{"location":"graduate/writing_tips.html#structure-of-the-presentation","text":"","title":"Structure of the presentation"},{"location":"graduate/writing_tips.html#introduction","text":"Your introduction should answer the following questions (due to Lee Ohanian): What is the question to be answered? Why is it important? (Often obvious) How is it approached? Why is the approach reasonable? What is the main result? How does the paper change the way I think about economics? What is the contribution? What is new relative to the literature?","title":"Introduction"},{"location":"graduate/writing_tips.html#literature-review","text":"The literature review's goal is not to write a survey of the related literature. Instead, it clarifies your contribution relative to previous work.","title":"Literature review"},{"location":"graduate/writing_tips.html#presenting-models","text":"Separate the presentation of what you do from the discussion of why you do it. Brief comments mixed in with the model presentation are ok. Long discussions make it hard to follow what you actually do. Separate the presentation of the model from the derivation of its implications. It is very confusing to read a paper that mixes assumptions with results. First present the model. Define equilibrium. Then derive properties of the equilibrium. There is a standard structure for presenting a model : Demographics Endowments Preferences Technologies Market arrangements Only once these have been stated is it acceptable to talk about equilibrium properties or agents' problems. Next, describe the agents' problems, and define an equilibrium.","title":"Presenting models"},{"location":"graduate/writing_tips.html#the-process-of-writing","text":"","title":"The process of writing"},{"location":"graduate/writing_tips.html#nice-wording-comes-last","text":"First decide on what you want to write. Just write that down. Focus on structure. Ignore wording and formatting. Only when everything is in place does it make sense to worry about construcing nice sentences. When you write a section, ask yourself: what is the message of this section? And then write the answer to that question as the section's intro sentence. Do not mix levels of abstraction (a rule borrowed from programming). When you discuss high level arguments (e.g. in the Introduction), do not mix in details. Think of your document as a nested list or an outline. There should be a place (the Intro) where the reader can get the entire story (minus detail) on about one page. Then think of each section as elaborating the details of the overall argument. Ideally, the reader should be able to read the level 2 sections (skipping the level 3s) and get the entire argument again, just with a bit more detail. The level 3 sections then provide even more detail. Each such section should by itself make a self-contained point. PS: I wish there was a technology for actually writing papers as nested, collapsible lists. Why are we still writing (and formatting) documents as if they were printed and read on paper?","title":"Nice wording comes last"},{"location":"graduate/writing_tips.html#tips-and-tricks","text":"A little trick: When you are unsure about notation, define latex commands for the mathematical symbols. Example: \\newcommand{\\capShare}{\\alpha} . Then y = A k^\\capShare . Avoid literals in your text. Let your code write a latex preamble with statments like \\newcommand{\\meanWage}{7.53} . Then in the text: \"the mean wage in the sample is $\\meanWage\". That way, you don't have to manually update the numbers in the text. It's more robust.","title":"Tips and tricks"},{"location":"graduate/writing_tips.html#tables","text":"Don't write tables by hand. Let your code write them. It's faster and it avoids mistakes. It is fairly easy to write basic Latex tables using code. I have Matlab code for this purpose in my github repo.","title":"Tables"},{"location":"graduate/writing_tips.html#links","text":"Tips on Writing Economics Papers by R. Carter Hill (a collection of links) A Guide to Writing in Economics by P. Dudenhefer. Written for undergraduate writing, but also useful for PhD students. Writing Tips For Economics Research Papers by P. Nikilov.","title":"Links"},{"location":"julia_notes/arrays.html","text":"Arrays \u00b6 Tensorcast.jl handles matrix and vector operations such as: changing index order: @cast A[j, i] := B[i,j] functions over selected indices: @cast A[j,i] := B[i,j] + C[i] going from Matrix to Vector of Vector: @cast A[j][i] := B[i,j]","title":"Arrays"},{"location":"julia_notes/arrays.html#arrays","text":"Tensorcast.jl handles matrix and vector operations such as: changing index order: @cast A[j, i] := B[i,j] functions over selected indices: @cast A[j,i] := B[i,j] + C[i] going from Matrix to Vector of Vector: @cast A[j][i] := B[i,j]","title":"Arrays"},{"location":"julia_notes/clusters.html","text":"Remote Clusters \u00b6 See also: The Ultimate Guide to Distributed Computing with a MWE. Preparation \u00b6 Get an account on the cluster, such as UNC's longleaf . Generate an ssh key , which allows you to log on without entering passwords. Try this out by logging into the cluster via ssh . At the terminal, enter ssh user@longleaf.unc.edu . Getting started with a test script \u00b6 How to get your code to run on a typical Linux cluster? Get started by writing a simple test script (Test3.jl) so we can test running from the command line. Make sure you can run the test script locally with julia \u201c/full/path/to/Test3.jl\u201d Now copy Test3.jl to a directory on the cluster and repeat the same. Once: make Julia available on the cluster with module add julia or module add julia/1.5.3 if you want a specific version. Then run julia \"/full/path/to/Test3.jl\" Now we know that things run on the cluster and it's time to submit a batch file: sbatch -p general -N 1 -J \"test_job\" -t 3-00 --mem 16384 -n 1 --mail-type=end --mail-user=lhendri@email.unc.edu -o \"test1.out\" --wrap=\"julia /full/path/to/Test3.jl\" Slurm \u00b6 Submitting jobs \u00b6 The usual way of submitting jobs consists of writing an sbatch file and then submitting it using the sbatch command. Steps: Copy your code and all of its dependencies to the cluster (see below). This is not needed when all dependencies are registered. Write a Julia script that contains the startup code for the project and then runs the actual computation (call this batch.jl ). Write a batch file that submits julia batch.jl as a job to the cluster's job scheduler. For UNC's longleaf cluster, this would be slurm. So you need to write job.sl that will be submitted using sbatch job.sl . Each line in the sbatch file looks like #SBATCH -o value . Options (indicated by -o) are: * -t 03-00 : time in days-hours * -N 1 : number of nodes * --mem 24576 : memory in megabytes (per cpu) Status of running jobs: \u00b6 squeue -u squeue --job XXXX sacct --format=\"JobID,JobName%30,State,ExitCode\" (best typed using KeyboardMaestro) Examining memory and cpu usage \u00b6 Yale guide After jobs completed: - seff jobid - sacct with MaxRSS switch shows memory usage. Errors \u00b6 From time to time, github asks for user credentials when trying to download private repos, even if those have been downloaded many times before. Then precompile the package from the REPL on the cluster, entering the credentials by hand. They will then be stored for some time again. The Julia script \u00b6 Submitting a job is (almost) equivalent to julia batch.jl from the terminal. Note: cd() does not work in these command files. To include a file, provide a full path. If you only use registered packages, life is easy. Your code would simply say: using Pkg # This needs to be done only once, but it does not hurt Pkg.add(MyPackage) # Make sure all required packages are downloaded Pkg.instantiate() MyPackage.run() If the code for MyPackage has been copied to the remote, then julia --project=\"/path/to/MyPackage\" --startup-file=no batch.jl activates MyPackage and runs batch.jl . The --project option is equivalent to Pkg.activate. Julia looks for batch.jl in the MyPackage directory. Disabling the startup-file prevents surprises where the startup-file changes the directory before looking for batch.jl. ~ is not expanded when relative paths are used. If MyPackage contains is unregistered or contains unregistered dependencies, things get more difficult. Now batch.jl must: Activate the package's environment. develop all unregistered dependencies. This replaces the invalid paths to directories on the local machine (e.g. /Users/lutz/julia/...) with the corresponding paths on the cluster (e.g. /nas/longleaf/...). Note: I verified that one cannot replace homedir() with ~ in Manifest.toml. using MyPackage MyPackage.run() Developing MyPackage in a blank folder does not work (for reasons I do not understand). It results in errors indicating that dependencies of MyPackage could not be found. This approach requires you to keep track of all unregistered dependencies and where they are located on the remote machine. My way of doing this is contained in PackageTools.jl in the shared repo (this is not a package b/c its very purpose is to facilitate loading of unregistered packages). But the easier way is to create a private registry and register all dependencies. File Transfer \u00b6 A reliable command line transfer option is rsync (on mac / linux). The command would be something like rsync -atuzv \"/someDirectory/sourceDir/\" \"username@longleaf.unc.edu:someDirectorySourceDir\" Notes: The source dir should end in \u201c/\u201d; the target dir should not. Exluding .git speeds up the transfer. --delete ensures that no old files remain on the server. This will use ssh for authentication if it is set up. An alternative is to use git . To transfer an individual file: run( scp $filename hostname:/path/to/newfile.txt')`.","title":"Remote clusters"},{"location":"julia_notes/clusters.html#remote-clusters","text":"See also: The Ultimate Guide to Distributed Computing with a MWE.","title":"Remote Clusters"},{"location":"julia_notes/clusters.html#preparation","text":"Get an account on the cluster, such as UNC's longleaf . Generate an ssh key , which allows you to log on without entering passwords. Try this out by logging into the cluster via ssh . At the terminal, enter ssh user@longleaf.unc.edu .","title":"Preparation"},{"location":"julia_notes/clusters.html#getting-started-with-a-test-script","text":"How to get your code to run on a typical Linux cluster? Get started by writing a simple test script (Test3.jl) so we can test running from the command line. Make sure you can run the test script locally with julia \u201c/full/path/to/Test3.jl\u201d Now copy Test3.jl to a directory on the cluster and repeat the same. Once: make Julia available on the cluster with module add julia or module add julia/1.5.3 if you want a specific version. Then run julia \"/full/path/to/Test3.jl\" Now we know that things run on the cluster and it's time to submit a batch file: sbatch -p general -N 1 -J \"test_job\" -t 3-00 --mem 16384 -n 1 --mail-type=end --mail-user=lhendri@email.unc.edu -o \"test1.out\" --wrap=\"julia /full/path/to/Test3.jl\"","title":"Getting started with a test script"},{"location":"julia_notes/clusters.html#slurm","text":"","title":"Slurm"},{"location":"julia_notes/clusters.html#submitting-jobs","text":"The usual way of submitting jobs consists of writing an sbatch file and then submitting it using the sbatch command. Steps: Copy your code and all of its dependencies to the cluster (see below). This is not needed when all dependencies are registered. Write a Julia script that contains the startup code for the project and then runs the actual computation (call this batch.jl ). Write a batch file that submits julia batch.jl as a job to the cluster's job scheduler. For UNC's longleaf cluster, this would be slurm. So you need to write job.sl that will be submitted using sbatch job.sl . Each line in the sbatch file looks like #SBATCH -o value . Options (indicated by -o) are: * -t 03-00 : time in days-hours * -N 1 : number of nodes * --mem 24576 : memory in megabytes (per cpu)","title":"Submitting jobs"},{"location":"julia_notes/clusters.html#status-of-running-jobs","text":"squeue -u squeue --job XXXX sacct --format=\"JobID,JobName%30,State,ExitCode\" (best typed using KeyboardMaestro)","title":"Status of running jobs:"},{"location":"julia_notes/clusters.html#examining-memory-and-cpu-usage","text":"Yale guide After jobs completed: - seff jobid - sacct with MaxRSS switch shows memory usage.","title":"Examining memory and cpu usage"},{"location":"julia_notes/clusters.html#errors","text":"From time to time, github asks for user credentials when trying to download private repos, even if those have been downloaded many times before. Then precompile the package from the REPL on the cluster, entering the credentials by hand. They will then be stored for some time again.","title":"Errors"},{"location":"julia_notes/clusters.html#the-julia-script","text":"Submitting a job is (almost) equivalent to julia batch.jl from the terminal. Note: cd() does not work in these command files. To include a file, provide a full path. If you only use registered packages, life is easy. Your code would simply say: using Pkg # This needs to be done only once, but it does not hurt Pkg.add(MyPackage) # Make sure all required packages are downloaded Pkg.instantiate() MyPackage.run() If the code for MyPackage has been copied to the remote, then julia --project=\"/path/to/MyPackage\" --startup-file=no batch.jl activates MyPackage and runs batch.jl . The --project option is equivalent to Pkg.activate. Julia looks for batch.jl in the MyPackage directory. Disabling the startup-file prevents surprises where the startup-file changes the directory before looking for batch.jl. ~ is not expanded when relative paths are used. If MyPackage contains is unregistered or contains unregistered dependencies, things get more difficult. Now batch.jl must: Activate the package's environment. develop all unregistered dependencies. This replaces the invalid paths to directories on the local machine (e.g. /Users/lutz/julia/...) with the corresponding paths on the cluster (e.g. /nas/longleaf/...). Note: I verified that one cannot replace homedir() with ~ in Manifest.toml. using MyPackage MyPackage.run() Developing MyPackage in a blank folder does not work (for reasons I do not understand). It results in errors indicating that dependencies of MyPackage could not be found. This approach requires you to keep track of all unregistered dependencies and where they are located on the remote machine. My way of doing this is contained in PackageTools.jl in the shared repo (this is not a package b/c its very purpose is to facilitate loading of unregistered packages). But the easier way is to create a private registry and register all dependencies.","title":"The Julia script"},{"location":"julia_notes/clusters.html#file-transfer","text":"A reliable command line transfer option is rsync (on mac / linux). The command would be something like rsync -atuzv \"/someDirectory/sourceDir/\" \"username@longleaf.unc.edu:someDirectorySourceDir\" Notes: The source dir should end in \u201c/\u201d; the target dir should not. Exluding .git speeds up the transfer. --delete ensures that no old files remain on the server. This will use ssh for authentication if it is set up. An alternative is to use git . To transfer an individual file: run( scp $filename hostname:/path/to/newfile.txt')`.","title":"File Transfer"},{"location":"julia_notes/data_handling.html","text":"Data Handling \u00b6 Useful packages: DataSkimmer.jl produces a summary of tabular data (e.g. DataFrames ), including histogram.","title":"Data Handling"},{"location":"julia_notes/data_handling.html#data-handling","text":"Useful packages: DataSkimmer.jl produces a summary of tabular data (e.g. DataFrames ), including histogram.","title":"Data Handling"},{"location":"julia_notes/debugging.html","text":"Debugging \u00b6 Discourse thread on debugging A useful tutorial The Upshot \u00b6 This is a point of contention in the Julia ecosystem. Many users think the lack of a \"good\" debugger is the main drawback that prevents them from using Julia. One common answer is: Yeah, debugging is kind of lousy at this point. Just write your code so you don't need a debugger much. This is pretty much what I do and I find that I don't miss the debugger much at all. Roughly, I work as follows. Where possible, I break code into lots of small functions. This is probably anyway a good idea (see Martin's famous \"Clean Code\" book). Then I write tests for the small functions. When I develop custom types, I write test setup functions that make instances of the types that can be used for testing. The test functions are placed into self-contained files that can be include d from the REPL. When something goes wrong, it is easy to inspect it there. See testing . When something goes wrong in the integrated code that was not found during tests, I start to sprinkle @assert s into the code. If the code is not performance sensitive (95% of what I write), the @assert s are never removed, even when the bug is fixed. This gets me closer to the source of the error. In the vast majority of the cases, this process identifies errors without ever using a debugger. If this fails, Infiltrator.jl and Exfiltrator.jl are helpful. They are a bit like Matlab s keyboard statements, but less powerful. The code essentially stops at a breakpoint. The user can inspect the state of the system, but cannot move around the call stack. But that's usually OK because the steps taken before invoking the debugger have gotten me close to the origin of the problem. The Options \u00b6 Julia offers several debugger options that work in very different ways. The main trade-off is compile time versus run time . Debuggers that run interpreted code, such as Debugger.jl, compile reasonably fast but run very slowly (about 10 times slower than compiled code). Debuggers that compile debugging features into the code run at near native speed but are either slow to compile (MagneticReadHead) or offer limited features (Infiltrator). Common options are: Debugger.jl: It interprets all code and can therefore offer a complete feature set. But it is very slow for larger projects. Options are available that make Debugger faster, but less powerful. The VS Code plugin gives an IDE experience. MagneticReadHead.jl: It compiles debugging features into all code and therefore runs at near native speed. But compile times are often extremely long. Infiltrator.jl: It compiles all code, adding only user specified breakpoints (@infiltrate). Compile times and run times are good, but the user can only inspect the local state when a break point is reached. It is not possible to move around the call stack. Exfiltrator.jl: Simply exports all local variables at the point of call to Main. The idea is that the entire local environment can be inspected at really no runtime or compilation cost. Simple and effective, but one cannot manipulate objects in the context of the calling module. There are other options that I don't know much about, such as Juno's debugger.","title":"Debugging"},{"location":"julia_notes/debugging.html#debugging","text":"Discourse thread on debugging A useful tutorial","title":"Debugging"},{"location":"julia_notes/debugging.html#the-upshot","text":"This is a point of contention in the Julia ecosystem. Many users think the lack of a \"good\" debugger is the main drawback that prevents them from using Julia. One common answer is: Yeah, debugging is kind of lousy at this point. Just write your code so you don't need a debugger much. This is pretty much what I do and I find that I don't miss the debugger much at all. Roughly, I work as follows. Where possible, I break code into lots of small functions. This is probably anyway a good idea (see Martin's famous \"Clean Code\" book). Then I write tests for the small functions. When I develop custom types, I write test setup functions that make instances of the types that can be used for testing. The test functions are placed into self-contained files that can be include d from the REPL. When something goes wrong, it is easy to inspect it there. See testing . When something goes wrong in the integrated code that was not found during tests, I start to sprinkle @assert s into the code. If the code is not performance sensitive (95% of what I write), the @assert s are never removed, even when the bug is fixed. This gets me closer to the source of the error. In the vast majority of the cases, this process identifies errors without ever using a debugger. If this fails, Infiltrator.jl and Exfiltrator.jl are helpful. They are a bit like Matlab s keyboard statements, but less powerful. The code essentially stops at a breakpoint. The user can inspect the state of the system, but cannot move around the call stack. But that's usually OK because the steps taken before invoking the debugger have gotten me close to the origin of the problem.","title":"The Upshot"},{"location":"julia_notes/debugging.html#the-options","text":"Julia offers several debugger options that work in very different ways. The main trade-off is compile time versus run time . Debuggers that run interpreted code, such as Debugger.jl, compile reasonably fast but run very slowly (about 10 times slower than compiled code). Debuggers that compile debugging features into the code run at near native speed but are either slow to compile (MagneticReadHead) or offer limited features (Infiltrator). Common options are: Debugger.jl: It interprets all code and can therefore offer a complete feature set. But it is very slow for larger projects. Options are available that make Debugger faster, but less powerful. The VS Code plugin gives an IDE experience. MagneticReadHead.jl: It compiles debugging features into all code and therefore runs at near native speed. But compile times are often extremely long. Infiltrator.jl: It compiles all code, adding only user specified breakpoints (@infiltrate). Compile times and run times are good, but the user can only inspect the local state when a break point is reached. It is not possible to move around the call stack. Exfiltrator.jl: Simply exports all local variables at the point of call to Main. The idea is that the entire local environment can be inspected at really no runtime or compilation cost. Simple and effective, but one cannot manipulate objects in the context of the calling module. There are other options that I don't know much about, such as Juno's debugger.","title":"The Options"},{"location":"julia_notes/documentation.html","text":"Documentation \u00b6 DocStringExtensions.jl makes it easier to write docs. In particular, function signatures are automatically created in docstrings. Literate.jl is useful for generating examples. A useful guide to writing documentation (pointed out by Tim Holy on Discourse). Documenter.jl \u00b6 Documenter.jl is the most commonly used package to write documentation. Documentation specific dependencies are in ./docs/Project.toml . In my case, this contains FilesLH for deploying the docs. Then ./docs/make.jl needs to be called when the docs environment is active. Easiest: add Pkg.activate(\"./docs\") at the start of make.jl and Pkg.activate(\".\") at the end. It is then not necessary to have Documenter.jl as a dependency of the package. Deploying (1.5) \u00b6 The standard approach is TravisCI. Since I have private repos and a private package registry, I prefer \u201cmanual\u201d hosting on my own website. I run the docs/make.jl documenation build script as usual, but replace deploydocs with FilesLH.deploy_docs . This simply rsyncs the static html files generated by Documenter.jl to my personal website. See also Deploy Documenter docs locally .","title":"Documentation"},{"location":"julia_notes/documentation.html#documentation","text":"DocStringExtensions.jl makes it easier to write docs. In particular, function signatures are automatically created in docstrings. Literate.jl is useful for generating examples. A useful guide to writing documentation (pointed out by Tim Holy on Discourse).","title":"Documentation"},{"location":"julia_notes/documentation.html#documenterjl","text":"Documenter.jl is the most commonly used package to write documentation. Documentation specific dependencies are in ./docs/Project.toml . In my case, this contains FilesLH for deploying the docs. Then ./docs/make.jl needs to be called when the docs environment is active. Easiest: add Pkg.activate(\"./docs\") at the start of make.jl and Pkg.activate(\".\") at the end. It is then not necessary to have Documenter.jl as a dependency of the package.","title":"Documenter.jl"},{"location":"julia_notes/documentation.html#deploying-15","text":"The standard approach is TravisCI. Since I have private repos and a private package registry, I prefer \u201cmanual\u201d hosting on my own website. I run the docs/make.jl documenation build script as usual, but replace deploydocs with FilesLH.deploy_docs . This simply rsyncs the static html files generated by Documenter.jl to my personal website. See also Deploy Documenter docs locally .","title":"Deploying (1.5)"},{"location":"julia_notes/installation.html","text":"Installation \u00b6 My Setup \u00b6 My current setup is Julia 1.5 run from the terminal and Visual Studio Code as editor (augmented with BBEdit to overcome VsCode's shortcomings in multi-file search and replace). My startup file loads the packages OhMyREPL and the. Revise comes after packages from the standard libraries, so it does not track changes to those. It appears that the default editor is determined by the system wide file association. No need to set the JULIA_EDITOR environment variable. Updating to a new version \u00b6 After starting the new version, basic packages need to be added so the startup code can be run (e.g., OhMyREPL ). In my case these are: ]add OhMyREPL Revise The bash profile needs to be updated to point to the new version. Alternatively, create a symlink for the new version with rm /usr/local/bin/julia ln -s /Applications/Julia-1.5.app/Contents/Resources/julia/bin/julia /usr/local/bin/julia The Jill bash script automates this process. There is no need to copy installed packages to the new version's subdirectory. They are downloaded again as needed. Customizing the REPL \u00b6 On MacOS, meta-X means Esc-X. There does not seem to be a way of binding Alt-x. Customizing key bindings is somewhat tricky. One has to edit startup.jl to define a function that modifies the key map. I have not been able to assign Ctrl-H and similar. Perhaps iterm intercepts them, but they always arrive as control sequences. VS Code \u00b6 Set the Julia executable path to /usr/local/bin/julia (the symlink created above). A bash script that links an external terminal REPL to the Julia VSCode extension. Troubleshooting \u00b6 When problems with package operations occur, it often helps to reinstall the main registry: pkg> registry rm General Julia will automatically redownload the general registry when needed. Clearing out the package cache may also help.","title":"Installation"},{"location":"julia_notes/installation.html#installation","text":"","title":"Installation"},{"location":"julia_notes/installation.html#my-setup","text":"My current setup is Julia 1.5 run from the terminal and Visual Studio Code as editor (augmented with BBEdit to overcome VsCode's shortcomings in multi-file search and replace). My startup file loads the packages OhMyREPL and the. Revise comes after packages from the standard libraries, so it does not track changes to those. It appears that the default editor is determined by the system wide file association. No need to set the JULIA_EDITOR environment variable.","title":"My Setup"},{"location":"julia_notes/installation.html#updating-to-a-new-version","text":"After starting the new version, basic packages need to be added so the startup code can be run (e.g., OhMyREPL ). In my case these are: ]add OhMyREPL Revise The bash profile needs to be updated to point to the new version. Alternatively, create a symlink for the new version with rm /usr/local/bin/julia ln -s /Applications/Julia-1.5.app/Contents/Resources/julia/bin/julia /usr/local/bin/julia The Jill bash script automates this process. There is no need to copy installed packages to the new version's subdirectory. They are downloaded again as needed.","title":"Updating to a new version"},{"location":"julia_notes/installation.html#customizing-the-repl","text":"On MacOS, meta-X means Esc-X. There does not seem to be a way of binding Alt-x. Customizing key bindings is somewhat tricky. One has to edit startup.jl to define a function that modifies the key map. I have not been able to assign Ctrl-H and similar. Perhaps iterm intercepts them, but they always arrive as control sequences.","title":"Customizing the REPL"},{"location":"julia_notes/installation.html#vs-code","text":"Set the Julia executable path to /usr/local/bin/julia (the symlink created above). A bash script that links an external terminal REPL to the Julia VSCode extension.","title":"VS Code"},{"location":"julia_notes/installation.html#troubleshooting","text":"When problems with package operations occur, it often helps to reinstall the main registry: pkg> registry rm General Julia will automatically redownload the general registry when needed. Clearing out the package cache may also help.","title":"Troubleshooting"},{"location":"julia_notes/intro.html","text":"Notes on the Julia Language \u00b6 This document collects what I have learned about the Julia language. Its main purpose is to document tips and tricks that are not covered in the official documentation. Much of what is collected here is really just that: collected from other sources, which I try to cite where appropriate. Some of the material is a synthesis of material taken from various Discourse threads. In these cases, I may not always recall where I learned something. Apologies to Discourse contributors who I should perhaps have cited, but whose contributions I failed to recall. I will be happy to add citations if omissions are pointed out to me. Note: Earlier notes in pdf format","title":"Introduction"},{"location":"julia_notes/intro.html#notes-on-the-julia-language","text":"This document collects what I have learned about the Julia language. Its main purpose is to document tips and tricks that are not covered in the official documentation. Much of what is collected here is really just that: collected from other sources, which I try to cite where appropriate. Some of the material is a synthesis of material taken from various Discourse threads. In these cases, I may not always recall where I learned something. Apologies to Discourse contributors who I should perhaps have cited, but whose contributions I failed to recall. I will be happy to add citations if omissions are pointed out to me. Note: Earlier notes in pdf format","title":"Notes on the Julia Language"},{"location":"julia_notes/jupyter.html","text":"Jupyter \u00b6 Jupyter creates or runs notebooks that combine code, output, and text. An IDE for editing notebooks is JupyterLab .","title":"Jupyter"},{"location":"julia_notes/jupyter.html#jupyter","text":"Jupyter creates or runs notebooks that combine code, output, and text. An IDE for editing notebooks is JupyterLab .","title":"Jupyter"},{"location":"julia_notes/miscellaneous.html","text":"Miscellaneous \u00b6 Good advice on miscellaneous topics: Julia Antipatterns Random numbers (1.5) \u00b6 Generating reproducible random numbers across Julia versions can be done with StableRNGs.jl . This also seems to generate the same random numbers across operating systems (in my case MacOS and Linux).","title":"Miscellaneous"},{"location":"julia_notes/miscellaneous.html#miscellaneous","text":"Good advice on miscellaneous topics: Julia Antipatterns","title":"Miscellaneous"},{"location":"julia_notes/miscellaneous.html#random-numbers-15","text":"Generating reproducible random numbers across Julia versions can be done with StableRNGs.jl . This also seems to generate the same random numbers across operating systems (in my case MacOS and Linux).","title":"Random numbers (1.5)"},{"location":"julia_notes/packages.html","text":"Packages \u00b6 Creating packages \u00b6 Create the package locally. If using PkgTemplates.jl , this automatically initializes the github repo and sets it as the origin ( git remote add origin <url> ). Write some code. Push to github. PkgTemplates.jl \u00b6 The typical flow would be: using PkgTemplates gitIgnore = [\"*.jl.cov\", \"*.jl.*.cov\", \"*.jl.mem\", \"/deps/deps.jl\", \"/docs/build\"]; t = Template(; dir = joinpath(homedir(), \"Documents\", \"julia\"), plugins = [ Documenter{GitHubActions}, Git(; jl = false, ignore = gitIgnore), !CompatHelper, !AppVeyor, !TravisCI, !TagBot ]); t(\"MyPkg\"); Note that dir points to the parent directory of the new packages to be created. Even if one does not want to deploy documentation, the Documenter plugin is needed to create the barebones file structure. PkgSkeleton.jl (1.5) \u00b6 The easiest way for creating a package is PkgSkeleton.jl. You need to set your github info (user.name etc) using git config --global user.name YourName This must be done inside a git directory. Then generate generates the directory structure and the required files (Project.toml etc). Example: PkgSkeleton.generate(\"dir1/MyPackage\") Details: I first create the repo on github and clone it to the local dir. Then I use, from the parent dir: PkgSkeleton.generate(\"MyPackage\", skip_existing_dir = false) This way everything is linked to github from the start. Github and packages \u00b6 The basic steps (after creating the package locally): Create the package on github. git branch -M main git push -u origin main Or import the package repo into Github Desktop. Pkg Errors \u00b6 Occasionally, Pkg complains that a package is not registered. ]registry up tends to solve that issue.","title":"Packages"},{"location":"julia_notes/packages.html#packages","text":"","title":"Packages"},{"location":"julia_notes/packages.html#creating-packages","text":"Create the package locally. If using PkgTemplates.jl , this automatically initializes the github repo and sets it as the origin ( git remote add origin <url> ). Write some code. Push to github.","title":"Creating packages"},{"location":"julia_notes/packages.html#pkgtemplatesjl","text":"The typical flow would be: using PkgTemplates gitIgnore = [\"*.jl.cov\", \"*.jl.*.cov\", \"*.jl.mem\", \"/deps/deps.jl\", \"/docs/build\"]; t = Template(; dir = joinpath(homedir(), \"Documents\", \"julia\"), plugins = [ Documenter{GitHubActions}, Git(; jl = false, ignore = gitIgnore), !CompatHelper, !AppVeyor, !TravisCI, !TagBot ]); t(\"MyPkg\"); Note that dir points to the parent directory of the new packages to be created. Even if one does not want to deploy documentation, the Documenter plugin is needed to create the barebones file structure.","title":"PkgTemplates.jl"},{"location":"julia_notes/packages.html#pkgskeletonjl-15","text":"The easiest way for creating a package is PkgSkeleton.jl. You need to set your github info (user.name etc) using git config --global user.name YourName This must be done inside a git directory. Then generate generates the directory structure and the required files (Project.toml etc). Example: PkgSkeleton.generate(\"dir1/MyPackage\") Details: I first create the repo on github and clone it to the local dir. Then I use, from the parent dir: PkgSkeleton.generate(\"MyPackage\", skip_existing_dir = false) This way everything is linked to github from the start.","title":"PkgSkeleton.jl (1.5)"},{"location":"julia_notes/packages.html#github-and-packages","text":"The basic steps (after creating the package locally): Create the package on github. git branch -M main git push -u origin main Or import the package repo into Github Desktop.","title":"Github and packages"},{"location":"julia_notes/packages.html#pkg-errors","text":"Occasionally, Pkg complains that a package is not registered. ]registry up tends to solve that issue.","title":"Pkg Errors"},{"location":"julia_notes/performance.html","text":"Performance \u00b6 Profiling (1.5) \u00b6 A blog post on profiling and benchmarking. I find it most efficient to have a global profiling environment that Pkg.add s Profile, BenchmarkTools, StatProfilerHTML . To use it: using MyPackage Pkg.activate(\"path/to/profiling\") using BenchmarkTools, Profile, StatProfilerHTML Pkg.activate(\".\") include(\"profiling_code.jl\") # for this package The output generated by the built-in profiler is hard to read. Fortunately, there are packages that improve readability or graph the results. ProfileView does compile now (1.3), taking a surprisingly long time. Personally, I find the presentation of StatProfilerHTML more convenient, though. StatProfilerHTML \u00b6 It provides a flame graph with clickable links that show which lines in a function take up most time. Need to locate index.html and open it by hand in the browser after running statprofilehtml() . But can click on path link in terminal as well. PProf.jl \u00b6 requires Graphviz. On MacOS, install using brew install graphviz. But it has TONS of dependencies and did not install on my system. Then PProf cannot be used. TimerOutputs.jl \u00b6 can be used to time selected lines of code produces a nicely formatted table that is much easier to digest than profiler output. Loops (1.5) \u00b6 LoopVectorization.jl can give massive speed improvements for for loops. An example . Manual dispatch (1.5) \u00b6 It is beneficial to manually dispatch at runtime when a variable could potentially take on many types (as far as the compiler knows) but we know that only a few of those are possible. This is done automatically for small unions (known as union splitting). But for parametric types, the compiler has to look up methods in the method table at runtime because they could be extended. The package ManualDispatch.jl has a @unionsplit macro for this purpose. But AFAIK one may just as well write out an explicit if else . This would look weird: if x isa A foo(x); elseif x isa B foo(x); end but it seems to work. See the discussion on discourse . GPU computing (1.5) \u00b6 Tutorials - Nextjournal 2019 - Cuda.jl tutorial","title":"Performance"},{"location":"julia_notes/performance.html#performance","text":"","title":"Performance"},{"location":"julia_notes/performance.html#profiling-15","text":"A blog post on profiling and benchmarking. I find it most efficient to have a global profiling environment that Pkg.add s Profile, BenchmarkTools, StatProfilerHTML . To use it: using MyPackage Pkg.activate(\"path/to/profiling\") using BenchmarkTools, Profile, StatProfilerHTML Pkg.activate(\".\") include(\"profiling_code.jl\") # for this package The output generated by the built-in profiler is hard to read. Fortunately, there are packages that improve readability or graph the results. ProfileView does compile now (1.3), taking a surprisingly long time. Personally, I find the presentation of StatProfilerHTML more convenient, though.","title":"Profiling (1.5)"},{"location":"julia_notes/performance.html#statprofilerhtml","text":"It provides a flame graph with clickable links that show which lines in a function take up most time. Need to locate index.html and open it by hand in the browser after running statprofilehtml() . But can click on path link in terminal as well.","title":"StatProfilerHTML"},{"location":"julia_notes/performance.html#pprofjl","text":"requires Graphviz. On MacOS, install using brew install graphviz. But it has TONS of dependencies and did not install on my system. Then PProf cannot be used.","title":"PProf.jl"},{"location":"julia_notes/performance.html#timeroutputsjl","text":"can be used to time selected lines of code produces a nicely formatted table that is much easier to digest than profiler output.","title":"TimerOutputs.jl"},{"location":"julia_notes/performance.html#loops-15","text":"LoopVectorization.jl can give massive speed improvements for for loops. An example .","title":"Loops (1.5)"},{"location":"julia_notes/performance.html#manual-dispatch-15","text":"It is beneficial to manually dispatch at runtime when a variable could potentially take on many types (as far as the compiler knows) but we know that only a few of those are possible. This is done automatically for small unions (known as union splitting). But for parametric types, the compiler has to look up methods in the method table at runtime because they could be extended. The package ManualDispatch.jl has a @unionsplit macro for this purpose. But AFAIK one may just as well write out an explicit if else . This would look weird: if x isa A foo(x); elseif x isa B foo(x); end but it seems to work. See the discussion on discourse .","title":"Manual dispatch (1.5)"},{"location":"julia_notes/performance.html#gpu-computing-15","text":"Tutorials - Nextjournal 2019 - Cuda.jl tutorial","title":"GPU computing (1.5)"},{"location":"julia_notes/plotting.html","text":"Plotting \u00b6 Plots.jl \u00b6 Visually, PlotlyJS produces the most appealing plots (for me). But it does not install on my system (1.5). When a plotting related library is not found (as in \u201cerror compiling display\u201d), try ]build Plots . Defaults are set with the defaults command. Axis labels \u00b6 bar tends to have too small default margins for axis labels to show (at least in subplots). Try using Plots.PlotMeasures Legends \u00b6 The label is set when each series is plotted. If labels are set when the plot is created (before the series are plotted), the entries are ignored. Saving data with plots: \u00b6 VegaLite does this natively. with Plots.jl one can use hdf5plot_write to write an entire plot, including the data, to an hdf5 file. This means that each plot has to be generated twice; once with whatever backend is used to generate PDF files; and then again with hdf5. In particular, one cannot first plot with another backend and then save the resulting plot object to hdf5. The approach is then to first save the plot to hdf5, then load it and save it with another backend. Note: In my current (v.1.3) installation, hdf5plot_write generates a bunch or warnings followed by a crash due to world age problems.","title":"Plotting"},{"location":"julia_notes/plotting.html#plotting","text":"","title":"Plotting"},{"location":"julia_notes/plotting.html#plotsjl","text":"Visually, PlotlyJS produces the most appealing plots (for me). But it does not install on my system (1.5). When a plotting related library is not found (as in \u201cerror compiling display\u201d), try ]build Plots . Defaults are set with the defaults command.","title":"Plots.jl"},{"location":"julia_notes/plotting.html#axis-labels","text":"bar tends to have too small default margins for axis labels to show (at least in subplots). Try using Plots.PlotMeasures","title":"Axis labels"},{"location":"julia_notes/plotting.html#legends","text":"The label is set when each series is plotted. If labels are set when the plot is created (before the series are plotted), the entries are ignored.","title":"Legends"},{"location":"julia_notes/plotting.html#saving-data-with-plots","text":"VegaLite does this natively. with Plots.jl one can use hdf5plot_write to write an entire plot, including the data, to an hdf5 file. This means that each plot has to be generated twice; once with whatever backend is used to generate PDF files; and then again with hdf5. In particular, one cannot first plot with another backend and then save the resulting plot object to hdf5. The approach is then to first save the plot to hdf5, then load it and save it with another backend. Note: In my current (v.1.3) installation, hdf5plot_write generates a bunch or warnings followed by a crash due to world age problems.","title":"Saving data with plots:"},{"location":"julia_notes/regressions.html","text":"Regressions \u00b6 RegressionTables.jl produces formatted regression tables. GLM (1.5) \u00b6 GLM.jl is the package to run regressions. GLM really expects the data to be provided as a DataFrame , but one can run m = fit(LinearModel, X, y); Then the intercept needs to be explicitly provided as a column of X . Methods: coef(m) returns values of coefficients stderror(m) returns coefficient std errors confint(m) produces confidence intervals by (regressor, lower/upper). But these are wrong in the current version of GLM (and the method no longer appears in the documentation). predict(m) gives predicted values for original X values It is currently not possible to compute confidence intervals for predicted values. There are open issues for this. To save just the regression results (without the data, which could be a lot of memory), use coeftable(mdl). This produces a StatsBase.CoefTable. Alternative, use RegressionTable from EconometricsLH. Categorical regressors return names such as Symbol(\u201cschool: 3\u201d). A useful introduction is in the Cookbook .","title":"Regressions"},{"location":"julia_notes/regressions.html#regressions","text":"RegressionTables.jl produces formatted regression tables.","title":"Regressions"},{"location":"julia_notes/regressions.html#glm-15","text":"GLM.jl is the package to run regressions. GLM really expects the data to be provided as a DataFrame , but one can run m = fit(LinearModel, X, y); Then the intercept needs to be explicitly provided as a column of X . Methods: coef(m) returns values of coefficients stderror(m) returns coefficient std errors confint(m) produces confidence intervals by (regressor, lower/upper). But these are wrong in the current version of GLM (and the method no longer appears in the documentation). predict(m) gives predicted values for original X values It is currently not possible to compute confidence intervals for predicted values. There are open issues for this. To save just the regression results (without the data, which could be a lot of memory), use coeftable(mdl). This produces a StatsBase.CoefTable. Alternative, use RegressionTable from EconometricsLH. Categorical regressors return names such as Symbol(\u201cschool: 3\u201d). A useful introduction is in the Cookbook .","title":"GLM (1.5)"},{"location":"julia_notes/testing.html","text":"Testing \u00b6 Structuring tests \u00b6 The goal is to be able to run subsets of tests and to encapsulate the code of each test. My current approach: Place each testset inside a function. Call these functions from within other testsets. One can now include each file and run the tests independently. The function provide some isolation (similar to using modules). # runtests.jl @testset \"All\" begin include(\"test_one.jl\"); end # test_one.jl using Test function test_one() @testset \"A\" begin @test 1 == 1 end end @testset \"One\" begin test_one(); end Now Pkg.test() runs everything, but include(\"test/test_one.jl\") only runs the subset. SafeTests.jl goes further by wrapping tests in modules. Test helpers can be put into a separate file and conditionally included, as in (taken from MPVerify.jl): @isdefined(TestHelpers) || include(\"../TestHelpers.jl\") This checks whether the module TestHelpers exists. But one may not need a module for the helpers. Module approach: \u00b6 Place each group of tests into a module, so the tests are independent of each other and can be run independently. SafeTestsets.jl has a similar idea, but I find it cleaner to explicitly write out the modules. Though modules have the benefit that they can include setup code that is used repeatedly in different tests. runtests.jl simply contains a list of include statements; one for each test module. Those are wrapped in a @testset for nice display and to ensure that errors don't stop the tests. Each test module also contains a @testset. When runtests is run, it displays a single success summary. But when there are errors, they are nicely broken down by testset. To run tests selectively, simply include the file that contains the @testset at the REPL. Test specific dependencies \u00b6 Test dependencies now need to be added to the Project.toml file in ./test : pkg> activate ./test pkg> add MyPkg pkg> activate . All dependencies used in tests now have to be manually added. They do not \"carry over\" from the main package. Developing test set dependencies seems to cause problems (\"error: cannot merge projects\"). They need to be added. Important note : For now (1.5) test dependencies are still considered \"beta\" and buggy. Do not use. Instead, use the 1.0 method of extras in Project.toml . Useful packages \u00b6 Aqua.jl checks for method ambiguities, invalid exports, stale dependencies, and more. TestSetExtensions.jl mainly provides nicer display of test progress and failures UnitTestDesign generates combinations of arguments that are passed to tests the goal is to generate coverage without having to run all parameter combinations Travis CI (1.2) \u00b6 Travis can automatically test all branches uploaded to github. Need to customize travis.yml to only build for the current Julia version. Building with unregistered dependencies is tricky. Probably ok if the dependencies are added (so they point to a github url), but not if they are developed. Miscellaneous \u00b6 Errors in the code to be tested (but not caught by @test) cause the entire test run to crash. Preventing this requires all tests to be enclosed in a @testset. A sequence of @testset does not do the trick. An error in one prevents all others from being run. Nested @testsets produce nested error reports (nice). @test statements can be placed inside functions. To preserve result reporting, the function should contain a @testset and return its result.","title":"Testing"},{"location":"julia_notes/testing.html#testing","text":"","title":"Testing"},{"location":"julia_notes/testing.html#structuring-tests","text":"The goal is to be able to run subsets of tests and to encapsulate the code of each test. My current approach: Place each testset inside a function. Call these functions from within other testsets. One can now include each file and run the tests independently. The function provide some isolation (similar to using modules). # runtests.jl @testset \"All\" begin include(\"test_one.jl\"); end # test_one.jl using Test function test_one() @testset \"A\" begin @test 1 == 1 end end @testset \"One\" begin test_one(); end Now Pkg.test() runs everything, but include(\"test/test_one.jl\") only runs the subset. SafeTests.jl goes further by wrapping tests in modules. Test helpers can be put into a separate file and conditionally included, as in (taken from MPVerify.jl): @isdefined(TestHelpers) || include(\"../TestHelpers.jl\") This checks whether the module TestHelpers exists. But one may not need a module for the helpers.","title":"Structuring tests"},{"location":"julia_notes/testing.html#module-approach","text":"Place each group of tests into a module, so the tests are independent of each other and can be run independently. SafeTestsets.jl has a similar idea, but I find it cleaner to explicitly write out the modules. Though modules have the benefit that they can include setup code that is used repeatedly in different tests. runtests.jl simply contains a list of include statements; one for each test module. Those are wrapped in a @testset for nice display and to ensure that errors don't stop the tests. Each test module also contains a @testset. When runtests is run, it displays a single success summary. But when there are errors, they are nicely broken down by testset. To run tests selectively, simply include the file that contains the @testset at the REPL.","title":"Module approach:"},{"location":"julia_notes/testing.html#test-specific-dependencies","text":"Test dependencies now need to be added to the Project.toml file in ./test : pkg> activate ./test pkg> add MyPkg pkg> activate . All dependencies used in tests now have to be manually added. They do not \"carry over\" from the main package. Developing test set dependencies seems to cause problems (\"error: cannot merge projects\"). They need to be added. Important note : For now (1.5) test dependencies are still considered \"beta\" and buggy. Do not use. Instead, use the 1.0 method of extras in Project.toml .","title":"Test specific dependencies"},{"location":"julia_notes/testing.html#useful-packages","text":"Aqua.jl checks for method ambiguities, invalid exports, stale dependencies, and more. TestSetExtensions.jl mainly provides nicer display of test progress and failures UnitTestDesign generates combinations of arguments that are passed to tests the goal is to generate coverage without having to run all parameter combinations","title":"Useful packages"},{"location":"julia_notes/testing.html#travis-ci-12","text":"Travis can automatically test all branches uploaded to github. Need to customize travis.yml to only build for the current Julia version. Building with unregistered dependencies is tricky. Probably ok if the dependencies are added (so they point to a github url), but not if they are developed.","title":"Travis CI (1.2)"},{"location":"julia_notes/testing.html#miscellaneous","text":"Errors in the code to be tested (but not caught by @test) cause the entire test run to crash. Preventing this requires all tests to be enclosed in a @testset. A sequence of @testset does not do the trick. An error in one prevents all others from being run. Nested @testsets produce nested error reports (nice). @test statements can be placed inside functions. To preserve result reporting, the function should contain a @testset and return its result.","title":"Miscellaneous"},{"location":"julia_notes/types.html","text":"Types \u00b6 Parametric types without the type parameter are NOT DataTypes; they are UnionAll. Example: struct Foo{T} end; isa(Foo, DataType) == false; I find it easiest to write model specific code NOT using parametric types. Instead, I define type aliases for the types used in custom types (e.g., Double=Float64 ). Then I hardwire the use of Double everywhere. This removes two problems: Possible type instability as the compiler tries to figure out the types of the custom type fields. It becomes possible to call constructors with, say, integers of all kinds without raising method errors. Constructors (1.5) \u00b6 Constructing objects with many fields: Define an inner constructor that leaves the object (partially) uninitialized. It is legal to have new(x) even if the object contains additional fields. LazyInitializedFields.jl ensures that accessing uninitialized fields gives errors. Parameters.jl is useful for objects with default values. Constructor must then provide all arguments that do not have defaults. Note that @with_kw automatically defines show(). Use @with_kw_noshow to avoid this. Base.@kwdef now does much of the same. Inheritance (1.5) \u00b6 There is no inheritance in Julia. Abstract types have no fields and concrete types have no subtypes. There are various discussions about how to implement types that share common fields. For simple cases, it is probably best to just repeat the fields in all types. One good piece of advice: ensure that methods are generally defined on the abstract type, so that all concrete types have the same interface (kind of the point of having an abstract type). Macro for common fields \u00b6 A macro that lets users define a set of common fields for a set of structs: macro def(name, definition) return quote macro $(esc(name))() esc($(Expr(:quote, definition))) end end end @def commonfields begin #Data X #Feature vectors y #Labels (-1,1) nSamples::Int64 # Number of data points nFeatures::Int64 # Number of features end struct Foo @commonfields z end But this does not work with default values. Common fields with default values \u00b6 mutable struct Foo x y z Foo() = new(); end # Need at least one positional argument. Otherwise stack overflow. function Foo(z :: Integer; kwargs...) f = Foo(); set_common_fields!(f); set_kw_args!(f; kwargs...); f.z = z; return f end function set_common_fields!(f :: Foo) f.x = 1; f.y = 2; end function set_kw_args!(f :: Foo; kwargs...) for kw in kwargs setfield!(f, kw[1], kw[2]) end end julia> Foo(3) Foo(1, 2, 3) Common fields in sub-struct \u00b6 An alternative is to store common fields in a sub-struct. Passing methods through to these fields can be automated using @forward in Lazy.jl . using Lazy struct Foo x end @forward Foo.x (Base.show, Base.isempty) The tricky part is to modify these fields. One possible solution: Base.@kwdef mutable struct FooCommon x = 1 y = 2 end Base.@kwdef mutable struct Foo fc :: FooCommon z = 3 zz = 4 end # Again: need at least one positional argument to avoid stack overflow. function Foo(z; kwargs...) f = Foo(fc = FooCommon()); set_kwargs!(f; kwargs...); return f end function set_kwargs!(f :: Foo; kwargs...) for kw in kwargs set_field!(f, kw[1], kw[2]); end end # Note the changed function name. Cannot overload `setfield!`. function set_field!(f :: Foo, fName :: Symbol, fValue) if hasproperty(f, fName) setfield!(f, fName, fValue); else setfield!(f.fc, fName, fValue); end end User Defined Types (1.5) \u00b6 LazyInitializedFields.jl is a nice way of handling partially initialized struct fields. Properties and fields \u00b6 getfield is a \"built-in\" function that always points to a struct field directly. Example: struct A x :: Dict{Symbol,Int} y :: Int end a = A(Dict([:a => 1]), 2); getfield(a, :x) isa Dict{Symbol, Int} getproperty is generically the same as getfield . But note that propertynames(A) spits out additional hidden properties, not just :x, :y . Users can overload getproperty to point to something more useful than the direct fields of the struct : Base.getproperty(a :: A, n :: Symbol) = getfield(a, :x)[n]; Then also overload propertynames so that functions that rely on the public properties of A work.","title":"Types"},{"location":"julia_notes/types.html#types","text":"Parametric types without the type parameter are NOT DataTypes; they are UnionAll. Example: struct Foo{T} end; isa(Foo, DataType) == false; I find it easiest to write model specific code NOT using parametric types. Instead, I define type aliases for the types used in custom types (e.g., Double=Float64 ). Then I hardwire the use of Double everywhere. This removes two problems: Possible type instability as the compiler tries to figure out the types of the custom type fields. It becomes possible to call constructors with, say, integers of all kinds without raising method errors.","title":"Types"},{"location":"julia_notes/types.html#constructors-15","text":"Constructing objects with many fields: Define an inner constructor that leaves the object (partially) uninitialized. It is legal to have new(x) even if the object contains additional fields. LazyInitializedFields.jl ensures that accessing uninitialized fields gives errors. Parameters.jl is useful for objects with default values. Constructor must then provide all arguments that do not have defaults. Note that @with_kw automatically defines show(). Use @with_kw_noshow to avoid this. Base.@kwdef now does much of the same.","title":"Constructors (1.5)"},{"location":"julia_notes/types.html#inheritance-15","text":"There is no inheritance in Julia. Abstract types have no fields and concrete types have no subtypes. There are various discussions about how to implement types that share common fields. For simple cases, it is probably best to just repeat the fields in all types. One good piece of advice: ensure that methods are generally defined on the abstract type, so that all concrete types have the same interface (kind of the point of having an abstract type).","title":"Inheritance (1.5)"},{"location":"julia_notes/types.html#macro-for-common-fields","text":"A macro that lets users define a set of common fields for a set of structs: macro def(name, definition) return quote macro $(esc(name))() esc($(Expr(:quote, definition))) end end end @def commonfields begin #Data X #Feature vectors y #Labels (-1,1) nSamples::Int64 # Number of data points nFeatures::Int64 # Number of features end struct Foo @commonfields z end But this does not work with default values.","title":"Macro for common fields"},{"location":"julia_notes/types.html#common-fields-with-default-values","text":"mutable struct Foo x y z Foo() = new(); end # Need at least one positional argument. Otherwise stack overflow. function Foo(z :: Integer; kwargs...) f = Foo(); set_common_fields!(f); set_kw_args!(f; kwargs...); f.z = z; return f end function set_common_fields!(f :: Foo) f.x = 1; f.y = 2; end function set_kw_args!(f :: Foo; kwargs...) for kw in kwargs setfield!(f, kw[1], kw[2]) end end julia> Foo(3) Foo(1, 2, 3)","title":"Common fields with default values"},{"location":"julia_notes/types.html#common-fields-in-sub-struct","text":"An alternative is to store common fields in a sub-struct. Passing methods through to these fields can be automated using @forward in Lazy.jl . using Lazy struct Foo x end @forward Foo.x (Base.show, Base.isempty) The tricky part is to modify these fields. One possible solution: Base.@kwdef mutable struct FooCommon x = 1 y = 2 end Base.@kwdef mutable struct Foo fc :: FooCommon z = 3 zz = 4 end # Again: need at least one positional argument to avoid stack overflow. function Foo(z; kwargs...) f = Foo(fc = FooCommon()); set_kwargs!(f; kwargs...); return f end function set_kwargs!(f :: Foo; kwargs...) for kw in kwargs set_field!(f, kw[1], kw[2]); end end # Note the changed function name. Cannot overload `setfield!`. function set_field!(f :: Foo, fName :: Symbol, fValue) if hasproperty(f, fName) setfield!(f, fName, fValue); else setfield!(f.fc, fName, fValue); end end","title":"Common fields in sub-struct"},{"location":"julia_notes/types.html#user-defined-types-15","text":"LazyInitializedFields.jl is a nice way of handling partially initialized struct fields.","title":"User Defined Types (1.5)"},{"location":"julia_notes/types.html#properties-and-fields","text":"getfield is a \"built-in\" function that always points to a struct field directly. Example: struct A x :: Dict{Symbol,Int} y :: Int end a = A(Dict([:a => 1]), 2); getfield(a, :x) isa Dict{Symbol, Int} getproperty is generically the same as getfield . But note that propertynames(A) spits out additional hidden properties, not just :x, :y . Users can overload getproperty to point to something more useful than the direct fields of the struct : Base.getproperty(a :: A, n :: Symbol) = getfield(a, :x)[n]; Then also overload propertynames so that functions that rely on the public properties of A work.","title":"Properties and fields"},{"location":"julia_notes/workflow.html","text":"Workflow \u00b6 Revise.jl \u00b6 Revise is essential for a smooth workflow. One limitation: include ing files in a model that is tracked with includet does not work (1.6). Example: # Foo.jl module Foo include(\"foo2.jl\") end # foo2.jl foo() = println(\"This is foo\") # REPL includet(\"Foo.jl\") produces a MethodError that is hard to make sense of. Once code gets complicated enough that files include other files, it is best to make a package.","title":"Workflow"},{"location":"julia_notes/workflow.html#workflow","text":"","title":"Workflow"},{"location":"julia_notes/workflow.html#revisejl","text":"Revise is essential for a smooth workflow. One limitation: include ing files in a model that is tracked with includet does not work (1.6). Example: # Foo.jl module Foo include(\"foo2.jl\") end # foo2.jl foo() = println(\"This is foo\") # REPL includet(\"Foo.jl\") produces a MethodError that is hard to make sense of. Once code gets complicated enough that files include other files, it is best to make a package.","title":"Revise.jl"},{"location":"teaching/current_issues.html","text":"Topics in the Current Policy Debate \u00b6 Trade Restrictions: China \u00b6 Economist topic page: trade barriers Winners and losers in a China-America trade war (Economist, Jan 2017) What might a trade war between America and China look like? (Economist, Feb 2017) Taxes \u00b6 Border Adjustments, Tariffs, VAT, and the Corporate Income Tax , Jan 2017 discusses the implications of corporate tax reforms, including the Trump proposal Useful sources for undergraduate research \u00b6 Journal of Economic Perspectives Brookings Institution , which also has topics pages NY Fed: Liberty Street Economics , Economic Policy Review MN Fed: Quarterly Review SF Fed: Economic Letter","title":"Topics in the Current Policy Debate #"},{"location":"teaching/current_issues.html#topics-in-the-current-policy-debate","text":"","title":"Topics in the Current Policy Debate"},{"location":"teaching/current_issues.html#trade-restrictions-china","text":"Economist topic page: trade barriers Winners and losers in a China-America trade war (Economist, Jan 2017) What might a trade war between America and China look like? (Economist, Feb 2017)","title":"Trade Restrictions: China"},{"location":"teaching/current_issues.html#taxes","text":"Border Adjustments, Tariffs, VAT, and the Corporate Income Tax , Jan 2017 discusses the implications of corporate tax reforms, including the Trump proposal","title":"Taxes"},{"location":"teaching/current_issues.html#useful-sources-for-undergraduate-research","text":"Journal of Economic Perspectives Brookings Institution , which also has topics pages NY Fed: Liberty Street Economics , Economic Policy Review MN Fed: Quarterly Review SF Fed: Economic Letter","title":"Useful sources for undergraduate research"},{"location":"teaching/exam_tips.html","text":"Tips for Exams \u00b6 Slow down \u00b6 Most exam answers are quite short. The trick is to approach the question correctly from the start. Algebra errors are quite costly. They can be avoided by slowing down, writing carefully, and checking your algebra from time to time. Read the question carefully. I often grade answers that clearly overlooked a piece of information that was given in the question. Don't panic \u00b6 Don't panic when an answer does not come together. Move on to the next question and come back to the one that bugs you later. Explain your answers \u00b6 Just giving me a graph and letting me figure out the answer does not work. When you draw a graph, explain why you think the curves slope up or down, etc. If you make a mistake, at least I can give you partial credit. Writing \u00b6 Make room. A lot of answers are very crowded. Then you find that you have to fit something else in and soon you have a mess on the page, where I don't even know in what order I am supposed to read things. If I can't read it, I can't grade it.","title":"Tips for Exams #"},{"location":"teaching/exam_tips.html#tips-for-exams","text":"","title":"Tips for Exams"},{"location":"teaching/exam_tips.html#slow-down","text":"Most exam answers are quite short. The trick is to approach the question correctly from the start. Algebra errors are quite costly. They can be avoided by slowing down, writing carefully, and checking your algebra from time to time. Read the question carefully. I often grade answers that clearly overlooked a piece of information that was given in the question.","title":"Slow down"},{"location":"teaching/exam_tips.html#dont-panic","text":"Don't panic when an answer does not come together. Move on to the next question and come back to the one that bugs you later.","title":"Don't panic"},{"location":"teaching/exam_tips.html#explain-your-answers","text":"Just giving me a graph and letting me figure out the answer does not work. When you draw a graph, explain why you think the curves slope up or down, etc. If you make a mistake, at least I can give you partial credit.","title":"Explain your answers"},{"location":"teaching/exam_tips.html#writing","text":"Make room. A lot of answers are very crowded. Then you find that you have to fit something else in and soon you have a mess on the page, where I don't even know in what order I am supposed to read things. If I can't read it, I can't grade it.","title":"Writing"},{"location":"teaching/honors_thesis_topics.html","text":"Some Ideas for Honors Thesis Projects \u00b6 This page contains a collection of ideas that may be useful starting points for honors theses. Disclaimer : I haven't thought about these ideas carefully, so they may not be good ideas. Or they may have been done (note the date next to each idea). Or they may not be doable. Or boring, or fundamentally mistaken, or any of the other things that tend to derail research projects. Don't take the ideas as given. Use them to get started thinking about a set of questions. College \u00b6 College qualities over time \u00b6 Are college qualities highly persistent over time? Do colleges move around in the quality distribution? Which colleges move up and why? College Stratification \u00b6 Hoxby (2009) shows that colleges became more stratified in the 1960s. Her data end in 2006. They are also not publicly available. Moreover, Hoxby's data show that initially highly selective colleges became more selective over time and vice versa. A different, but related, question is: did colleges become more homogeneous? How did the CDF of college \"qualities\" change over time? What happened more recently? Possible data sources: IPEDS (since about 1985) and HERI freshmen surveys. Cross-country Income Differences \u00b6 Do immigrant earnings rise with source country GDP? \u00b6 But see JOEG 2018/139 (never published) Occupational downgrading of immigrants (2020) \u00b6 Idea: If immigrants from poor countries have less hc (given schooling), they should be employed in jobs that require less hc. Those are jobs held by natives with lower schooling. Quantify this: Construct avg native schooling by [occupation, industry]. For each source/host pair: compute the average gap between immigrant and native schooling in [occ, ind] cells. This is a measure of occupational downgrading. To what extent is the wage gap between immigrants and similar natives explained by this? Jones (2014) has strong claims about downgrading. How do those hold up? The task content of immigrant jobs (2020) \u00b6 Todd Schoellman may have done this. Inequality \u00b6 Hsieh/Klenow for Immigrants \u00b6 Hsieh et al 2019 show that women and black men were underrepresented in certain occupations in the 1960s. Over time, the gaps diminished, suggesting that the allocation of talent improved. Is there evidence for a similar convergence among immigrants? How important are inheritances (2020) \u00b6 Using the SCF, calculate the fraction of wealth inherited by the rich. Feiveson and Sabelhaus 2018 do something like this. They conclude that the rich likely inherit a large fraction of their wealth. Those calculations are quite sensitive to the assumed real interest rates. Sources of earnings \"shocks\" (2021) \u00b6 Administrative data show that earnings \"shocks\" are asymmetric (frequent small positive and rare large negative shocks). What observable events are associated with earnings shocks? What fraction of the \"shocks\" are due to employer changes including layoffs occupation changes big changes in hours worked family events (e.g., having children) The goal is to inform how one could model earnings shocks (in structural models). How predictable are lifetime earnings? (2020) \u00b6 It is fairly easy to get a lower bound on predictability. Take a panel dataset. Use half to fit a statistical model. Use the other half to perform out of sample prediction. Specification search is a problem. Skill premium variation across U.S. states / cities \u00b6 Dispersion supposedly has decreased. Could one explore empirically possible explanations? This is very open ended without a clear hypothesis or method. Giannone, Elisa. n.d. \u201cSkill-Biased Technical Change and Regional Convergence\u201d","title":"Some Ideas for Honors Thesis Projects #"},{"location":"teaching/honors_thesis_topics.html#some-ideas-for-honors-thesis-projects","text":"This page contains a collection of ideas that may be useful starting points for honors theses. Disclaimer : I haven't thought about these ideas carefully, so they may not be good ideas. Or they may have been done (note the date next to each idea). Or they may not be doable. Or boring, or fundamentally mistaken, or any of the other things that tend to derail research projects. Don't take the ideas as given. Use them to get started thinking about a set of questions.","title":"Some Ideas for Honors Thesis Projects"},{"location":"teaching/honors_thesis_topics.html#college","text":"","title":"College"},{"location":"teaching/honors_thesis_topics.html#college-qualities-over-time","text":"Are college qualities highly persistent over time? Do colleges move around in the quality distribution? Which colleges move up and why?","title":"College qualities over time"},{"location":"teaching/honors_thesis_topics.html#college-stratification","text":"Hoxby (2009) shows that colleges became more stratified in the 1960s. Her data end in 2006. They are also not publicly available. Moreover, Hoxby's data show that initially highly selective colleges became more selective over time and vice versa. A different, but related, question is: did colleges become more homogeneous? How did the CDF of college \"qualities\" change over time? What happened more recently? Possible data sources: IPEDS (since about 1985) and HERI freshmen surveys.","title":"College Stratification"},{"location":"teaching/honors_thesis_topics.html#cross-country-income-differences","text":"","title":"Cross-country Income Differences"},{"location":"teaching/honors_thesis_topics.html#do-immigrant-earnings-rise-with-source-country-gdp","text":"But see JOEG 2018/139 (never published)","title":"Do immigrant earnings rise with source country GDP?"},{"location":"teaching/honors_thesis_topics.html#occupational-downgrading-of-immigrants-2020","text":"Idea: If immigrants from poor countries have less hc (given schooling), they should be employed in jobs that require less hc. Those are jobs held by natives with lower schooling. Quantify this: Construct avg native schooling by [occupation, industry]. For each source/host pair: compute the average gap between immigrant and native schooling in [occ, ind] cells. This is a measure of occupational downgrading. To what extent is the wage gap between immigrants and similar natives explained by this? Jones (2014) has strong claims about downgrading. How do those hold up?","title":"Occupational downgrading of immigrants (2020)"},{"location":"teaching/honors_thesis_topics.html#the-task-content-of-immigrant-jobs-2020","text":"Todd Schoellman may have done this.","title":"The task content of immigrant jobs (2020)"},{"location":"teaching/honors_thesis_topics.html#inequality","text":"","title":"Inequality"},{"location":"teaching/honors_thesis_topics.html#hsiehklenow-for-immigrants","text":"Hsieh et al 2019 show that women and black men were underrepresented in certain occupations in the 1960s. Over time, the gaps diminished, suggesting that the allocation of talent improved. Is there evidence for a similar convergence among immigrants?","title":"Hsieh/Klenow for Immigrants"},{"location":"teaching/honors_thesis_topics.html#how-important-are-inheritances-2020","text":"Using the SCF, calculate the fraction of wealth inherited by the rich. Feiveson and Sabelhaus 2018 do something like this. They conclude that the rich likely inherit a large fraction of their wealth. Those calculations are quite sensitive to the assumed real interest rates.","title":"How important are inheritances (2020)"},{"location":"teaching/honors_thesis_topics.html#sources-of-earnings-shocks-2021","text":"Administrative data show that earnings \"shocks\" are asymmetric (frequent small positive and rare large negative shocks). What observable events are associated with earnings shocks? What fraction of the \"shocks\" are due to employer changes including layoffs occupation changes big changes in hours worked family events (e.g., having children) The goal is to inform how one could model earnings shocks (in structural models).","title":"Sources of earnings \"shocks\" (2021)"},{"location":"teaching/honors_thesis_topics.html#how-predictable-are-lifetime-earnings-2020","text":"It is fairly easy to get a lower bound on predictability. Take a panel dataset. Use half to fit a statistical model. Use the other half to perform out of sample prediction. Specification search is a problem.","title":"How predictable are lifetime earnings? (2020)"},{"location":"teaching/honors_thesis_topics.html#skill-premium-variation-across-us-states-cities","text":"Dispersion supposedly has decreased. Could one explore empirically possible explanations? This is very open ended without a clear hypothesis or method. Giannone, Elisa. n.d. \u201cSkill-Biased Technical Change and Regional Convergence\u201d","title":"Skill premium variation across U.S. states / cities"},{"location":"teaching/teaching.html","text":"Undergraduate Teaching \u00b6 Potential topics for honors theses How can undergraduates get involved in research? Current issues in the policy arena Exam tips","title":"Teaching notes"},{"location":"teaching/teaching.html#undergraduate-teaching","text":"Potential topics for honors theses How can undergraduates get involved in research? Current issues in the policy arena Exam tips","title":"Undergraduate Teaching"},{"location":"teaching/undergrad_research.html","text":"How can undergraduates get involved in research? \u00b6 The main organized path for undergraduate research in economics is the senior honors thesis . Aside from the honors thesis, students need to approach faculty members directly and inquire whether they can work on one of the faculty members' projects. This works best if the faculty member already knows the student. For help with this process, please contact the undergraduate research liasion (the economics front office will know who this is at any given time). Also see the notes provided by OUR Summer research fellowships \u00b6 Mayo Summer Research Fellowship for macro SURF Summer University Research Fellowships Guest Summer Research Fellowship for micro. These are announced in late fall, with applications due in March. An additional option is the University work-study program.","title":"How can undergraduates get involved in research?"},{"location":"teaching/undergrad_research.html#how-can-undergraduates-get-involved-in-research","text":"The main organized path for undergraduate research in economics is the senior honors thesis . Aside from the honors thesis, students need to approach faculty members directly and inquire whether they can work on one of the faculty members' projects. This works best if the faculty member already knows the student. For help with this process, please contact the undergraduate research liasion (the economics front office will know who this is at any given time). Also see the notes provided by OUR","title":"How can undergraduates get involved in research?"},{"location":"teaching/undergrad_research.html#summer-research-fellowships","text":"Mayo Summer Research Fellowship for macro SURF Summer University Research Fellowships Guest Summer Research Fellowship for micro. These are announced in late fall, with applications due in March. An additional option is the University work-study program.","title":"Summer research fellowships"},{"location":"thoughts/duplication.html","text":"Thoughts on How Economists Can Avoid Reinventing the Wheel \u00b6 The Problem \u00b6 In writing research papers, economists solve the same problems over and over again. Code Examples Drawing joint Normal random variables with fixed standard deviations (e.g. agents' endowments). Coding common production functions (nested CES). Data Examples Constructing individual histories of earnings / schooling using NLSY / PSID data. Consistently constructing measures of schooling / earnings across year in CPS / Census / ACS data. The list is endless. The Solution \u00b6 Consider what other disciplines do. People who work on numerical math have access to a set of trusted code libraries (BLAS, NLopt, ...). There is a mechanism through which users can contribute to code ( github ) or discuss it (e.g., stackexchange ). Consider the development of the Julia language . All the code libraries live on github . The major packages are moderated by groups who take responsibility for the code's correctness. All code comes with automated tests. The result: Much of the time when users ask questions on how to solve a problem in Julia , someone will simply point to an existing library. Economics needs a similar setup for code and for data. Instead of creating the same variables over and over again from each of the major datasets, there should be a place where the construction of such variables can be discussed and where code for constructing variables can be posted (and trusted). The Organizational Problem \u00b6 Why does this not happen?[^QuantEconFn] Because there is no payoff for individuals to run such an effort. Can this problem be solved? As a small first step, I have started to post reusable code I wrote at github . [^QuantEconFn]: A partial exception is QuantEcon , which is organized by Sargent and Stacchurski. But it is not an open repository.","title":"Avoid reinventing the wheel"},{"location":"thoughts/duplication.html#thoughts-on-how-economists-can-avoid-reinventing-the-wheel","text":"","title":"Thoughts on How Economists Can Avoid Reinventing the Wheel"},{"location":"thoughts/duplication.html#the-problem","text":"In writing research papers, economists solve the same problems over and over again. Code Examples Drawing joint Normal random variables with fixed standard deviations (e.g. agents' endowments). Coding common production functions (nested CES). Data Examples Constructing individual histories of earnings / schooling using NLSY / PSID data. Consistently constructing measures of schooling / earnings across year in CPS / Census / ACS data. The list is endless.","title":"The Problem"},{"location":"thoughts/duplication.html#the-solution","text":"Consider what other disciplines do. People who work on numerical math have access to a set of trusted code libraries (BLAS, NLopt, ...). There is a mechanism through which users can contribute to code ( github ) or discuss it (e.g., stackexchange ). Consider the development of the Julia language . All the code libraries live on github . The major packages are moderated by groups who take responsibility for the code's correctness. All code comes with automated tests. The result: Much of the time when users ask questions on how to solve a problem in Julia , someone will simply point to an existing library. Economics needs a similar setup for code and for data. Instead of creating the same variables over and over again from each of the major datasets, there should be a place where the construction of such variables can be discussed and where code for constructing variables can be posted (and trusted).","title":"The Solution"},{"location":"thoughts/duplication.html#the-organizational-problem","text":"Why does this not happen?[^QuantEconFn] Because there is no payoff for individuals to run such an effort. Can this problem be solved? As a small first step, I have started to post reusable code I wrote at github . [^QuantEconFn]: A partial exception is QuantEcon , which is organized by Sargent and Stacchurski. But it is not an open repository.","title":"The Organizational Problem"},{"location":"thoughts/forums.html","text":"Economics Discussion Forums \u00b6 2020-Aug-9 Wouldn't it be nice if there were a place where economists can pose questions and get help from other economists? Wouldn't that be very helpful for undergraduate and graduate students who are trying to learn economics? But also for researchers who look for data sources, references, methods, ...? For software, online forums of this kind are commonplace. Even experience programmers consult them all the time. For learning new languages, they are essential. Economics needs its own discussion forum. For this to work, the forum must require registration. Posts cannot be anonymous. The discussion must be moderated. Otherwise, we end up with another facebook or twitter. Here are the forums that I know about: EconSpark organized by the AEA registration required, moderated volume is currently quite low Econ StackExchange currently listed as \"beta\" registration required, moderated focused on Q&A, not discussion there is reasonable volume, but questions and answers tend to be basic I found that Debate.org is overrun by spam. It seems to me that StackExchange could be the place to pose specific questions and EconSpark could be the place for more open ended conversations. I propose that we all point our students to those two forums to get some volume going.","title":"Economics discussion forums"},{"location":"thoughts/forums.html#economics-discussion-forums","text":"2020-Aug-9 Wouldn't it be nice if there were a place where economists can pose questions and get help from other economists? Wouldn't that be very helpful for undergraduate and graduate students who are trying to learn economics? But also for researchers who look for data sources, references, methods, ...? For software, online forums of this kind are commonplace. Even experience programmers consult them all the time. For learning new languages, they are essential. Economics needs its own discussion forum. For this to work, the forum must require registration. Posts cannot be anonymous. The discussion must be moderated. Otherwise, we end up with another facebook or twitter. Here are the forums that I know about: EconSpark organized by the AEA registration required, moderated volume is currently quite low Econ StackExchange currently listed as \"beta\" registration required, moderated focused on Q&A, not discussion there is reasonable volume, but questions and answers tend to be basic I found that Debate.org is overrun by spam. It seems to me that StackExchange could be the place to pose specific questions and EconSpark could be the place for more open ended conversations. I propose that we all point our students to those two forums to get some volume going.","title":"Economics Discussion Forums"},{"location":"thoughts/micro_macro.html","text":"Micro Versus Macro \u00b6 Why do macro models look so different from micro models? A caricature: A macro model: Has 7 parameters which are calibrated to match 7 data moments. Has decision rules that only depend on a few state variables. A micro model: Has 700 parameters which are estimated so that the model replicates the complete life histories of everyone in a dataset. All decisions a person ever makes in life are modeled. There are preference shocks everywhere. Decision rules depend on everything the researcher can observe. Why do researchers in the same profession, often studying the same question, write down models that look so different? I think the answer is that applied micro economists view models very differently from macro economists. In macro, a model is a proof of concept . It is a reasonable model with reasonable parameters that demonstrates that a particular mechanism can be big . In micro, a model is a close approximation of the true data generating process (that's why there is so much emphasis on hypothesis testing). The quantitative answers are taken seriously. Last updated: 2016-Dec","title":"Micro versus macro models"},{"location":"thoughts/micro_macro.html#micro-versus-macro","text":"Why do macro models look so different from micro models? A caricature: A macro model: Has 7 parameters which are calibrated to match 7 data moments. Has decision rules that only depend on a few state variables. A micro model: Has 700 parameters which are estimated so that the model replicates the complete life histories of everyone in a dataset. All decisions a person ever makes in life are modeled. There are preference shocks everywhere. Decision rules depend on everything the researcher can observe. Why do researchers in the same profession, often studying the same question, write down models that look so different? I think the answer is that applied micro economists view models very differently from macro economists. In macro, a model is a proof of concept . It is a reasonable model with reasonable parameters that demonstrates that a particular mechanism can be big . In micro, a model is a close approximation of the true data generating process (that's why there is so much emphasis on hypothesis testing). The quantitative answers are taken seriously. Last updated: 2016-Dec","title":"Micro Versus Macro"},{"location":"thoughts/models_beliefs.html","text":"Models and Beliefs \u00b6 I propose the hypothesis: It is very rare for models to change beliefs about reality. We (researchers) spend a rather large amount of time on structural models. Especially on getting quantitative answers out of them. Do the answers we get have much of an impact on what people believe about reality. I think the answer is \"no\". I am familiar with research on economic growth, cross-country income differences, and wealth distribution. Consider the basic questions from that literature. Why Are Some Countries Rich and Others Poor? \u00b6 Our current understanding seems alarmingly similar to that of 1996, when I got my degree. Capital is probably not important. I'm not sure we have a very good reason for believing this (see Caselli's JEL survey). Human capital: we don't know. Quantitative models are all over the place. Even if they weren't, I don't think anyone would take them very seriously. Immigrant earnings point in one direction (Hendricks 2002), but then maybe not (Hendricks and Schoellman 2016). TFP is probably important. But then we knew that back in the 1960s. Lots of research has changed beliefs very little. Why? Because we don't have clear evidence that we can interpret without a model. As for deep causes , most researchers probably believe that institutions are important. I would argue that this belief has not changed much over time. It has been supported by clever empirical papers (Acemoglu et al.). That work has changed beliefs. Notably, it is purely empirical, supported by a coherent historical narrative. Why Do Countries Grow? \u00b6 We don't really know anything about this. We like to write down \"R&D\" models, but that seems to have more to do with prejudice than with evidence. Is there any evidence to support that \"R&D\" is really what drives growth? It's probably true, but I say this because of my intuitive understanding of how the world works, not because of evidence. Why Do Some Households Hold Lots of Wealth? \u00b6 Here is a case where a model probably did change beliefs (Huggett 1996). I think this worked because households don't do very much in that model. We have a bunch of candidate solutions for generating high wealth holdings (inheritances and entrepreneurship are probably the leading candidates). How important these are is still not settled. Most researchers probably believe that entrepreneurship is important. But then this is somewhat obvious from looking at the data. I don't think that models did much to generate this belief. Implications \u00b6 If models don't change beliefs, then we are probably wasting a lot of time in macro research. Perhaps the old-fashioned approach of showing correlations (e.g., OLS regressions) and offering a coherent interpretation is underrated. Last updated: 2016-Dec","title":"Models and beliefs"},{"location":"thoughts/models_beliefs.html#models-and-beliefs","text":"I propose the hypothesis: It is very rare for models to change beliefs about reality. We (researchers) spend a rather large amount of time on structural models. Especially on getting quantitative answers out of them. Do the answers we get have much of an impact on what people believe about reality. I think the answer is \"no\". I am familiar with research on economic growth, cross-country income differences, and wealth distribution. Consider the basic questions from that literature.","title":"Models and Beliefs"},{"location":"thoughts/models_beliefs.html#why-are-some-countries-rich-and-others-poor","text":"Our current understanding seems alarmingly similar to that of 1996, when I got my degree. Capital is probably not important. I'm not sure we have a very good reason for believing this (see Caselli's JEL survey). Human capital: we don't know. Quantitative models are all over the place. Even if they weren't, I don't think anyone would take them very seriously. Immigrant earnings point in one direction (Hendricks 2002), but then maybe not (Hendricks and Schoellman 2016). TFP is probably important. But then we knew that back in the 1960s. Lots of research has changed beliefs very little. Why? Because we don't have clear evidence that we can interpret without a model. As for deep causes , most researchers probably believe that institutions are important. I would argue that this belief has not changed much over time. It has been supported by clever empirical papers (Acemoglu et al.). That work has changed beliefs. Notably, it is purely empirical, supported by a coherent historical narrative.","title":"Why Are Some Countries Rich and Others Poor?"},{"location":"thoughts/models_beliefs.html#why-do-countries-grow","text":"We don't really know anything about this. We like to write down \"R&D\" models, but that seems to have more to do with prejudice than with evidence. Is there any evidence to support that \"R&D\" is really what drives growth? It's probably true, but I say this because of my intuitive understanding of how the world works, not because of evidence.","title":"Why Do Countries Grow?"},{"location":"thoughts/models_beliefs.html#why-do-some-households-hold-lots-of-wealth","text":"Here is a case where a model probably did change beliefs (Huggett 1996). I think this worked because households don't do very much in that model. We have a bunch of candidate solutions for generating high wealth holdings (inheritances and entrepreneurship are probably the leading candidates). How important these are is still not settled. Most researchers probably believe that entrepreneurship is important. But then this is somewhat obvious from looking at the data. I don't think that models did much to generate this belief.","title":"Why Do Some Households Hold Lots of Wealth?"},{"location":"thoughts/models_beliefs.html#implications","text":"If models don't change beliefs, then we are probably wasting a lot of time in macro research. Perhaps the old-fashioned approach of showing correlations (e.g., OLS regressions) and offering a coherent interpretation is underrated. Last updated: 2016-Dec","title":"Implications"},{"location":"thoughts/quantitative_models.html","text":"The Question of Simple Models and Little Data \u00b6 For some time, I have been wondering why many highly competent authors in quantitative economics work with very stylized models and with very limited data. Examples: \u00b6 Hsieh/Hurst/Jones/Klenow (Econometrica, forthcoming) could use panel data to get a better idea of individuals' comparative advantage for particular occupations. Lagakos/Waugh (AER) could use panel data to see whether urban/rural migrants experience large wage gains (similar to Glazer/Mare using US data). An extreme example: Manuelli/Seshadri (AER) use essentially no data at all. Could one not pin down key model parameters, such as \"the elasticity\" in Manuelly/Seshadri, more precisely with more/better data? One possible resolution of the puzzle: these papers really point out the possibility that a particular cause-effect mechanism could be empirically important. To do so, they write down a simple model and calibrate it in a simple way. The point being made would then be rather limited: one can write down a non-nonsensical model and stick in non-nonsensical parameter values and find that the mechanism under study is \"big.\" Of course, this is not the way the papers are written. They typically contain quantitative statements, such as \"the entire rise in the US college wage premium can be accounted for by the changing relative abilities of college graduates\" (Hendricks/Schoellman, JME 2014; to point a finger at myself). An innocent reader (like myself, until recently) might take the quantitative results at face value. But then it is puzzling that the models so stylized and that not more data are used to discipline them. But then: if the papers merely point out a possibility, this puzzle is resolved. Perhaps, the authors understand that possibilities are all we can get from quantitative models. So we might as well proceed with simple examples instead of complicated models and detailed data. But then we have a major problem: quantitative economics is then limited to accumulating potentially important explanations for what we observe. In many cases, the number of explanations is quite large. Take the case of cross-country income gaps. If we add up the fractions explained by physical capital, human capital, misallocation, capital import frictions, etc., we end up explaining the observed income gaps many times over. Something seems fundamentally wrong here.","title":"On simple models calibrated using little data"},{"location":"thoughts/quantitative_models.html#the-question-of-simple-models-and-little-data","text":"For some time, I have been wondering why many highly competent authors in quantitative economics work with very stylized models and with very limited data.","title":"The Question of Simple Models and Little Data"},{"location":"thoughts/quantitative_models.html#examples","text":"Hsieh/Hurst/Jones/Klenow (Econometrica, forthcoming) could use panel data to get a better idea of individuals' comparative advantage for particular occupations. Lagakos/Waugh (AER) could use panel data to see whether urban/rural migrants experience large wage gains (similar to Glazer/Mare using US data). An extreme example: Manuelli/Seshadri (AER) use essentially no data at all. Could one not pin down key model parameters, such as \"the elasticity\" in Manuelly/Seshadri, more precisely with more/better data? One possible resolution of the puzzle: these papers really point out the possibility that a particular cause-effect mechanism could be empirically important. To do so, they write down a simple model and calibrate it in a simple way. The point being made would then be rather limited: one can write down a non-nonsensical model and stick in non-nonsensical parameter values and find that the mechanism under study is \"big.\" Of course, this is not the way the papers are written. They typically contain quantitative statements, such as \"the entire rise in the US college wage premium can be accounted for by the changing relative abilities of college graduates\" (Hendricks/Schoellman, JME 2014; to point a finger at myself). An innocent reader (like myself, until recently) might take the quantitative results at face value. But then it is puzzling that the models so stylized and that not more data are used to discipline them. But then: if the papers merely point out a possibility, this puzzle is resolved. Perhaps, the authors understand that possibilities are all we can get from quantitative models. So we might as well proceed with simple examples instead of complicated models and detailed data. But then we have a major problem: quantitative economics is then limited to accumulating potentially important explanations for what we observe. In many cases, the number of explanations is quite large. Take the case of cross-country income gaps. If we add up the fractions explained by physical capital, human capital, misallocation, capital import frictions, etc., we end up explaining the observed income gaps many times over. Something seems fundamentally wrong here.","title":"Examples:"},{"location":"thoughts/specialization.html","text":"Specialization (or the Lack Thereof) \u00b6 Researchers in other disciplines are highly specialized. Economists are not. This is inefficient. In Biology, someone may spend 20 years studying Red Ants in East Africa. It would by unthinkable for that person to suddenly write a paper on Emperor Penguins. In economics, the analogous behavior is entirely common. People write on topics they don't know anything about. And nobody thinks this is odd. As a referee, I commonly encounter authors that appear not to understand or not to be familiar with the literature. This is one cost of the lack of specialization. Another cost is duplication of effort. If an author wants to work with a particular dataset, he/she typically just figures out how that dataset \"works.\" This leads to mistakes and it wastes time. We need authors that specialize in specific datasets. Similarly, very few economists know how to write reasonable computer code. Having looked at quite a few examples of programs underlying published papers, I find: Spagetti code: single functions with over 1,000 lines of non-trivial code. No evidence that the code has been tested. Globals are used to set parameters. No easy way of swapping out model elements, even though a typical paper solves many different versions of a model. Little useful documentation. Essentially no general purpose code is used. Essentially no code is used that was written by someone else. In other words, most economists violate all the guidelines one would typically learn in Programming 101. Most code that is written is likely wrong. We need authors who specialize in programming. Consider again how other disciplines work. As an extreme example, experimental physics employs a wide variety of specialists (engineers, programmers, machine shop workers, etc). This makes it possible to run very complex projects, such as particle beam colliders. Economists do nothing of remotely similar complexity. We need to specialize.","title":"Economists need to specialize"},{"location":"thoughts/specialization.html#specialization-or-the-lack-thereof","text":"Researchers in other disciplines are highly specialized. Economists are not. This is inefficient. In Biology, someone may spend 20 years studying Red Ants in East Africa. It would by unthinkable for that person to suddenly write a paper on Emperor Penguins. In economics, the analogous behavior is entirely common. People write on topics they don't know anything about. And nobody thinks this is odd. As a referee, I commonly encounter authors that appear not to understand or not to be familiar with the literature. This is one cost of the lack of specialization. Another cost is duplication of effort. If an author wants to work with a particular dataset, he/she typically just figures out how that dataset \"works.\" This leads to mistakes and it wastes time. We need authors that specialize in specific datasets. Similarly, very few economists know how to write reasonable computer code. Having looked at quite a few examples of programs underlying published papers, I find: Spagetti code: single functions with over 1,000 lines of non-trivial code. No evidence that the code has been tested. Globals are used to set parameters. No easy way of swapping out model elements, even though a typical paper solves many different versions of a model. Little useful documentation. Essentially no general purpose code is used. Essentially no code is used that was written by someone else. In other words, most economists violate all the guidelines one would typically learn in Programming 101. Most code that is written is likely wrong. We need authors who specialize in programming. Consider again how other disciplines work. As an extreme example, experimental physics employs a wide variety of specialists (engineers, programmers, machine shop workers, etc). This makes it possible to run very complex projects, such as particle beam colliders. Economists do nothing of remotely similar complexity. We need to specialize.","title":"Specialization (or the Lack Thereof)"}]}